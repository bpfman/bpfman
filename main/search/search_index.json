{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>Formerly know as <code>bpfd</code></p>"},{"location":"#bpfman-an-ebpf-manager","title":"bpfman: An eBPF Manager","text":"<p>bpfman operates as an eBPF manager, focusing on simplifying the deployment and administration of eBPF programs. Its notable features encompass:</p> <ul> <li>System Overview: Provides insights into how eBPF is utilized in your system.</li> <li>eBPF Program Loader: Includes a built-in program loader that supports program cooperation for XDP and TC programs, as well as deployment of eBPF programs from OCI images.</li> <li>eBPF Filesystem Management: Manages the eBPF filesystem, facilitating the deployment of eBPF applications without requiring additional privileges.</li> </ul> <p>Our program loader and eBPF filesystem manager ensure the secure deployment of eBPF applications. Furthermore, bpfman includes a Kubernetes operator, extending these capabilities to Kubernetes. This allows users to confidently deploy eBPF through custom resource definitions across nodes in a cluster.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>To get up and running with bpfman go straight to the quick start documentation.</p>"},{"location":"#why-ebpf","title":"Why eBPF?","text":"<p>eBPF is a powerful general-purpose framework that allows running sandboxed programs in the kernel. It can be used for many purposes, including networking, monitoring, tracing and security.</p>"},{"location":"#why-ebpf-in-kubernetes","title":"Why eBPF in Kubernetes?","text":"<p>Demand is increasing from both Kubernetes developers and users. Examples of eBPF in Kubernetes include:</p> <ul> <li>Cilium and Calico   CNIs</li> <li>Pixie: Open source observability</li> <li>KubeArmor: Container-aware runtime security   enforcement system</li> <li>Blixt: Gateway API L4 conformance   implementation</li> <li>NetObserv: Open source operator for network   observability</li> </ul>"},{"location":"#challenges-for-ebpf-in-kubernetes","title":"Challenges for eBPF in Kubernetes","text":"<ul> <li>Requires privileged pods:<ul> <li>eBPF-enabled apps require at least CAP_BPF permissions and potentially   more depending on the type of program that is being attached.</li> <li>Since the Linux capabilities are very broad it is challenging to constrain   a pod to the minimum set of privileges required. This can allow them to do   damage (either unintentionally or intentionally).</li> </ul> </li> <li>Handling multiple eBPF programs on the same eBPF hooks:<ul> <li>Not all eBPF hooks are designed to support multiple programs.</li> <li>Some software using eBPF assumes exclusive use of an eBPF hook and can   unintentionally eject existing programs when being attached. This can   result in silent failures and non-deterministic failures.</li> </ul> </li> <li>Debugging problems with deployments is hard:<ul> <li>The cluster administrator may not be aware that eBPF programs are being   used in a cluster.</li> <li>It is possible for some eBPF programs to interfere with others in   unpredictable ways.</li> <li>SSH access or a privileged pod is necessary to determine the state of eBPF   programs on each node in the cluster.</li> </ul> </li> <li>Lifecycle management of eBPF programs:<ul> <li>While there are libraries for the basic loading and unloading of eBPF   programs, a lot of code is often needed around them for lifecycle   management.</li> </ul> </li> <li>Deployment on Kubernetes is not simple:<ul> <li>It is an involved process that requires first writing a daemon that loads   your eBPF bytecode and deploying it using a DaemonSet.</li> <li>This requires careful design and intricate knowledge of the eBPF program   lifecycle to ensure your program stays loaded and that you can easily   tolerate pod restarts and upgrades.</li> <li>In eBPF enabled K8s deployments today, the eBPF Program is often embedded   into the userspace binary that loads and interacts with it. This means   there's no easy way to have fine-grained versioning control of the   bpfProgram in relation to it's accompanying userspace counterpart.</li> </ul> </li> </ul>"},{"location":"#what-is-bpfman","title":"What is bpfman?","text":"<p>bpfman is a software stack that aims to make it easy to load, unload, modify and monitor eBPF programs whether on a single host, or in a Kubernetes cluster. bpfman includes the following core components:</p> <ul> <li>bpfman: A system daemon that supports loading, unloading, modifying and   monitoring of eBPF programs exposed over a gRPC API.</li> <li>eBPF CRDS: bpfman provides a set of CRDs (<code>XdpProgram</code>, <code>TcProgram</code>, etc.) that   provide a way to express intent to load eBPF programs as well as a bpfman   generated CRD (<code>BpfProgram</code>) used to represent the runtime state of loaded   programs.</li> <li>bpfman-agent: The agent runs in a container in the bpfman daemonset and ensures   that the requested eBPF programs for a given node are in the desired state.</li> <li>bpfman-operator: An operator, built using Operator   SDK, that manages the installation and   lifecycle of bpfman-agent and the CRDs in a Kubernetes cluster.</li> </ul> <p>bpfman is developed in Rust and built on top of Aya, a Rust eBPF library.</p> <p>The benefits of this solution include the following:</p> <ul> <li>Security:<ul> <li>Improved security because only the bpfman daemon, which can be tightly   controlled, has the privileges needed to load eBPF programs, while access   to the API can be controlled via standard RBAC methods. Within bpfman, only   a single thread keeps these capabilities while the other threads (serving   RPCs) do not.</li> <li>Gives the administrators control over who can load programs.</li> <li>Allows administrators to define rules for the ordering of networking eBPF   programs. (ROADMAP)</li> </ul> </li> <li>Visibility/Debuggability:<ul> <li>Improved visibility into what eBPF programs are running on a system, which   enhances the debuggability for developers, administrators, and customer   support.</li> <li>The greatest benefit is achieved when all apps use bpfman, but even if they   don't, bpfman can provide visibility into all the eBPF programs loaded on   the nodes in a cluster.</li> </ul> </li> <li>Multi-program Support:<ul> <li>Support for the coexistence of multiple eBPF programs from multiple users.</li> <li>Uses the libxdp multiprog   protocol   to allow multiple XDP programs on single interface</li> <li>This same protocol is also supported for TC programs to provide a common   multi-program user experience across both TC and XDP.</li> </ul> </li> <li>Productivity:<ul> <li>Simplifies the deployment and lifecycle management of eBPF programs in a   Kubernetes cluster.</li> <li>Developers can stop worrying about program lifecycle (loading, attaching,   pin management, etc.) and use existing eBPF libraries to interact with   their program maps using well defined pin points which are managed by   bpfman.</li> <li>Developers can still use Cilium/libbpf/Aya/etc libraries for eBPF   development, and load/unload with bpfman.</li> <li>Provides eBPF Bytecode Image Specifications that allows fine-grained   separate versioning control for userspace and kernelspace programs. This   also allows for signing these container images to verify bytecode   ownership.</li> </ul> </li> </ul> <p>For more details, please see the following:</p> <ul> <li>bpfman Overview for an overview of bpfman.</li> <li>Quick Start for a quick installation of bpfman without having to download or   build the code from source.   Good for just getting familiar with bpfman and playing around with it.</li> <li>Deploying Example eBPF Programs On Local Host   for some examples of running <code>bpfman</code> on local host and using the CLI to install   eBPF programs on the host.</li> <li>Deploying Example eBPF Programs On Kubernetes   for some examples of deploying eBPF programs through <code>bpfman</code> in a Kubernetes deployment.</li> <li>Setup and Building bpfman for instructions   on setting up your development environment and building bpfman.</li> <li>Example eBPF Programs for some examples of   eBPF programs written in Go, interacting with <code>bpfman</code>.</li> <li>Deploying the bpfman-operator for   details on launching bpfman in a Kubernetes cluster.</li> <li>Meet the Community for details on community   meeting details.</li> </ul> <p> We are a Cloud Native Computing Foundation sandbox project. </p>"},{"location":"quick-start/","title":"Quick Start","text":"<p>This section describes how to deploy <code>bpfman</code> quickly from pre-built release artifacts.  Users can either deploy it locally via provided RPMs or in a kubernetes cluster via the provided container images and install yamls. See Releases for the complete set of bpfman releases.</p>"},{"location":"quick-start/#deploy-released-rpm-from-copr-locally","title":"Deploy Released RPM from COPR Locally","text":"<p>This section describes how to install an RPM built automatically by the Packit Service. The Packit Service builds RPMs for each release.</p> <p>To install an RPM generated by the Packit Service, the following packages need to be installed:</p> <p><code>dnf</code> based OS:</p> <pre><code>sudo dnf install -y dnf-plugins-core\n</code></pre> <p>Additionally the bpfman copr repo needs to be enabled:</p> <pre><code>sudo dnf copr enable @ebpf-sig/bpfman\n</code></pre> <p>To see information about the latest released version of bpfman simply run</p> <pre><code>sudo dnf info bpfman\n\nLast metadata expiration check: 0:03:10 ago on Mon 06 May 2024 10:37:37 AM EDT.\nAvailable Packages\nName         : bpfman\nVersion      : 0.4.2\nRelease      : 1.fc39\nArchitecture : src\nSize         : 41 M\nSource       : None\nRepository   : copr:copr.fedorainfracloud.org:group_ebpf-sig:bpfman\nSummary      : An eBPF program manager\nURL          : https://bpfman.io\nLicense      : Apache-2.0\nDescription  : An eBPF Program Manager.\n\nName         : bpfman\nVersion      : 0.4.2\nRelease      : 1.fc39\nArchitecture : x86_64\nSize         : 9.7 M\nSource       : bpfman-0.4.2-1.fc39.src.rpm\nRepository   : copr:copr.fedorainfracloud.org:group_ebpf-sig:bpfman\nSummary      : An eBPF program manager\nURL          : https://bpfman.io\nLicense      : Apache-2.0 AND Unicode-DFS-2016 AND BSD-3-Clause AND ISC AND MIT AND MPL-2.0\nDescription  : An eBPF Program Manager.\n</code></pre> <p>Next install, either the latest version with:</p> <pre><code>sudo dnf install bpfman \n</code></pre> <p>Or install an older version with:</p> <pre><code>sudo dnf install bpfman-&lt;RELEASE_VERSION&gt; \n</code></pre> <p><code>bpfman</code> is now installed but not running. To start the <code>bpfman-rpc</code> server process:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable bpfman.socket\nsudo systemctl start bpfman.socket\n</code></pre> <p>Finally you can load and attach one of the sample applications:</p> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/tracepoint:latest --application my_tracepoint \\\n     --programs tracepoint:enter_openat\n Bpfman State\n ---------------\n Name:          enter_openat\n Program Type:  tracepoint\n Image URL:     quay.io/bpfman-bytecode/tracepoint:latest\n Pull Policy:   IfNotPresent\n Global:        None\n Metadata:      bpfman_application=my_tracepoint\n Map Pin Path:  /run/bpfman/fs/maps/63433\n Map Owner ID:  None\n Maps Used By:  63433\n Links:         None\n\n Kernel State\n ----------------------------------\n Program ID:                       63433\n BPF Function:                     enter_openat\n Kernel Type:                      tracepoint\n Loaded At:                        2025-03-12T13:02:29-0400\n Tag:                              9b2c38d37350bfff\n GPL Compatible:                   true\n Map IDs:                          [20081]\n BTF ID:                           30286\n Size Translated (bytes):          96\n JITted:                           true\n Size JITted:                      72\n Kernel Allocated Memory (bytes):  4096\n Verified Instruction Count:       9\n</code></pre> <pre><code>sudo bpfman attach 63433 tracepoint --tracepoint syscalls/sys_enter_openat\n Bpfman State\n ---------------\n BPF Function:  enter_openat\n Program Type:  tracepoint\n Program ID:    63433\n Link ID:       456579923\n Tracepoint:    syscalls/sys_enter_openat\n Metadata:      bpfman_application=my_tracepoint\n</code></pre> <pre><code>sudo bpfman list programs\n Program ID  Application     Type        Function Name  Links\n 63433       my_tracepoint   tracepoint  enter_openat   (1) 456579923\n</code></pre> <pre><code>sudo bpfman unload 63433\n</code></pre> <p>When ready to uninstall, determine the RPM that is currently loaded:</p> <pre><code>$ sudo rpm -qa | grep bpfman\nbpfman-0.4.2-1.fc39.x86_64\n</code></pre> <p>To stop bpfman and uninstall the RPM:</p> <pre><code>sudo systemctl stop bpfman.socket\nsudo systemctl disable bpfman.socket\n\nsudo dnf erase -y bpfman-0.4.2-1.fc39.x86_64\n\nsudo systemctl daemon-reload\n</code></pre>"},{"location":"quick-start/#deploy-released-container-images-on-kubernetes","title":"Deploy Released Container Images on Kubernetes","text":"<p>The quickest solution for running <code>bpfman</code> in a Kubernetes deployment is to run a local Kubernetes KIND Cluster:</p> <p>Note</p> <p>OpenShift has tighter security requirements and requires additional settings. When deploying bpfman on OpenShift, use the <code>OperatorHub</code> from the OpenShift console, search for <code>ebpf</code>, and install either the <code>Bpfman Operator by Community</code> or the <code>eBPF Manager Operator by Red Hat</code>. The <code>Bpfman Operator by Community</code> tracks the upstream releases of bpfman. The <code>eBPF Manager Operator by Red Hat</code> is based on bpfman at the time of the corresponding OpenShift release.</p> <pre><code>kind create cluster --name=test-bpfman\n</code></pre> <p>Next, deploy the bpfman CRDs:</p> <pre><code>export BPFMAN_REL=0.5.6\nkubectl apply -f https://github.com/bpfman/bpfman-operator/releases/download/v${BPFMAN_REL}/bpfman-crds-install.yaml\n</code></pre> <p>Next, deploy the <code>bpfman-operator</code>, which will also deploy the <code>bpfman-daemon</code>, which contains <code>bpfman-rpc</code>, <code>bpfman</code> Library and <code>bpfman-agent</code>:</p> <pre><code>kubectl apply -f https://github.com/bpfman/bpfman-operator/releases/download/v${BPFMAN_REL}/bpfman-operator-install.yaml\n</code></pre> <p>Finally, deploy an example eBPF program:</p> <pre><code>kubectl apply -f https://github.com/bpfman/bpfman/releases/download/v${BPFMAN_REL}/go-xdp-counter-install.yaml\n\nkubectl get clusterbpfapplications\nNAME                     NODESELECTOR   STATUS    AGE\ngo-xdp-counter-example                  Success   21s\n\nkubectl get clusterbpfapplicationstates\nNAME                              NODE                              STATUS    AGE\ngo-xdp-counter-example-317f95f7   bpfman-deployment-control-plane   Success   101s\n</code></pre> <p>There are other example program install yamls in the artifacts for each Release payload.</p> <p>Use the following command to teardown the cluster:</p> <pre><code>kind delete cluster -n test-bpfman\n</code></pre>"},{"location":"blog/","title":"Bpfman Blog","text":""},{"location":"blog/2023/11/25/a-new-logo-using-generative-ai-of-course/","title":"A New Logo: Using Generative AI, of course","text":"<p>Since we renamed the project to <code>bpfman</code> we are in need of a new logo. Given that the tech buzz around Generative AI is infectious, we decided to explore using generative AI to create our new logo. What we found was that it was a great way to generate ideas, but a human (me) was still needed to create the final design.</p>"},{"location":"blog/2023/11/25/a-new-logo-using-generative-ai-of-course/#the-brief","title":"The Brief","text":"<p>I have a love of open source projects with animal mascots, so bpfman should be no different. The \"bee\" is used a lot for eBPF related projects. One such example is Crabby, the crab/bee hybrid, that I created for the Aya project.</p> <p>The logo should be cute and playful, but not too childish. As a nod to Podman, we'd like to use the same typeface and split color-scheme as they do, replacing purple with yellow.</p> <p>One bee is not enough! Since we're an eBPF manager, we need a more bees!</p> <p>via GIPHY</p> <p>And since those bees are bee-ing (sorry) managed, they should be organized. Maybe in a pyramid shape?</p>"},{"location":"blog/2023/11/25/a-new-logo-using-generative-ai-of-course/#the-process","title":"The Process","text":"<p>We used Bing Image Creator, which is backed by DALL-E 3.</p> <p>Initially we tried to use the following prompt:</p> <p>Logo for open source software project called \"bpfman\". \"bpf\" should be yellow and \"man\" should be black or grey. an illustration of some organized bees above the text. cute. playful</p> <p>Our AI overlords came up with:</p> <p></p> <p>Not bad, but not quite what we were looking for. It's clear that as smart as AI is, it struggles with text, so whatever we need will need some manual post-processing. There are bees, if you squint a bit, but they're not very organized. Let's refine our prompt a bit:</p> <p>Logo for open source software project called \"bpfman\" as one word. The \"bpf\" should be yellow and \"man\" should be black or grey. an illustration of some organized bees above the text. cute. playful.</p> <p></p> <p>That... is worse.</p> <p>Let's try again:</p> <p>Logo for a project called \"bpfman\". In the text \"bpfman\", \"bpf\" should be yellow and \"man\" should be black or grey. add an illustration of some organized bees above the text. cute and playful style.</p> <p></p> <p>The bottom left one is pretty good! So I shared it with the rest of the maintainers to see what they thought.</p> <p>At this point the feedback that I got was the bees were too cute! We're a manager, and managers are serious business, so we need serious bees.</p> <p>Prompting the AI for the whole logo was far too ambitious, so I decided I would just use the AI to generate the bees and then I would add the text myself.</p> <p>I tried a few different prompts, but the one that worked best was:</p> <p>3 bees guarding a hive. stern expressions. simple vector style.</p> <p></p> <p>The bottom right was exactly what I had in mind! With a little bit of post-processing, I ended up with this:</p> <p></p> <p>Now it was time to solicit some feedback.</p>"},{"location":"blog/2023/11/25/a-new-logo-using-generative-ai-of-course/#gathering-feedback","title":"Gathering Feedback","text":"<p>After showing the logo to a few others, we decided that the bees were infact too stern. At this point we had a few options, like reverting back to our cute bees, however, this section in the [Bing Image Creator Terms of Service] was pointed out to me:</p> <p>Use of Creations. Subject to your compliance with this Agreement, the Microsoft Services Agreement, and our Content Policy, you may use Creations outside of the Online Services for any legal personal, non-commercial purpose.</p> <p>This means that we can't use the AI generated images for our logo.</p>"},{"location":"blog/2023/11/25/a-new-logo-using-generative-ai-of-course/#was-it-all-for-nothing","title":"Was it all for nothing?","text":"<p>Was it all for nothing? No! We learnt a lot from this process.</p> <p>Generative AI is great for generating ideas. Some of the logo compositions produced were great!</p> <p>It was also very useful to adjust the prompt based on feedback from team members so we could incorporate their ideas into the design.</p> <p>We also learnt that the AI is not great at text, so we should avoid using it for that.</p> <p>And finally, we learnt that we can't use the AI generated images for our logo. Well, not with the generator we used anyway.</p>"},{"location":"blog/2023/11/25/a-new-logo-using-generative-ai-of-course/#the-semi-final-design-process","title":"The (Semi) Final Design Process","text":"<p>I started from scratch, taking inspiration from the AI generated images. The bees were drawn first and composed around a hive - as our AI overlords suggested. I then added the text, and colours, but it still felt like it was missing something.</p> <p>What if we added a force field around the hive? That might be cool! And so, I added a force field around the hive and played around with the colours until I was happy.</p> <p>Here's what we ended up with:</p> <p></p> <p>We consulted a few more people and got some feedback. The general consensus was that the logo was too busy... However, the reception to the force field was that the favicon I'd mocked would work better as the logo.</p>"},{"location":"blog/2023/11/25/a-new-logo-using-generative-ai-of-course/#the-final-design","title":"The Final Design","text":"<p>Here's the final design:</p> <p></p> <p>Pretty cool, right? Even if I do say so myself.</p> <p>Our mascot is a queen bee, because she's the manager of the hive.</p> <p>The force field, is now no longer a force field - It's a pheramone cloud that represents the Queen Mandibular Pheromone (QMP) that the queen bee produces to keep the hive organized.</p>"},{"location":"blog/2023/11/25/a-new-logo-using-generative-ai-of-course/#conclusion","title":"Conclusion","text":"<p>I'm really happy with the result! I'm not a designer, so I'm sure there are things that could be improved, but I think it's a good start.</p> <p>What do you think? Join us on Slack and let us know!</p>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/","title":"bpfman's Integration with the AF_XDP Device Plugin and CNI for Kubernetes","text":"<p>AF_XDP is an address/socket family that is optimized for high performance packet processing. It takes advantage of XDP (an in Kernel fastpath), which essentially runs an eBPF program as early as possible on a network driver's receive path, and redirects the packet to an AF_XDP socket.</p> <p></p> <p>AF_XDP sockets (XSKs) are created in Userspace and have a 1:1 mapping with netdev queues. An XSKMAP is an eBPF map of AF_XDP sockets for a particular netdev. It's a simple key:value map where the key is the netdev's queue-id and the value is the AF_XDP socket that's attached to that queue. The eBPF program (at the XDP hook) will leverage the XSKMAP and the XDP_REDIRECT action to redirect packets to an AF_XDP socket. In the image below the XDP program is redirecting an incoming packet to the XSK attached to Queue 2.</p> <p>NOTE: If no XSK is attached to a queue, the XDP program will simply pass the packet to the Kernel Network Stack.</p> <pre><code>+---------------------------------------------------+\n|     XSK A      |     XSK B       |      XSK C     |&lt;---+  Userspace\n=========================================================|==========\n|    Queue 0     |     Queue 1     |     Queue 2    |    |  Kernel space\n+---------------------------------------------------+    |\n|                  Netdev eth0                      |    |\n+---------------------------------------------------+    |\n|                            +=============+        |    |\n|                            | key |  xsk  |        |    |\n|  +---------+               +=============+        |    |\n|  |         |               |  0  | xsk A |        |    |\n|  |         |               +-------------+        |    |\n|  |         |               |  1  | xsk B |        |    |\n|  | BPF     |               +-------------+        |    |\n|  | prog    |-- redirect --&gt;|  2  | xsk C |-------------+\n|  | (XDP    |               +-------------+        |\n|  |  HOOK)  |                   xskmap             |\n|  |         |                                      |\n|  +---------+                                      |\n|                                                   |\n+---------------------------------------------------+\n</code></pre> <p>The AF_XDP Device Plugin and CNI project provides the Kubernetes components to provision, advertise and manage AF_XDP networking devices for Kubernetes pods. These networking devices are typically used as a Secondary networking interface for a pod. A key goal of this project is to enable pods to run without any special privileges, without it pods that wish to use AF_XDP will need to run with elevated privileges in order to manage the eBPF program on the interface. The infrastructure will have little to no control over what these pods can load. Therefore it's ideal to leverage a central/infrastructure centric eBPF program management approach.  This blog will discuss the eBPF program management journey for the AF_XDP Device Plugin and CNI.</p>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#what-does-the-af_xdp-device-plugin-and-cni-do","title":"What does the AF_XDP Device Plugin and CNI do?","text":"<p>For pods to create and use AF_XDP sockets on their interfaces, they can either:</p> <ol> <li>Create the AF_XDP socket on an interface already plumbed to the Pod (via SR-IOV    Device Plugin and the Host CNI) --&gt; But this requires CAP_BPF or CAP_SYS_ADMIN    privileges in order to load the BPF program on the netdev.</li> </ol> <p>OR</p> <ol> <li> <p>Use the AF_XDP Device Plugin (DP) and CNI in order to support a Pod without the    aforementioned root like privileges.</p> <p>NOTE: Prior to kernel 5.19, all BPF sys calls required CAP_BPF, which are used to access maps shared between the BPF program and the userspace program. In kernel 5.19, a change went in that only requires CAP_BPF for map creation (BPF_MAP_CREATE) and loading programs (BPF_PROG_LOAD).</p> <p>In this scenario, the <code>AF_XDP DP</code>, will advertise resource pools (of netdevs) to <code>Kubelet</code>. When a Pod requests a resource from these pools, <code>Kubelet</code> will <code>Allocate()</code> one of these devices through the <code>AF_XDP DP</code>. The <code>AF_XDP DP</code> will load the eBPF program (to redirect packets to an AF_XDP socket) on the allocated device.</p> <p>The default behaviour of the <code>AF_XDP DP</code> (unless otherwise configured) is to take note of the XSKMAP File Descriptor (FD) for that netdev. It will also mount a Unix Domain Socket (UDS), as a hostpath mount, in the Pod. This UDS will be used by the AF_XDP application to perform a handshake with the <code>AF_XDP DP</code> to retrieve the XSKMAP FD. The application needs the XSKMAP FD to \"attach\" AF_XDP sockets it creates to the netdev queues.</p> <p>NOTE: Newer versions of the <code>AF_XDP DP</code> support eBPF map pinning which eliminate the need to perform this (non trivial) handshake with AF_XDP pods. It now mounts the pinned XSKMAP into the Pod using a hostpath mount. The downside of this approach is that the <code>AF_XDP DP</code> now needs to manage several eBPF File Systems (BPFFS), one per pod.</p> <p>The <code>AF_XDP CNI</code> (like any CNI) has the task of moving the netdev (with the loaded eBPF program) into the Pod namespace. It also does a few other important things:</p> <ul> <li>It does not rename the netdev (to allow the DP to avoid IF_INDEX clashes as it manages      the AF_XDP resource pools).</li> <li>The CNI is also capable of configuring hardware filters on the NIC.</li> <li>Finally, the CNI also unloads the eBPF program from the netdev and clear any hardware     filters when the Pod is terminated.</li> </ul> <p>NOTE 1: The <code>AF_XDP CNI</code> manages the unloading of the eBPF program due to the <code>AF_XDP DP</code> not being aware of when a pod terminates (it's only invoked by <code>Kubelet</code> during pod creation).</p> <p>NOTE 2: Prior to bpfman integration, the CNI was extended to signal the AF_XDP DP on pod termination (via gRPC) in an effort to support eBPF map pinning directly in the AF_XDP DP. The AF_XDP DP was managing BPFFS(es) for map pinning and needed to be signalled to clean them up.</p> </li> </ol>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#bpfman-integration","title":"bpfman Integration","text":"<p>Prior to bpfman integration the AF_XDP Device Plugin and CNI managed the eBPF program for redirecting incoming packets to AF_XDP sockets, its associated map (XSKMAP), and/or several BPFFS.</p>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#integration-benefits","title":"Integration benefits","text":"<p>So what are the benefits of bpfman integration for the AF_XDP DP and CNI?</p> <ul> <li> <p>Removes code for loading and managing eBPF from the AF_XDP DP and CNI codebase.</p> </li> <li> <p>This presented a difficulty particularly when trying to find/update appropriate     base container images to use for the AF_XDP device plugin. Different images     supported different versions of eBPF management libraries (i.e libbpf or libxdp) which     forced multiple changes around the loading and attaching of the base eBPF program.</p> </li> <li> <p>Additionally the CNI runs as a binary on the Kubernetes node so we would need to     statically compile libbpf/libxdp as part of the CNI.</p> </li> <li> <p>More diverse XDP program support through bpfman's eBPF Bytecode Image Specification. Not   only do the AF_XDP eBPF programs no longer need to be stored in the Device Plugin   itself, but it's now configurable on a per pool basis.</p> </li> <li> <p>No longer required to leverage Hostpath volume mounts to mount the AF_XDP maps inside   a Pod. But rather take advantage of the bpfman CSI support to ensure that maps are   pinned in the context of the Pod itself and not in a BPFFS on the host (then shared   to the Pod).</p> </li> </ul>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#af_xdp-device-plugin-ebpf-programmap-management","title":"AF_XDP Device Plugin eBPF program/map management","text":"<p>The role of the <code>AF_XDP DP</code> in eBPF program/map management prior to bpfman integration:</p> <ul> <li> <p>Loads the default AF_XDP BPF prog onto the netdev at Pod creation and manages info regarding the XSKMAP for that netdev.</p> </li> <li> <p>Mounts a UDS as a hostpath volume in the Pod OR creates a BPFFS per netdev and pins the   XSKMAP to it, then mounts this BPFFS as a hostpath volume in the Pod.</p> </li> <li> <p>Shares the XSKMAP file descriptor via UDS (involves a handshake with the Pod).</p> </li> </ul> <p>The role of the <code>AF_XDP DP</code> in eBPF program/map management after bpfman integration:</p> <ul> <li> <p>Uses bpfman's client APIs to load the BPF prog.</p> </li> <li> <p>Shares the XSKMAP (that bpfman pinned ) with the Pod as a hostpath volume.</p> </li> </ul>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#af_xdp-cni-ebpf-programmap-management","title":"AF_XDP CNI eBPF program/map management","text":"<p>The role of the <code>AF_XDP CNI</code> in eBPF program/map management prior to bpfman integration:</p> <ul> <li>Unloads the eBPF program when a device is returned to the Host network namespace.</li> </ul> <p>The role of the <code>AF_XDP CNI</code> in eBPF program/map management after bpfman integration:</p> <ul> <li>Uses gRPC to signal to the Device Plugin to request bpfman to unload the eBPF program   using the client APIs.</li> </ul>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#is-there-a-working-example","title":"Is there a working example?","text":"<p>The bpfman integration with the AF_XDP Device Plugin and CNI was demo'ed as part of a series of demos that show the migration of a DPDK application to AF_XDP (without) any application modification. The demo can be watched below:</p> <p></p>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#af_xdp-dp-and-cnis-integration-with-bpfman-in-images","title":"AF_XDP DP and CNI's integration with bpfman in images","text":"<p>The following sections will present the evolution of the AF_XDP DP and CNI from independent eBPF program management to leveraging bpfman to manage eBPF programs on their behalf.</p>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#af_xdp-dp-and-cni-managing-ebpf-programs-independently","title":"AF_XDP DP and CNI managing eBPF programs independently","text":"<p>The following diagram details how the AF_XDP DP and CNI worked prior to bpfman integration.</p> <p></p> <ol> <li> <p>Setup Subfunctions on the network devices (if the are supported/being used).</p> </li> <li> <p>Create an AF_XDP DP and CNI configuration file to setup the device resource pools and    deploy the DP and CNI.</p> </li> <li> <p>When the AF_XDP DP runs it will discover the netdevs on the host and create the resource pools.</p> </li> <li> <p>The AF_XDP DP registers the resource pools with Kubelet.</p> </li> <li> <p>When a pod (that requests an AF_XDP resource) is started, Kubelet will send an <code>Allocate()</code>    request to the AF_XDP DP. The AF_XDP DP loads the eBPF program on the interface and mounts the    UDS in the pod and sets some environment variables in the pod using the Downward API.</p> </li> </ol> <p>NOTE: In the case where eBPF map pinning is used rather than the UDS, the AF_XDP    DP will create a BPFFS where it pins the XSKMAP and mounts the BPFFS as a hostpath volume    in the pod.</p> <ol> <li> <p>The AF_XDP DP signals success to the Kubelet so that the device is added to the pod.</p> </li> <li> <p>Kubelet triggers multus, which in turn triggers the AF_XDP CNI. The CNI does the relevant network    configuration and moves the netdev into the pod network namespace.</p> </li> <li> <p>The application in the pod start and initiates a handshake with the AF_XDP DP over the mounted UDS    to retrieve the XSKMAP FD.</p> </li> </ol>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#af_xdp-dp-and-cni-integrated-with-bpfman-no-csi","title":"AF_XDP DP and CNI integrated with bpfman (no csi)","text":"<p>The following diagram details how the AF_XDP DP and CNI worked after bpfman integration.</p> <p></p> <p>The main difference here is that when the <code>Allocate()</code> request comes in from Kubelet, the AF_XDP DP uses the bpfman client API to load the eBPF program on the relevant netdev. It takes note of where bpfman pins the XSKMAP and mounts this directory as a hostpath volume in the pod.</p>"},{"location":"blog/2024/02/27/bpfmans-integration-with-the-af_xdp-device-plugin-and-cni-for-kubernetes/#af_xdp-dp-and-cni-integrated-with-bpfman-with-csi","title":"AF_XDP DP and CNI integrated with bpfman (with csi)","text":"<p>The following diagram details how the AF_XDP DP and CNI will work with bpfman leveraging the new CSI implementation.</p> <p></p> <p>The pod will include a volume definition as follows:</p> <pre><code>   volumes:\n   - name: bpf-maps\n     csi:\n       driver: csi.bpfman.dev\n       volumeAttributes:\n         csi.bpfman.dev/thru-annotations: true\n</code></pre> <p>The idea here is when the <code>Allocate()</code> request comes in from Kubelet, the AF_XDP DP uses the bpfman client API to load the eBPF program on the relevant netdev. The AF_XDP DP will annotate the pod with the XdpProgram name, map and mountpath. When the bpfman CSI plugin is triggered by Kubelet, it will retrieve the information it needs from the pod annotations in order to pin the map inside the Pod.</p>"},{"location":"blog/2023/11/23/bpfd-becomes-bpfman/","title":"bpfd becomes bpfman","text":"<p>Bpfd is now bpfman! We've renamed the project to better reflect the direction we're taking. We're still the same project, just with a new name.</p>"},{"location":"blog/2023/11/23/bpfd-becomes-bpfman/#why-the-name-change","title":"Why the name change?","text":"<p>We've been using the name <code>bpfd</code> for a while now, but we were not the first to use it. There were projects before us that used the name <code>bpfd</code>, but since most were inactive, originally we didn't see this as an issue.</p> <p>More recently though the folks at Meta have started using the name <code>systemd-bpfd</code> for their proposed addition to systemd.</p> <p>In addition, we've been thinking about the future of the project, and particularly about security and whether it's wise to keep something with <code>CAP_BPF</code> capabilities running as a daemon - even if we've been very careful. This is similar to the issues faced by docker which eventually lead to the creation of podman.</p> <p>This issue led us down the path of redesigning the project to be daemonless. We'll be implementing these changes in the coming months and plan to perform our first release as <code>bpfman</code> in Q1 of 2024.</p> <p>The 'd' in <code>bpfd</code> stood for daemon, so with our new design and the confusion surrounding the name <code>bpfd</code> we though it was time for a change.</p> <p>Since we're a BPF manager, we're now bpfman! It's also a nice homage to podman, which we're big fans of.</p>"},{"location":"blog/2023/11/23/bpfd-becomes-bpfman/#what-does-this-mean-for-me","title":"What does this mean for me?","text":"<p>If you're a developer of <code>bpfman</code> you will need to update your Git remotes to point at our new organization and repository name. Github will redirect these for a while, but we recommend updating your remotes as soon as possible.</p> <p>If you're a user of <code>bpfd</code> or the <code>bpfd-operator</code> then version 0.3.1 will be the last release under the <code>bpfd</code> name. We will continue to support you as best we can, but we recommend upgrading to <code>bpfman</code> as soon as our first release is available.</p>"},{"location":"blog/2023/11/23/bpfd-becomes-bpfman/#whats-next","title":"What's next?","text":"<p>We've hinted at some of the changes we're planning, and of course, our roadmap is always available in Github. It's worth mentioning that we're also planning to expand our release packages to include RPMs and DEBs, making it even easier to install <code>bpfman</code> on your favorite Linux distribution.</p>"},{"location":"blog/2023/11/23/bpfd-becomes-bpfman/#thanks","title":"Thanks!","text":"<p>We'd like to thank everyone who has contributed to <code>bpfd</code> over the years. We're excited about the future of <code>bpfman</code> and we hope you are too! Please bear with us as we make this transition, and if you have any questions or concerns, please reach out to us on Slack. We're in the '#bpfd' channel, but we'll be changing that to '#bpfman' soon.</p>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/","title":"Technical Challenges for Attaching eBPF Programs in Containers","text":"<p>We recently added support for attaching uprobes inside containers. The purpose of this blog is to give a brief overview of the feature, to document the technical challenges encountered, and describe our solutions for those challenges. In particular, how to attach an eBPF program inside of a container, and how to find the host Process ID (PID) on the node for the container?</p> <p>The solutions seem relatively straightforward now that they are done, but we found limited information elsewhere, so we thought it would be helpful to document them here.</p> <p>The uprobe implementation will be used as the example in this blog, but the concepts can (and will eventually) be applied to other program types.</p>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#introduction","title":"Introduction","text":"<p>A \"uprobe\" (user probe) is a type of eBPF program that can be attached to a specific location in a user-space application. This allows developers and system administrators to dynamically instrument a user-space binary to inspect its behavior, measure performance, or debug issues without modifying the application's source code or binary. When the program execution reaches the location to which the uprobe is attached, the eBPF program associated with the uprobe is executed.</p> <p>bpfman support for uprobes has existed for some time.  We recently extended this support to allow users to attach uprobes inside of containers both in the general case of a container running on a Linux server and also for containers running in a Kubernetes cluster.</p> <p>The following is a bpfman command line example for loading a uprobe inside a container:</p> <pre><code>bpfman load image --image-url quay.io/bpfman-bytecode/uprobe:latest uprobe --fn-name \"malloc\" --target \"libc\" --container-pid 102745\n</code></pre> <p>The above command instructs bpfman to attach a uprobe to the <code>malloc</code> function in the <code>libc</code> library for the container with PID 102745. The main addition here is the ability to specify a <code>container-pid</code>, which is the PID of the container as it is known to the host server.</p> <p>The term \"target\" as used in the above bpfman command (and the CRD below) describes the library or executable that we want to attach the uprobe to.  The fn-name (the name of the function within that target) and/or an explicit \"offset\" can be used to identify a specific offset from the beginning of the target.  We also use the term \"target\" more generally to describe the intended location of the uprobe.</p> <p>For Kubernetes, the CRD has been extended to include a \"container selector\" to describe one or more containers as shown in the following example.</p> <pre><code>apiVersion: bpfman.io/v1alpha1\nkind: UprobeProgram\nmetadata:\n  labels:\n    app.kubernetes.io/name: uprobeprogram\n  name: uprobe-example-containers\nspec:\n  # Select all nodes\n  nodeselector: {}\n  bpffunctionname: my_uprobe\n  func_name: malloc\n  # offset: 0 # optional offset w/in function\n  target: libc\n  retprobe: false\n  # pid: 0 # optional pid to execute uprobe for\n  bytecode:\n    image:\n      url: quay.io/bpfman-bytecode/uprobe:latest\n  containers:      &lt;=== New section for specifying containers to attach uprobe to\n    namespace: bpfman\n    pods:\n      matchLabels:\n        name: bpfman-daemon\n    containernames:\n      - bpfman\n      - bpfman-agent\n</code></pre> <p>In the Kubernetes case, the container selector (<code>containers</code>) is used to identify one or more containers in which to attach the uprobe. If <code>containers</code> identifies any containers on a given node, the bpfman agent on that node will determine their host PIDs and make the calls to bpfman to attach the uprobes.</p>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#attaching-uprobes-in-containers","title":"Attaching uprobes in containers","text":"<p>A Linux \"mount namespace\" is a feature that isolates the mount points seen by a group of processes. This means that processes in different mount namespaces can have different views of the filesystem.  A container typically has its own mount namespace that is isolated both from those of other containers and its parent. Because of this, files that are visible in one container are likely not visible to other containers or even to the parent host (at least not directly). To attach a uprobe to a file in a container, we need to have access to that container's mount namespace so we can see the file to which the uprobe needs to be attached.</p> <p>From a high level, attaching a uprobe to an executable or library in a container is relatively straight forward. <code>bpfman</code> needs to change to the mount namespace of the container, attach the uprobe to the target in that container, and then return to our own mount namespace so that we can save the needed state and continue processing other requests.</p> <p>The main challenges are:</p> <ol> <li>Changing to the mount namespace of the target container.</li> <li>Returning to the bpfman mount namespace.</li> <li><code>setns</code> (at least for the mount namespace) can't be called from a    multi-threaded application, and bpfman is currently multithreaded.</li> <li>How to find the right PID for the target container.</li> </ol>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#the-mount-namespace","title":"The Mount Namespace","text":"<p>To enter the container namespace, <code>bpfman</code> uses the sched::setns function from the Rust nix crate. The <code>setns</code> function requires the file descriptor for the mount namespace of the target container.</p> <p>For a given container PID, the namespace file needed by the <code>setns</code> function can be found in the <code>/proc/&lt;PID&gt;/ns/</code> directory. An example listing for the PID 102745 directory is shown below:</p> <pre><code>sudo ls -l /proc/102745/ns/\ntotal 0\nlrwxrwxrwx 1 root root 0 Feb 15 12:10 cgroup -&gt; 'cgroup:[4026531835]'\nlrwxrwxrwx 1 root root 0 Feb 15 12:10 ipc -&gt; 'ipc:[4026532858]'\nlrwxrwxrwx 1 root root 0 Feb 15 12:10 mnt -&gt; 'mnt:[4026532856]'\nlrwxrwxrwx 1 root root 0 Feb 15 12:07 net -&gt; 'net:[4026532860]'\nlrwxrwxrwx 1 root root 0 Feb 15 12:10 pid -&gt; 'pid:[4026532859]'\nlrwxrwxrwx 1 root root 0 Feb 15 12:10 pid_for_children -&gt; 'pid:[4026532859]'\nlrwxrwxrwx 1 root root 0 Feb 15 12:10 time -&gt; 'time:[4026531834]'\nlrwxrwxrwx 1 root root 0 Feb 15 12:10 time_for_children -&gt; 'time:[4026531834]'\nlrwxrwxrwx 1 root root 0 Feb 15 12:10 user -&gt; 'user:[4026531837]'\nlrwxrwxrwx 1 root root 0 Feb 15 12:10 uts -&gt; 'uts:[4026532857]'\n</code></pre> <p>In this case, the mount namespace file is <code>/proc/102745/ns/mnt</code>. </p> <p>NOTE: How to find the PID and the relationship between parent and child PIDs is described in the \"Finding The PID\" section below.</p> <p>When running directly on a Linux server, <code>bpfman</code> has access to the host <code>/proc</code> directory and can access the mount namespace file for any PID.  However, on Kubernetes, <code>bpfman</code> runs in a container, so it doesn't have access to the namespace files of other containers or the <code>/proc</code> directory of the host by default. Therefore, in the Kubernetes implementation, <code>/proc</code> is mounted in the <code>bpfman</code> container so it has access to the ns directories of other containers. </p>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#returning-to-the-bpfman-mount-namespace","title":"Returning to the <code>bpfman</code> Mount Namespace","text":"<p>After <code>bpfman</code> does a <code>setns</code> to the target container mount namespace, it has access to the target binary in that container.  However, it only has access to that container's view of the filesystem, and in most cases, this does not include access to bpfman's filesystem or the host filesystem.  As a result, bpfman loses the ability to access its own mount namespace file.</p> <p>However, before calling setns, <code>bpfman</code> has access to it's own mount namespace file.  Therefore, to avoid getting stranded in a different mount namespace, <code>bpfman</code> also opens its own mount namespace file prior to calling <code>setns</code> so it already has the file descriptor that will allow it to call <code>setns</code> to return to its own mount namespace.</p>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#running-setns-from-a-multi-threaded-process","title":"Running <code>setns</code> From a Multi-threaded Process","text":"<p>Calling <code>setns</code> to a mount namespace doesn't work from a multi-threaded process.</p> <p>To work around this issue, the logic was moved to a standalone single-threaded executable called bpfman-ns that does the job of entering the namespace, attaching the uprobe, and then returning to the bpfman namespace to save the needed info.</p>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#finding-the-pid","title":"Finding the PID","text":""},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#finding-a-host-container-pid-on-a-linux-server","title":"Finding a Host Container PID on a Linux Server","text":"<p>This section provides an overview of PID namespaces and shows several ways to find the host PID for a container.</p>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#tldr","title":"tl;dr","text":"<p>If you used Podman or Docker to run your container, and you gave the container a unique name, the following commands can be used to find the host PID of a container.</p> <pre><code>podman inspect -f '{{.State.Pid}}' &lt;CONTAINER_NAME&gt;\n</code></pre> <p>or, similarly,</p> <pre><code>docker inspect -f '{{.State.Pid}}'  &lt;CONTAINER_NAME&gt;\n</code></pre>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#overview-of-pid-namespaces-and-container-host-pids","title":"Overview of PID namespaces and Container Host PIDs","text":"<p>Each container has a PID namespace. Each PID namespace (other than the root) is contained within a parent PID namespace. In general, this relationship is hierarchical and PID namespaces can be nested within other PID namespaces. In this section, we will just cover the case of a root PID namepsace on a Linux server that has containers with PID namespaces that are direct children of the root. The multi-level case is described in the section on Nested Containers with kind below.</p> <p>The PID namespaces can be listed using the <code>lsns -t pid</code> command. Before we start any containers, we just have the one root pid namespace as shown below.</p> <pre><code>sudo lsns -t pid\n        NS TYPE NPROCS PID USER COMMAND\n4026531836 pid     325   1 root /usr/lib/systemd/systemd rhgb --switched-root --system --deserialize 30\n</code></pre> <p>Now lets start a container with the following command in a new shell:</p> <pre><code>podman run -it --name=container_1 fedora:latest /bin/bash\n</code></pre> <p>NOTE: In this section, we are using <code>podman</code> to run containers. However, all of the same commands can also be used with <code>docker</code>.</p> <p>Now back on the host we have:</p> <pre><code>sudo lsns -t pid\n        NS TYPE NPROCS    PID USER      COMMAND\n4026531836 pid     337      1 root      /usr/lib/systemd/systemd rhgb --switched-root --system --deserialize 30\n4026532948 pid       1 150342 user_abcd /bin/bash\n</code></pre> <p>We can see that the host PID for the container we just started is 150342.</p> <p>Now let's start another container in a new shell with the same command (except with a different name), and run the <code>lsns</code> command again on the host.</p> <pre><code>podman run -it --name=container_2 fedora:latest /bin/bash\n</code></pre> <p>On the host:</p> <pre><code>sudo lsns -t pid\n        NS TYPE NPROCS    PID USER      COMMAND\n4026531836 pid     339      1 root      /usr/lib/systemd/systemd rhgb --switched-root --system --deserialize 30\n4026532948 pid       1 150342 user_abcd /bin/bash\n4026533041 pid       1 150545 user_abcd /bin/bash\n</code></pre> <p>We now have 3 pid namespaces -- one for root and two for the containers. Since we already know that the first container had PID 150342 we can conclude that the second container has PID 150545. However, what would we do if we didn't already know the PID for one of the containers?  </p> <p>If the container we were interested in was running a unique command, we could use that to disambiguate. However, in this case, both are running the same <code>/bin/bash</code> command.</p> <p>If something unique is running inside of the container, we can use the <code>ps -e -o pidns,pid,args</code> command to get some info.</p> <p>For example, run <code>sleep 1111</code> in <code>container_1</code>, then</p> <pre><code>sudo ps -e -o pidns,pid,args | grep 'sleep 1111'\n4026532948  150778 sleep 1111\n4026531836  151002 grep --color=auto sleep 1111\n</code></pre> <p>This tells us that the <code>sleep 1111</code> command is running in PID namespace 4026532948. And,</p> <pre><code>sudo lsns -t pid | grep 4026532948\n4026532948 pid       2 150342 user_abcd /bin/bash\n</code></pre> <p>Tells us that the container's host PID is 150342.</p> <p>Alternatively, we could run <code>lsns</code> inside of <code>container_1</code>.</p> <pre><code>dnf install -y util-linux\nlsns -t pid\n        NS TYPE NPROCS PID USER COMMAND\n4026532948 pid       2   1 root /bin/bash\n</code></pre> <p>This tells us a few interesting things. </p> <ol> <li>Inside the container, the PID is 1,</li> <li>We can't see any of the other PID namespaces inside the container.</li> <li>The container PID namespace is 4026532948.</li> </ol> <p>With the container PID namespace, we can run the <code>lsns -t pid | grep 4026532948</code> command as we did above to find the container's host PID</p> <p>Finally, the container runtime knows the pid mapping. As mentioned at the beginning of this section, if the unique name of the container is known, the following command can be used to get the host PID.</p> <pre><code>podman inspect -f '{{.State.Pid}}' container_1\n150342\n</code></pre>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#how-bpfman-agent-finds-the-pid-on-kubernetes","title":"How bpfman Agent Finds the PID on Kubernetes","text":"<p>When running on Kubernetes, the \"containers\" field in the UprobeProgram CRD can be used to identify one or more containers using the following information:</p> <ul> <li>Namespace</li> <li>Pod Label</li> <li>Container Name</li> </ul> <p>If the container selector matches any containers on a given node, the <code>bpfman-agent</code> determines the host PID for those containers and then calls <code>bpfman</code> to attach the uprobe in the container with the given PID.</p> <p>From what we can tell, there is no way to find the host PID for a container running in a Kubernetes pod from the Kubernetes interface. However, the container runtime does know this mapping. </p> <p>The <code>bpfman-agent</code> implementation uses multiple steps to find the set of PIDs on a given node (if any) for the containers that are identified by the container selector.</p> <ol> <li>It uses the Kubernetes interface to get a list of pods on the local node that    match the container selector.</li> <li>It uses use crictl with the names of the pods found to get the pod IDs</li> <li>It uses <code>crictl</code> with the pod ID to find the containers in those pods and    then checks whether any match the container selector.</li> <li>Finally, it uses <code>crictl</code> with the pod IDs found to get the host PIDs for the    containers.</li> </ol> <p>As an example, the bpfman.io_v1alpha1_uprobe_uprobeprogram_containers.yaml file can be used with the <code>kubectl apply -f</code> command to install uprobes on two of the containers in the <code>bpfman-agent</code> pod. The bpfman code does this programmatically, but we will step through the process of finding the host PIDs for the two containers here using cli commands to demonstrate how it works.</p> <p>We will use a kind deployment with bpfman for this demo. See Deploy Locally via KIND for instructions on how to get this running.</p> <p>The container selector in the above yaml file is the following.</p> <pre><code>  containers:\n    namespace: bpfman\n    pods:\n      matchLabels:\n        name: bpfman-daemon\n    containernames:\n      - bpfman\n      - bpfman-agent\n</code></pre> <p><code>bpfman</code> accesses the Kubernetes API and uses <code>crictl</code> from the <code>bpfman-agent</code> container. However, the <code>bpfman-agent</code> container doesn't have a shell by default, so we will run the examples from the <code>bpfman-deployment-control-plane</code> node, which will yield the same results. <code>bpfman-deployment-control-plane</code> is a docker container in our kind cluster, so enter the container.</p> <p><pre><code>docker exec -it c84cae77f800 /bin/bash\n</code></pre> Install <code>crictl</code>.</p> <pre><code>apt update\napt install wget\nVERSION=\"v1.28.0\"\nwget https://github.com/kubernetes-sigs/cri-tools/releases/download/$VERSION/crictl-$VERSION-linux-amd64.tar.gz\ntar zxvf crictl-$VERSION-linux-amd64.tar.gz -C /usr/local/bin\nrm -f crictl-$VERSION-linux-amd64.tar.gz\n</code></pre> <p>First use <code>kubectl</code> to get the list of pods that match our container selector.</p> <pre><code>kubectl get pods -n bpfman -l name=bpfman-daemon\nNAME                  READY   STATUS    RESTARTS   AGE\nbpfman-daemon-cv9fm   3/3     Running   0          6m54s\n</code></pre> <p>NOTE: The bpfman code also filters on the local node, but we only have one node in this deployment, so we'll ignore that here.</p> <p>Now, use <code>crictl</code> with the name of the pod found to get the pod ID.</p> <pre><code>crictl pods --name bpfman-daemon-cv9fm\nPOD ID              CREATED             STATE               NAME                  NAMESPACE           ATTEMPT             RUNTIME\ne359900d3eca5       46 minutes ago      Ready               bpfman-daemon-cv9fm   bpfman              0                   (default)\n</code></pre> <p>Now, use the pod ID to get the list of containers in the pod.</p> <pre><code>crictl ps --pod e359900d3eca5\nCONTAINER           IMAGE               CREATED             STATE               NAME                    ATTEMPT             POD ID              POD\n5eb3b4e5b45f8       50013f94a28d1       48 minutes ago      Running             node-driver-registrar   0                   e359900d3eca5       bpfman-daemon-cv9fm\n629172270a384       e507ecf33b1f8       48 minutes ago      Running             bpfman-agent            0                   e359900d3eca5       bpfman-daemon-cv9fm\n6d2420b80ddf0       86a517196f329       48 minutes ago      Running             bpfman                  0                   e359900d3eca5       bpfman-daemon-cv9fm\n</code></pre> <p>Now use the container IDs for the containers identified in the container selector to get the PIDs of the containers.</p> <pre><code># Get PIDs for bpfman-agent container\ncrictl inspect 629172270a384 | grep pid\n    \"pid\": 2158,\n            \"pid\": 1\n            \"type\": \"pid\"\n\n# Get PIDs for bpfman container\ncrictl inspect 6d2420b80ddf0 | grep pid\n    \"pid\": 2108,\n            \"pid\": 1\n            \"type\": \"pid\"\n</code></pre> <p>From the above output, we can tell that the host PID for the <code>bpfman-agent</code> container is 2158, and the host PID for the <code>bpfman</code> container is 2108. So, now <code>bpfman-agent</code> would have the information needed to call <code>bpfman</code> with a request to install a uprobe in the containers.</p>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#nested-containers-with-kind","title":"Nested Containers with kind","text":"<p>kind is a tool for running local Kubernetes clusters using Docker container \u201cnodes\u201d. The kind cluster we used for the previous section had a single node.</p> <pre><code>$ kubectl get nodes\nNAME                              STATUS   ROLES           AGE   VERSION\nbpfman-deployment-control-plane   Ready    control-plane   24h   v1.27.3\n</code></pre> <p>We can see the container for that node on the base server from Docker as follows.</p> <pre><code>docker ps\nCONTAINER ID   IMAGE                  COMMAND                  CREATED        STATUS        PORTS                       NAMES\nc84cae77f800   kindest/node:v1.27.3   \"/usr/local/bin/entr\u2026\"   25 hours ago   Up 25 hours   127.0.0.1:36795-&gt;6443/tcp   bpfman-deployment-control-plane\n</code></pre> <p>Our cluster has a number of pods as shown below.</p> <pre><code>kubectl get pods -A\nNAMESPACE            NAME                                                      READY   STATUS    RESTARTS   AGE\nbpfman               bpfman-daemon-cv9fm                                       3/3     Running   0          24h\nbpfman               bpfman-operator-7f67bc7c57-bpw9v                          2/2     Running   0          24h\nkube-system          coredns-5d78c9869d-7tw9b                                  1/1     Running   0          24h\nkube-system          coredns-5d78c9869d-wxwfn                                  1/1     Running   0          24h\nkube-system          etcd-bpfman-deployment-control-plane                      1/1     Running   0          24h\nkube-system          kindnet-lbzw4                                             1/1     Running   0          24h\nkube-system          kube-apiserver-bpfman-deployment-control-plane            1/1     Running   0          24h\nkube-system          kube-controller-manager-bpfman-deployment-control-plane   1/1     Running   0          24h\nkube-system          kube-proxy-sz8v9                                          1/1     Running   0          24h\nkube-system          kube-scheduler-bpfman-deployment-control-plane            1/1     Running   0          24h\nlocal-path-storage   local-path-provisioner-6bc4bddd6b-22glj                   1/1     Running   0          24h\n</code></pre> <p>Using the <code>lsns</code> command in the node's docker container, we can see that it has a number of PID namespaces (1 for each container that is running in the pods in the cluster), and all of these containers are nested inside of the docker \"node\" container shown above.</p> <p><pre><code>lsns -t pid\n        NS TYPE NPROCS   PID USER  COMMAND\n# Note: 12 rows have been deleted below to save space\n4026532861 pid      17     1 root  /sbin/init\n4026532963 pid       1   509 root  kube-scheduler --authentication-kubeconfig=/etc/kubernetes/scheduler.conf --authorization-kubeconfig=/etc/kubernetes/scheduler.conf --bind-addre\n4026532965 pid       1   535 root  kube-controller-manager --allocate-node-cidrs=true --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf --authorization-kubeconfi\n4026532967 pid       1   606 root  kube-apiserver --advertise-address=172.18.0.2 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt\n4026532969 pid       1   670 root  etcd --advertise-client-urls=https://172.18.0.2:2379 --cert-file=/etc/kubernetes/pki/etcd/server.crt --client-cert-auth=true --data-dir=/var/lib\n4026532972 pid       1  1558 root  local-path-provisioner --debug start --helper-image docker.io/kindest/local-path-helper:v20230510-486859a6 --config /etc/config/config.json\n4026533071 pid       1   957 root  /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/config.conf --hostname-override=bpfman-deployment-control-plane\n4026533073 pid       1  1047 root  /bin/kindnetd\n4026533229 pid       1  1382 root  /coredns -conf /etc/coredns/Corefile\n4026533312 pid       1  1896 65532 /usr/local/bin/kube-rbac-proxy --secure-listen-address=0.0.0.0:8443 --upstream=http://127.0.0.1:8174/ --logtostderr=true --v=0\n4026533314 pid       1  1943 65532 /bpfman-operator --health-probe-bind-address=:8175 --metrics-bind-address=127.0.0.1:8174 --leader-elect\n4026533319 pid       1  2108 root  ./bpfman system service --timeout=0 --csi-support\n4026533321 pid       1  2158 root  /bpfman-agent --health-probe-bind-address=:8175 --metrics-bind-address=127.0.0.1:8174\n4026533323 pid       1  2243 root  /csi-node-driver-registrar --v=5 --csi-address=/csi/csi.sock --kubelet-registration-path=/var/lib/kubelet/plugins/csi-bpfman/csi.sock\n</code></pre> We can see the bpfman containers we were looking at earlier in the output above. Let's take a deeper look at the <code>bpfman-agent</code> container that has a PID of 2158 on the Kubernetes node container and a PID namespace of 4026533321. If we go back to the base server, we can find the container's PID there.</p> <pre><code>sudo lsns -t pid | grep 4026533321\n4026533321 pid       1 222225 root  /bpfman-agent --health-probe-bind-address=:8175 --metrics-bind-address=127.0.0.1:8174\n</code></pre> <p>This command tells us that the PID of our <code>bpfman-agent</code> is 222225 on the base server. The information for this PID is contained in <code>/proc/222225</code>.  The following command will show the PID mappings for that one container at each level.</p> <pre><code>sudo grep NSpid /proc/222225/status\nNSpid:  222225  2158    1\n</code></pre> <p>The output above tells us that the PIDs for the <code>bpfman-agent</code> container are 222225 on the base server, 2158 in the Docker \"node\" container, and 1 inside the container itself.</p>"},{"location":"blog/2024/02/26/technical-challenges-for-attaching-ebpf-programs-in-containers/#moving-forward","title":"Moving Forward","text":"<p>As always, there is more work to do. The highest priority goals are to support additional eBPF program types and to use the Container Runtime Interface directly.</p> <p>We chose uprobes first because we had a user with a specific need. However, there are use cases for other eBPF program types.</p> <p>We used <code>crictl</code> in this first implementation because it already exists, supports multiple container runtimes, handles the corner cases, and is maintained. This allowed us to focus on the bpfman implementation and get the feature done more quickly. However, it would be better to access the container runtime interface directly rather than using an external executable.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/","title":"bpfman: A Novel Way to Manage eBPF","text":"<p>In today's cloud ecosystem, there's a demand for low-level system access to enable high-performance observability, security, and networking functionality for applications. Historically these features have been implemented in user space, however, the ability to program such functionality into the kernel itself can provide many benefits including (but not limited to) performance. Regardless, many Linux users still opt away from in-tree or kernel module development due to the slow rate of iteration and ensuing large management burden.  eBPF has emerged as a technology in the Linux Kernel looking to change all that.</p> <p>eBPF is a simple and efficient way to dynamically load programs into the kernel at runtime, with safety and performance provided by the kernel itself using a Just-In-Time (JIT) compiler and verification process. There are a wide variety of program types one can create with eBPF, which include everything from networking applications to security systems.</p> <p>However, eBPF is still a fairly nascent technology and it's not all kittens and rainbows. The process of developing, testing, deploying, and maintaining eBPF programs is not a road well traveled yet, and the story gets even more complicated when you want to deploy your programs in a multi-node system, such as a Kubernetes cluster. It was these kinds of problems that motivated the creation of bpfman, a system daemon for loading and managing eBPF programs in both traditional systems and Kubernetes clusters. In this blog post, we'll discuss the problems bpfman can help solve, and how to deploy and use it.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#current-challenges-with-developing-and-deploying-ebpf-programs","title":"Current Challenges with Developing and Deploying eBPF Programs","text":"<p>While some organizations have had success developing, deploying, and maintaining production software which includes eBPF programs, the barrier to entry is still very high.</p> <p>Following the basic eBPF development workflow, which often involves many hours trying to interpret and fix mind-bending eBPF verifier errors, the process of deploying a program in testing and staging environments often results in a lot of custom program loading and management functionality specific to the application. When moving to production systems in environments like Kubernetes clusters the operational considerations continue to compound.</p> <p>Security is another significant challenge, which we will cover in more depth in a follow-on blog.  However, at a high level, applications that use eBPF typically load their own eBPF programs, which requires at least CAP_BPF.  Many BPF programs and attach points require additional capabilities from CAP_SYS_PTRACE, CAP_NET_ADMIN and even including CAP_SYS_ADMIN.  These privileges include capabilities that aren\u2019t strictly necessary for eBPF and are too coarsely grained to be useful.  Since the processes that load eBPF are usually long-lived and often don\u2019t drop privileges it leaves a wide attack surface.</p> <p>While it doesn't solve all the ergonomic and maintenance problems associated with adopting eBPF, bpfman does try to address several of these issues -- particularly as it pertains to security and the lifecycle management of eBPF programs. In the coming sections, we will go into more depth about what eBPF does, and how it can help reduce the costs associated with deploying and managing eBPF-powered workloads.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#bpfman-overview","title":"bpfman Overview","text":"<p>The bpfman project provides a software stack that makes it easy to manage the full lifecycle of eBPF programs.  In particular, it can load, unload, modify, and monitor eBPF programs on a single host, or across a full Kubernetes cluster. The key components of bpfman include the bpfman daemon itself which can run independently on any Linux box, an accompanying Kubernetes Operator designed to bring first-class support to clusters via Custom Resource Definitions (CRDs), and eBPF program packaging.</p> <p>These components will be covered in more detail in the following sections.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#bpfman-daemon","title":"bpfman Daemon","text":"<p>The bpfman daemon works directly with the operating system to manage eBPF programs.  It loads, updates, and unloads eBPF programs, pins maps, and provides visibility into the eBPF programs loaded on a system.  Currently, bpfman fully supports XDP, TC, Tracepoint, uProbe, and kProbe eBPF programs. In addition, bpfman can display information about all types of eBPF programs loaded on a system whether they were loaded by bpfman or some other mechanism. bpfman is developed in the Rust programming language and uses Aya, an eBPF library which is also developed in Rust.</p> <p>When used on an individual server, bpfman runs as a system daemon, and applications communicate with it using a gRPC API.  bpfman can also be used via a command line which in turn uses the gRPC API. The following is an example of using bpfman to load and attach an xdp program.</p> <pre><code>bpfman load-from-image -g GLOBAL_u8=01 -i quay.io/bpfman-bytecode/xdp_pass:latest xdp -i eth0 -p 100\n</code></pre> <p>This architecture is depicted in the following diagram.</p> <p></p> <p>Using bpfman in this manner significantly improves security because the API is secured using mTLS, and only bpfman needs the privileges required to load and manage eBPF programs and maps.</p> <p>Writing eBPF code is tough enough as it is.  Typically, an eBPF-based application would need to also implement support for the lifecycle management of the required eBPF programs.  bpfman does that for you and allows you to focus on developing your application.</p> <p>Another key functional advantage that bpfman offers over libbpf or the Cilium ebpf-go library is support for multiple XDP programs. Standard XDP only allows a single XDP program on a given interface, while bpfman supports loading multiple XDP programs on each interface using the multi-prog protocol defined in libxdp. This allows the user to add, delete, update, prioritize, and re-prioritize the multiple programs on each interface. There is also support to configure whether the flow of execution should terminate and return or continue to the next program in the list based on the return value.</p> <p>While TC natively supports multiple programs on each attach point, it lacks the controls and flexibility enabled by the multi-prog protocol. bpfman therefore also supports the same XDP multi-prog solution for TC programs which has the added benefit of a consistent user experience for both XDP and TC programs.</p> <p>eBPF programs are also difficult to debug on a system.  The visibility provided by bpfman can be a key tool in understanding what is deployed and how they may interact.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#bpfman-kubernetes-support","title":"bpfman Kubernetes Support","text":"<p>The benefits of bpfman are brought to Kubernetes by the bpfman operator.  The bpfman operator is developed in Go using the Operator SDK framework, so it should be familiar to most Kubernetes application developers. The bpfman operator deploys a daemonset, containing both bpfman and the bpfman agent processes on each node. Rather than making requests directly to bpfman with the gRPC API or CLI as described above, Kubernetes applications use bpfman custom resource definitions (CRDs) to make requests to bpfman to load and attach eBPF programs.  bpfman uses two types of CRDs; Program CRDs for each eBPF program type (referred to as *Program CRDs, where * = Xdp, Tc, etc.) created by the application to express the desired state of an eBPF program on the cluster, and per node BpfProgram CRDs created by the bpfman agent to report the current state of the eBPF program on each node.</p> <p>Using XDP as an example, the application can request that an XDP program be loaded on multiple nodes using the XdpProgram CRD, which includes the necessary information such as the bytecode image to load, interface to attach it to, and priority.  An XdpProgram CRD that would do the same thing as the CLI command shown above on every node in a cluster is shown below.</p> <pre><code>apiVersion: bpfman.io/v1alpha1\nkind: XdpProgram\nmetadata:\n  labels:\n    app.kubernetes.io/name: xdpprogram\n  name: xdp-pass-all-nodes\nspec:\n  name: pass\n  # Select all nodes\n  nodeselector: {}\n  interfaceselector:\n    primarynodeinterface: true\n  priority: 0\n  bytecode:\n    image:\n      url: quay.io/bpfman-bytecode/xdp_pass:latest\n  globaldata:\n    GLOBAL_u8:\n      - 0x01\n</code></pre> <p>The bpfman agent on each node watches for the *Program CRDs, and makes calls to the local instance of bpfman as necessary to ensure that the state on the local node reflects the state requested in the *Program CRD.  The bpfman agent on each node in turn creates and updates a BpfProgram object for the *Program CRD that reflects the state of the program on that node and reports the eBPF map information for the program.  The following is the BpfProgram CRD on one node for the above XdpProgram CRD.</p> <pre><code>kubectl get bpfprograms.bpfman.io xdp-pass-all-nodes-bpfman-deployment-control-plane-eth0 -o yaml\n</code></pre> <pre><code>apiVersion: bpfman.io/v1alpha1\nkind: BpfProgram\nmetadata:\n  annotations:\n    bpfman.io.xdpprogramcontroller/interface: eth0\n  creationTimestamp: \"2023-08-29T22:08:12Z\"\n  finalizers:\n  - bpfman.io.xdpprogramcontroller/finalizer\n  generation: 1\n  labels:\n    bpfman.io/ownedByProgram: xdp-pass-all-nodes\n    kubernetes.io/hostname: bpfman-deployment-control-plane\n  name: xdp-pass-all-nodes-bpfman-deployment-control-plane-eth0\n  ownerReferences:\n  - apiVersion: bpfman.io/v1alpha1\n    blockOwnerDeletion: true\n    controller: true\n    kind: XdpProgram\n    name: xdp-pass-all-nodes\n    uid: 838dc2f8-a348-427e-9dc4-f6a6ea621930\n  resourceVersion: \"2690\"\n  uid: 5a622961-e5b0-44fe-98af-30756b2d0b62\nspec:\n  type: xdp\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-08-29T22:08:14Z\"\n    message: Successfully loaded bpfProgram\n    reason: bpfmanLoaded\n    status: \"True\"\n    type: Loaded\n</code></pre> <p>Finally, the bpfman operator watches for updates to the BpfProgram objects and reports the global state of each eBPF program.  If the program was successfully loaded on every selected node, it will report success, otherwise, it will identify the node(s) that had a problem.  The following is the XdpProgram CRD as updated by the operator.</p> <pre><code>kubectl get xdpprograms.bpfman.io xdp-pass-all-nodes -o yaml\n</code></pre> <pre><code>apiVersion: bpfman.io/v1alpha1\nkind: XdpProgram\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"bpfman.io/v1alpha1\",\"kind\":\"XdpProgram\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/name\":\"xdpprogram\"},\"name\":\"xdp-pass-all-nodes\"},\"spec\":{\"bytecode\":{\"image\":{\"url\":\"quay.io/bpfman-bytecode/xdp_pass:latest\"}},\"globaldata\":{\"GLOBAL_u8\":[1]},\"interfaceselector\":{\"primarynodeinterface\":true},\"nodeselector\":{},\"priority\":0,\"bpffunctionname\":\"pass\"}}\n  creationTimestamp: \"2023-08-29T22:08:12Z\"\n  finalizers:\n  - bpfman.io.operator/finalizer\n  generation: 2\n  labels:\n    app.kubernetes.io/name: xdpprogram\n  name: xdp-pass-all-nodes\n  resourceVersion: \"2685\"\n  uid: 838dc2f8-a348-427e-9dc4-f6a6ea621930\nspec:\n  bytecode:\n    image:\n      imagepullpolicy: IfNotPresent\n      url: quay.io/bpfman-bytecode/xdp_pass:latest\n  globaldata:\n    GLOBAL_u8: 0x01\n  interfaceselector:\n    primarynodeinterface: true\n  mapownerselector: {}\n  nodeselector: {}\n  priority: 0\n  proceedon:\n  - pass\n  - dispatcher_return\n  name: pass\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-08-29T22:08:12Z\"\n    message: Waiting for Program Object to be reconciled to all nodes\n    reason: ProgramsNotYetLoaded\n    status: \"True\"\n    type: NotYetLoaded\n  - lastTransitionTime: \"2023-08-29T22:08:12Z\"\n    message: bpfProgramReconciliation Succeeded on all nodes\n    reason: ReconcileSuccess\n    status: \"True\"\n    type: ReconcileSuccess\n</code></pre> <p>More details about this process can be seen here</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#ebpf-program-packaging","title":"eBPF program packaging","text":"<p>The eBPF Bytecode Image specification was created as part of the bpfman project to define a way to package eBPF bytecode as OCI container images.  Its use was illustrated in the CLI and <code>XdpProgram</code> CRD examples above in which the XDP program was loaded from <code>quay.io/bpfman-bytecode/xdp_pass:latest</code>. The initial motivation for this image spec was to facilitate the deployment of eBPF programs in container orchestration systems such as Kubernetes, where it is necessary to provide a portable way to distribute bytecode to all nodes that need it. However, bytecode images have proven useful on standalone Linux systems as well.  When coupled with BPF CO-RE (Compile Once \u2013 Run Everywhere), portability is further enhanced in that applications can use the same bytecode images across different kernel versions without the need to recompile them for each version. Another benefit of bytecode containers is image signing.  There is currently no way to sign and validate raw eBPF bytecode.  However, the bytecode containers can be signed and validated by bpfman using sigstore to improve supply chain security.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#key-benefits-of-bpfman","title":"Key benefits of bpfman","text":"<p>This section reviews some of the key benefits of bpfman.  These benefits mostly apply to both standalone and Kubernetes deployments, but we will focus on the benefits for Kubernetes here.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#security","title":"Security","text":"<p>Probably the most compelling benefit of using bpfman is enhanced security. When using bpfman, only the bpfman daemon, which can be tightly controlled, needs the privileges required to load eBPF programs, while access to the API can be controlled via standard RBAC methods on a per-application and per-CRD basis. Additionally, the signing and validating of bytecode images enables supply chain security.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#visibility-and-debuggability","title":"Visibility and Debuggability","text":"<p>eBPF programs can interact with each other in unexpected ways.  The multi-program support described above helps control these interactions by providing a common mechanism to prioritize and control the flow between the programs.  However, there can still be problems, and there may be eBPF programs running on nodes that were loaded by other mechanisms that you don\u2019t even know about.  bpfman helps here too by reporting all of the eBPF programs running on all of the nodes in a Kubernetes cluster.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#productivity","title":"Productivity","text":"<p>As described above, managing the lifecycle of eBPF programs is something that each application currently needs to do on its own.  It is even more complicated to manage the lifecycle of eBPF programs across a Kubernetes cluster.  bpfman does this for you so you don't have to.  eBPF bytecode images help here as well by simplifying the distribution of eBPF bytecode to multiple nodes in a cluster, and also allowing separate fine-grained versioning control for user space and kernel space code.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#demonstration","title":"Demonstration","text":"<p>This demonstration is adapted from the instructions documented by Andrew Stoycos here.</p> <p>These instructions use kind and bpfman release v0.2.1. It should also be possible to run this demo on other environments such as minikube or an actual cluster.</p> <p>Another option is to build the code yourself and use make run-on-kind</p> <p>to create the cluster as is described in the given links.  Then, start with step 5.</p>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#run-the-demo","title":"Run the demo","text":"<p>1. Create Kind Cluster</p> <pre><code>kind create cluster --name=test-bpfman\n</code></pre> <p>2. Deploy Cert manager</p> <pre><code>kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.11.0/cert-manager.yaml\n</code></pre> <p>3. Deploy bpfman Crds</p> <pre><code>kubectl apply -f  https://github.com/bpfman/bpfman/releases/download/v0.2.1/bpfman-crds-install-v0.2.1.yaml\n</code></pre> <p>4. Deploy bpfman-operator</p> <pre><code>kubectl apply -f https://github.com/bpfman/bpfman/releases/download/v0.2.1/bpfman-operator-install-v0.2.1.yaml\n</code></pre> <p>5. Verify the deployment</p> <pre><code>kubectl get pods -A\n</code></pre> <pre><code>NAMESPACE            NAME                                              READY   STATUS    RESTARTS   AGE\nbpfman                 bpfman-daemon-nkzpf                                 2/2     Running   0          28s\nbpfman                 bpfman-operator-77d697fdd4-clrf7                    2/2     Running   0          33s\ncert-manager         cert-manager-99bb69456-x8n84                      1/1     Running   0          57s\ncert-manager         cert-manager-cainjector-ffb4747bb-pt4hr           1/1     Running   0          57s\ncert-manager         cert-manager-webhook-545bd5d7d8-z5brw             1/1     Running   0          57s\nkube-system          coredns-565d847f94-gjjft                          1/1     Running   0          61s\nkube-system          coredns-565d847f94-mf2cq                          1/1     Running   0          61s\nkube-system          etcd-test-bpfman-control-plane                      1/1     Running   0          76s\nkube-system          kindnet-lv6f9                                     1/1     Running   0          61s\nkube-system          kube-apiserver-test-bpfman-control-plane            1/1     Running   0          76s\nkube-system          kube-controller-manager-test-bpfman-control-plane   1/1     Running   0          77s\nkube-system          kube-proxy-dtmvb                                  1/1     Running   0          61s\nkube-system          kube-scheduler-test-bpfman-control-plane            1/1     Running   0          78s\nlocal-path-storage   local-path-provisioner-684f458cdd-8gxxv           1/1     Running   0          61s\n</code></pre> <p>Note that we have the bpfman-operator, bpf-daemon and cert-manager pods running.</p> <p>6. Deploy the XDP counter program and user space application</p> <pre><code>kubectl apply -f https://github.com/bpfman/bpfman/releases/download/v0.2.1/go-xdp-counter-install-v0.2.1.yaml\n</code></pre> <p>7. Confirm that the programs are loaded</p> <p>Userspace program:</p> <pre><code>kubectl get pods -n go-xdp-counter\n</code></pre> <pre><code>NAME                      READY   STATUS              RESTARTS   AGE\ngo-xdp-counter-ds-9lpgp   0/1     ContainerCreating   0          5s\n</code></pre> <p>XDP program:</p> <pre><code>kubectl get xdpprograms.bpfman.io -o wide\n</code></pre> <pre><code>NAME                     BPFFUNCTIONNAME   NODESELECTOR   PRIORITY   INTERFACESELECTOR               PROCEEDON\ngo-xdp-counter-example   stats             {}             55         {\"primarynodeinterface\":true}   [\"pass\",\"dispatcher_return\"]\n</code></pre> <p>8. Confirm that the counter program is counting packets.</p> <p>Notes:</p> <ul> <li>The counters are updated every 5 seconds, and stats are being collected for the pod's primary node interface, which may not have a lot of traffic. However, running the <code>kubectl</code> command below generates traffic on that interface, so run the command a few times and give it a few seconds in between to confirm whether the counters are incrementing.</li> <li>Replace \"go-xdp-counter-ds-9lpgp\" with the go-xdp-counter pod name for your deployment.</li> </ul> <pre><code>kubectl logs go-xdp-counter-ds-9lpgp -n go-xdp-counter | tail\n</code></pre> <pre><code>2023/09/05 16:58:21 1204 packets received\n2023/09/05 16:58:21 13741238 bytes received\n\n2023/09/05 16:58:24 1220 packets received\n2023/09/05 16:58:24 13744258 bytes received\n\n2023/09/05 16:58:27 1253 packets received\n2023/09/05 16:58:27 13750364 bytes received\n</code></pre> <p>9. Deploy the <code>xdp-pass-all-nodes</code> program with <code>priority</code> set to 50 and   <code>proceedon</code> set to <code>drop</code> as shown below</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: bpfman.io/v1alpha1\nkind: XdpProgram\nmetadata:\n  labels:\n    app.kubernetes.io/name: xdpprogram\n  name: xdp-pass-all-nodes\nspec:\n  name: pass\n  nodeselector: {}\n  interfaceselector:\n    primarynodeinterface: true\n  priority: 50\n  proceedon:\n    - drop\n  bytecode:\n    image:\n      url: quay.io/bpfman-bytecode/xdp_pass:latest\nEOF\n</code></pre> <p>10. Verify both XDP programs are loaded.</p> <pre><code>kubectl get xdpprograms.bpfman.io -o wide\n</code></pre> <pre><code>NAME                     BPFFUNCTIONNAME   NODESELECTOR   PRIORITY   INTERFACESELECTOR               PROCEEDON\ngo-xdp-counter-example   stats             {}             55         {\"primarynodeinterface\":true}   [\"pass\",\"dispatcher_return\"]\nxdp-pass-all-nodes       pass              {}             50         {\"primarynodeinterface\":true}   [\"drop\"]\n</code></pre> <p>The priority setting determines the order in which programs attached to the same interface are executed by the dispatcher with a lower number being a higher priority.  The <code>go-xdp-counter-example</code> program was loaded at priority 55, so the <code>xdp-pass-all-nodes</code> program will execute before the <code>go-xdp-counter-example</code> program.</p> <p>The proceedon setting tells the dispatcher whether to \"proceed\" to execute the next lower priority program attached to the same interface depending on the program's return value.  When we set proceedon to drop, execution will proceed only if the program returns <code>XDP_DROP</code>.  However, the <code>xdp-pass-all-nodes</code> program only returns <code>XDP_PASS</code>, so execution will terminate after it runs.</p> <p>Therefore, by loading the <code>xdp-pass-all-nodes</code> program in this way, we should have effectively stopped the <code>go-xdp-counter-example</code> program from running.  Let's confirm that.</p> <p>11. Verify that packet counts are not being updated anymore</p> <p>Run the following command several times</p> <pre><code>kubectl logs go-xdp-counter-ds-9lpgp -n go-xdp-counter | tail\n</code></pre> <pre><code>2023/09/05 17:10:27 1395 packets received\n2023/09/05 17:10:27 13799730 bytes received\n\n2023/09/05 17:10:30 1395 packets received\n2023/09/05 17:10:30 13799730 bytes received\n\n2023/09/05 17:10:33 1395 packets received\n2023/09/05 17:10:33 13799730 bytes received\n</code></pre> <p>12. Now, change the priority of the xdp-pass program to 60</p> <pre><code>kubectl apply -f - &lt;&lt;EOF\napiVersion: bpfman.io/v1alpha1\nkind: XdpProgram\nmetadata:\n  labels:\n    app.kubernetes.io/name: xdpprogram\n  name: xdp-pass-all-nodes\nspec:\n  name: pass\n  # Select all nodes\n  nodeselector: {}\n  interfaceselector:\n    primarynodeinterface: true\n  priority: 60\n  proceedon:\n    - drop\n  bytecode:\n    image:\n      url: quay.io/bpfman-bytecode/xdp_pass:latest\nEOF\n</code></pre> <p>13. Confirm that packets are being counted again</p> <p>Run the following command several times</p> <pre><code>kubectl logs go-xdp-counter-ds-9lpgp -n go-xdp-counter | tail\n</code></pre> <pre><code>2023/09/05 17:12:21 1435 packets received\n2023/09/05 17:12:21 13806214 bytes received\n\n2023/09/05 17:12:24 1505 packets received\n2023/09/05 17:12:24 13815359 bytes received\n\n2023/09/05 17:12:27 1558 packets received\n2023/09/05 17:12:27 13823065 bytes received\n</code></pre> <p>We can see that the counters are incrementing again.</p> <p>14. Clean everything up</p> <p>Delete the programs</p> <pre><code>kubectl delete xdpprogram xdp-pass-all-nodes\nkubectl delete -f https://github.com/bpfman/bpfman/releases/download/v0.2.0/go-xdp-counter-install-v0.2.0.yaml\n</code></pre> <p>And/or, delete the whole kind cluster</p> <pre><code>kind delete clusters test-bpfman\n</code></pre>"},{"location":"blog/2023/09/07/bpfman-a-novel-way-to-manage-ebpf/#joining-the-bpfman-community","title":"Joining the bpfman community","text":"<p>If you're interested in bpfman and want to get involved, you can connect with the community in multiple ways. If you have some simple questions or need some help feel free to start a discussion. If you find an issue, or you want to request a new feature, please create an issue. If you want something a little more synchronous, the project maintains a <code>#bpfman</code> channel on Kubernetes Slack and we have a weekly community meeting where everyone can join and bring topics to discuss about the project. We hope to see you there!</p>"},{"location":"blog/2024/01/15/bpfmans-shift-towards-a-daemonless-design-and-using-sled-a-high-performance-embedded-database/","title":"bpfman's Shift Towards a Daemonless Design and Using Sled: a High Performance Embedded Database","text":"<p>As part of issue #860 the community has steadily been converting all of the internal state management to go through a sled database instance which is part of the larger effort to make bpfman completely damonless.</p> <p>This article will go over the reasons behind the change and dive into some of the details of the actual implementation.</p>"},{"location":"blog/2024/01/15/bpfmans-shift-towards-a-daemonless-design-and-using-sled-a-high-performance-embedded-database/#why","title":"Why?","text":"<p>State management in bpfman has always been a headache, not because there's a huge amount of disparate data but there's multiple representations of the same data. Additionally the delicate filesystem interactions and layout previously used to ensure persistence across restarts often led to issues.</p> <p>Understanding the existing flow of data in bpfman can help make this a bit clearer:</p> <p></p> <p>With this design there was a lot of data wrangling required to convert the tonic generated rust bindings for the protocol buffer API into data structures that were useful for bpfman. Specifically, data would arrive via GRPC server as specified in <code>bpfman.v1.rs</code> where rust types are inferred from the protobuf definition. In <code>rpc.rs</code> data was then converted to an internal set of structures defined in <code>command.rs</code>.  Prior to pull request #683 there was an explosion of types, with each bpfman command having it's own set of internal structures and enums.  Now, most of the data for a program that bpfman needs internally for all commands to manage an eBPF program is stored in the <code>ProgramData</code> structure, which we'll take a deeper look at a bit later. Additionally, there is extra complexity for XDP and TC program types which rely on an eBPF dispatcher program to provide multi-program support on a single network interface, however this article will try to instead focus on the simpler examples.</p> <p>The tree of data stored by bpfman is quite complex and this is made even more complicated since bpfman has to be persistent across restarts. To support this, raw data was often flushed to disk in the form of JSON files (all types in <code>command.rs</code> needed to implement serde's <code>Serialize</code> and <code>Deserialize</code>). Specific significance would also be encoded to bpfman's directory structure, i.e all program related information was encoded in <code>/run/bpfd/programs/&lt;ID&gt;</code>. The extra infrastructure and failure modes introduced by this process was a constant headache, pushing the community to find a better solution.</p>"},{"location":"blog/2024/01/15/bpfmans-shift-towards-a-daemonless-design-and-using-sled-a-high-performance-embedded-database/#why-sled","title":"Why Sled?","text":"<p>Sled is an open source project described in github as \"the champagne of beta embedded databases\". The \"reasons\" for choosing an embedded database from the project website are pretty much spot on:</p> <pre><code>Embedded databases are useful in several cases:\n\n- you want to store data on disk, without facing the complexity of files\n- you want to be simple, without operating an external database\n- you want to be fast, without paying network costs\n- using disk storage as a building block in your system\n</code></pre> <p>As discussed in the previous section, persistence across restarts, is one of bpfman's core design constraints, and with sled we almost get it for free! Additionally due to the pervasive nature of data management to bpfman's core workflow the data-store needed to be kept as simple and light weight as possible, ruling out heavier production-ready external database systems such as MySQL or Redis.</p> <p>Now this mostly focused on why embedded dbs in general, but why did we choose sled...well because it's written in :crab: Rust :crab: of course! Apart from the obvious we took a small dive into the project before rewriting everything by transitioning the OCI bytecode image library to use the db rather than the filesystem.  Overall the experience was extremely positive due to the following:</p> <ul> <li>No more dealing directly with the filesystem, the sled instance is flushed to   the fs automatically every 500 ms by default and for good measure we manually   flush it before shutting down.</li> <li>The API is extremely simple, traditional get and insert operations function   as expected.</li> <li>Error handling with <code>sled:Error</code> is relatively simple and easy to map explicitly   to a <code>bpfmanError</code></li> <li>The db \"tree\" concept makes it easy to have separate key-spaces within the same   instance.</li> </ul>"},{"location":"blog/2024/01/15/bpfmans-shift-towards-a-daemonless-design-and-using-sled-a-high-performance-embedded-database/#transitioning-to-sled","title":"Transitioning to Sled","text":"<p>Using the new embedded database started with the creation of a sled instance which could be easily shared across all of the modules in bpfman. To do this we utilized a globally available [<code>lazy_static</code>] variable called <code>ROOT_DB</code> in <code>main.rs</code>:</p> <pre><code>#[cfg(not(test))]\nlazy_static! {\n    pub static ref ROOT_DB: Db = Config::default()\n        .path(STDIR_DB)\n        .open()\n        .expect(\"Unable to open root database\");\n}\n\n#[cfg(test)]\nlazy_static! {\n    pub static ref ROOT_DB: Db = Config::default()\n        .temporary(true)\n        .open()\n        .expect(\"Unable to open temporary root database\");\n}\n</code></pre> <p>This block creates OR opens the filesystem backed database at <code>/var/lib/bpfman/db</code> database only when the <code>ROOT_DB</code> variable is first accessed, and also allows for the creation of a temporary db instance if running in unit tests. With this setup all of the modules within bpfman can now easily access the database instance by simply using it i.e <code>use crate::ROOT_DB</code>.</p> <p>Next the existing bpfman structures needed to be flattened in order to work with the db, the central <code>ProgramData</code> can be used to demonstrate how this was completed. Prior to the recent sled conversion that structure looked like:</p> <pre><code>/// ProgramInfo stores information about bpf programs that are loaded and managed\n/// by bpfd.\n#[derive(Debug, Serialize, Deserialize, Clone, Default)]\npub(crate) struct ProgramData {\n    // known at load time, set by user\n    name: String,\n    location: Location,\n    metadata: HashMap&lt;String, String&gt;,\n    global_data: HashMap&lt;String, Vec&lt;u8&gt;&gt;,\n    map_owner_id: Option&lt;u32&gt;,\n\n    // populated after load\n    kernel_info: Option&lt;KernelProgramInfo&gt;,\n    map_pin_path: Option&lt;PathBuf&gt;,\n    maps_used_by: Option&lt;Vec&lt;u32&gt;&gt;,\n\n    // program_bytes is used to temporarily cache the raw program data during\n    // the loading process.  It MUST be cleared following a load so that there\n    // is not a long lived copy of the program data living on the heap.\n    #[serde(skip_serializing, skip_deserializing)]\n    program_bytes: Vec&lt;u8&gt;,\n}\n</code></pre> <p>This worked well enough, but as mentioned before the process of flushing the data to disk involved manual serialization to JSON, which needed to occur at a specific point in time (following program load) which made disaster recovery almost impossible and could sometimes result in lost or partially reconstructed state.</p> <p>With sled the first idea was to completely flatten ALL of bpfman's data into a single key-space, so that <code>program.name</code> now simply turns into a <code>db.get(\"program_&lt;ID&gt;_name\")</code>, however removing all of the core structures would have resulted in a complex diff which would have been hard to review and merge.  Therefore a more staged approach was taken, the <code>ProgramData</code> structure was kept around, and now looks like:</p> <pre><code>/// ProgramInfo stores information about bpf programs that are loaded and managed\n/// by bpfman.\n#[derive(Debug, Clone)]\npub(crate) struct ProgramData {\n    // Prior to load this will be a temporary Tree with a random ID, following\n    // load it will be replaced with the main program database tree.\n    db_tree: sled::Tree,\n\n    // populated after load, randomly generated prior to load.\n    id: u32,\n\n    // program_bytes is used to temporarily cache the raw program data during\n    // the loading process.  It MUST be cleared following a load so that there\n    // is not a long lived copy of the program data living on the heap.\n    program_bytes: Vec&lt;u8&gt;,\n}\n</code></pre> <p>All of the fields are now removed in favor of a private reference to the unique [<code>sled::Tree</code>] instance for this <code>ProgramData</code> which is named using the unique kernel id for the program. Each <code>sled::Tree</code> represents a single logical key-space / namespace / bucket which allows key generation to be kept simple, i.e <code>db.get(\"program_&lt;ID&gt;_name\")</code> now can be <code>db_tree_prog_0000.get(\"program_name)</code>. Additionally getters and setters are now built for each existing field so that access to the db can be controlled and the serialization/deserialization process can be hidden from the caller:</p> <pre><code>...\npub(crate) fn set_name(&amp;mut self, name: &amp;str) -&gt; Result&lt;(), BpfmanError&gt; {\n    self.insert(\"name\", name.as_bytes())\n}\n\npub(crate) fn get_name(&amp;self) -&gt; Result&lt;String, BpfmanError&gt; {\n    self.get(\"name\").map(|v| bytes_to_string(&amp;v))\n}\n...\n</code></pre> <p>Therefore, <code>ProgramData</code> is now less of a container for program data and more of a wrapper for accessing program data.  The getters/setters act as a bridge between standard Rust types and the raw bytes stored in the database, i.e the [<code>sled::IVec</code> type].</p> <p>Once this was completed for all the relevant fields on all the relevant types, see pull request #874, the data bpfman needed for it's managed eBPF programs was now automatically synced to disk :partying_face:</p>"},{"location":"blog/2024/01/15/bpfmans-shift-towards-a-daemonless-design-and-using-sled-a-high-performance-embedded-database/#tradeoffs","title":"Tradeoffs","text":"<p>All design changes come with some tradeoffs: for bpfman's conversion to using sled the main negative ended up being with the complexity introduced with the [<code>sled::IVec</code> type]. It is basically just a thread-safe reference-counting pointer to a raw byte slice, and the only type raw database operations can be performed with. Previously when using <code>serde_json</code> all serialization/deserialization was automatically handled, however with sled the conversion is manual handled internally. Therefore, instead of a library handling the conversion of a rust string (<code>std::string::String</code>) to raw bytes <code>&amp;[u8]</code> bpfman has to handle it internally, using [<code>std::string::String::as_bytes</code>] and <code>bpfman::utils::bytes_to_string</code>:</p> <pre><code>pub(crate) fn bytes_to_string(bytes: &amp;[u8]) -&gt; String {\n    String::from_utf8(bytes.to_vec()).expect(\"failed to convert &amp;[u8] to string\")\n}\n</code></pre> <p>For strings, conversion was simple enough, but when working with more complex rust data types like <code>HashMaps</code> and <code>Vectors</code> this became a bit more of an issue. For <code>Vectors</code>, we simply flatten the structure into a group of key/values with indexes encoded into the key:</p> <pre><code>    pub(crate) fn set_kernel_map_ids(&amp;mut self, map_ids: Vec&lt;u32&gt;) -&gt; Result&lt;(), BpfmanError&gt; {\n        let map_ids = map_ids.iter().map(|i| i.to_ne_bytes()).collect::&lt;Vec&lt;_&gt;&gt;();\n\n        map_ids.iter().enumerate().try_for_each(|(i, v)| {\n            sled_insert(&amp;self.db_tree, format!(\"kernel_map_ids_{i}\").as_str(), v)\n        })\n    }\n</code></pre> <p>The sled <code>scan_prefix(&lt;K&gt;)</code> api then allows for easy fetching and rebuilding of the vector:</p> <pre><code>    pub(crate) fn get_kernel_map_ids(&amp;self) -&gt; Result&lt;Vec&lt;u32&gt;, BpfmanError&gt; {\n        self.db_tree\n            .scan_prefix(\"kernel_map_ids_\".as_bytes())\n            .map(|n| n.map(|(_, v)| bytes_to_u32(v.to_vec())))\n            .map(|n| {\n                n.map_err(|e| {\n                    BpfmanError::DatabaseError(\"Failed to get map ids\".to_string(), e.to_string())\n                })\n            })\n            .collect()\n    }\n</code></pre> <p>For <code>HashMaps</code>, we follow a similar paradigm, except the map key is encoded in the database key:</p> <pre><code>    pub(crate) fn set_metadata(\n        &amp;mut self,\n        data: HashMap&lt;String, String&gt;,\n    ) -&gt; Result&lt;(), BpfmanError&gt; {\n        data.iter().try_for_each(|(k, v)| {\n            sled_insert(\n                &amp;self.db_tree,\n                format!(\"metadata_{k}\").as_str(),\n                v.as_bytes(),\n            )\n        })\n    }\n\n    pub(crate) fn get_metadata(&amp;self) -&gt; Result&lt;HashMap&lt;String, String&gt;, BpfmanError&gt; {\n    self.db_tree\n        .scan_prefix(\"metadata_\")\n        .map(|n| {\n            n.map(|(k, v)| {\n                (\n                    bytes_to_string(&amp;k)\n                        .strip_prefix(\"metadata_\")\n                        .unwrap()\n                        .to_string(),\n                    bytes_to_string(&amp;v).to_string(),\n                )\n            })\n        })\n        .map(|n| {\n            n.map_err(|e| {\n                BpfmanError::DatabaseError(\"Failed to get metadata\".to_string(), e.to_string())\n            })\n        })\n        .collect()\n    }\n</code></pre> <p>The same result could be achieved by creating individual database trees for each <code>Vector</code>/<code>HashMap</code> instance, however our goal was to keep the layout as flat as possible. Although this resulted in some extra complexity within the data layer, the overall benefits still outweighed the extra code once the conversion was complete.</p>"},{"location":"blog/2024/01/15/bpfmans-shift-towards-a-daemonless-design-and-using-sled-a-high-performance-embedded-database/#moving-forward-and-getting-involved","title":"Moving forward and Getting Involved","text":"<p>Once the conversion to sled is fully complete, see issue #860, the project will be able to completely transition to becoming a library without having to worry about data and state management.</p> <p>If you are interested in in memory databases, eBPF, Rust, or any of the technologies discussed today please don't hesitate to reach out at kubernetes slack on channel <code>#bpfman</code> or join one of the community meetings to get involved.</p>"},{"location":"blog/2024/01/04/community-meeting-january-4-2024/","title":"Community Meeting: January 4, 2024","text":""},{"location":"blog/2024/01/04/community-meeting-january-4-2024/#welcome-to-2024","title":"Welcome to 2024!","text":"<p>Welcome to the first <code>bpfman</code> Community Meeting of 2024. We are happy to start off a new year and excited for all the changes in store for <code>bpfman</code> in 2024!</p> <p>Below were some of the discussion points from this weeks Community Meeting.</p> <ul> <li>bpfman-csi Needs To Become Its Own Binary</li> <li>Kubernetes Support For Attaching uprobes In Containers</li> <li>Building The Community</li> </ul>"},{"location":"blog/2024/01/04/community-meeting-january-4-2024/#bpfman-csi-needs-to-become-its-own-binary","title":"bpfman-csi Needs To Become Its Own Binary","text":"<p>Some of the next work items for <code>bpfman</code> revolve around removing the async code from the code base, make <code>bpfman-core</code> a rust library, and removing all the gRPC logic. Dave (@dave-tucker) is currently investigating this. One area to help out is to take the <code>bpfman-csi</code> thread and making it it's own binary. This may require making <code>bpfman</code> a bin and lib crate (which is fine, just needs a lib.rs and to be very careful about what we\u2019re exporting). Andrew (@astoycos) is starting to take a look at this.</p>"},{"location":"blog/2024/01/04/community-meeting-january-4-2024/#kubernetes-support-for-attaching-uprobes-in-containers","title":"Kubernetes Support For Attaching uprobes In Containers","text":"<p>Base support for attaching uprobes in containers is currently merged. Andre (@anfredette) pushed PR#875 for the integration with Kubernetes. The hard problems are solved, like getting the Container PID, but the current PR has some shortcuts to get the functionality working before the holiday break. So the PR#875 is not ready for review, but Dave (@dave-tucker) and Andre (@anfredette) may have a quick review to verify the design principles.</p>"},{"location":"blog/2024/01/04/community-meeting-january-4-2024/#building-the-community","title":"Building The Community","text":"<p>Short discussion on building the Community. In a previous meeting, Dave (@dave-tucker) suggested capturing the meeting minutes in blogs. By placing in a blog, they become searchable from search engines. Billy (@billy99) re-raised this topic and volunteered to start capturing the content. In future meetings, we may use the transcript feature from Google Meet to capture the content and try generating the blog via ChatGTP.</p>"},{"location":"blog/2024/01/04/community-meeting-january-4-2024/#light-hearted-moments-and-casual-conversations","title":"Light-hearted Moments and Casual Conversations","text":"<p>Amidst the technical discussions, the community members took a moment to share some light-hearted moments and casual conversations. Topics ranged from the challenges of post-holiday credit card bills to the complexities of managing family schedules during exam week. The discussion touched on the quirks of public school rules and the unique challenges of parenting during exam periods.</p> <p>The meeting ended on a friendly note, with plans for further collaboration and individual tasks assigned for the upcoming days. Participants expressed their commitment to pushing updates and improvements, with a promise to reconvene in the near future.</p>"},{"location":"blog/2024/01/04/community-meeting-january-4-2024/#attendees","title":"Attendees","text":"<ul> <li>Andre Fredette (Red Hat)</li> <li>Andrew Stoycos (Red Hat)</li> <li>Billy McFall (Red Hat)</li> <li>Dave Tucker (Red Hat)</li> </ul>"},{"location":"blog/2024/01/04/community-meeting-january-4-2024/#bpfman-community-info","title":"bpfman Community Info","text":"<p>A friendly reminder that the Community Meetings are every Thursday 10am-11am Eastern US Time and all are welcome!</p> <p>Google Meet joining info:</p> <ul> <li>Google Meet</li> <li>Or dial: (US) +1 984-221-0859 PIN: 613 588 790#</li> <li>Agenda Document</li> </ul>"},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/","title":"Community Meeting: January 11 and 18, 2024","text":""},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#hit-the-ground-running","title":"Hit the Ground Running","text":"<p>Another set of <code>bpfman</code> Community Meetings for 2024. There is a lot going on with <code>bpfman</code> in Q1 of 2024. Spending a lot of time making <code>bpfman</code> daemonless. I bailed for a ski trip after the Jan 11 meeting, so the notes didn't get written up. So this summary will include two weeks of meetings.</p> <p>Below were some of the discussion points from the last two weeks Community Meetings.</p> <ul> <li>Manpage/CLI TAB Completion Questions (Jan 11)</li> <li>Kubernetes Support for Attaching uprobes in Containers (Jan 11)</li> <li>netify Preview in Github Removed (Jan 11)</li> <li>RPM Builds and Socket Activation (Jan 18)</li> <li>KubeCon EU Discussion (Jan 18)</li> </ul>"},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#january-11-2024","title":"January 11, 2024","text":""},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#manpagecli-tab-completion-questions-jan-11","title":"Manpage/CLI TAB Completion Questions (Jan 11)","text":"<p>The <code>bpfman</code> CLI now has TAB Completion and man pages. However, a couple nits need to be cleaned up Issue#913 and Billy (@billy99) wanted to clarify a few issues encountered. The current implementation for both features  is using an environment variable to set the destination directory for the generated files. Other features don't work this way and there was a discussion on the proper location for the generated files. The decision was to use <code>.output/.</code>.</p> <p>There was another discussion around <code>clap</code> (Rust CLI crate) and passing variables to <code>clap</code> from the Cargo.toml file. In the CLI code, <code>#[command(author, version, about, long_about = None)]</code> implies to pull the values from the Config.toml file, but we aren\u2019t setting any of those variables. Also, for <code>cargo xtask build-man-page</code> and <code>cargo xtask build-completion</code> they pull from the xtask Cargo.toml file. The decision was to set the variables implicitly in code and not pull from Cargo.toml.</p>"},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#kubernetes-support-for-attaching-uprobes-in-containers-jan-11","title":"Kubernetes Support for Attaching uprobes in Containers (Jan 11)","text":"<p>Andre (@anfredette) is working on a feature to enable attaching uprobes in other Containers. Currently, <code>bpfman</code> only supports attaching uprobes within the <code>bpfman</code> container. There was a discussion on proper way to format a query to the KubeAPI server to match on NodeName on a Pod list. The discussion included so code walk through. Andrew (@astoycos) found a possible solution client-go:Issue#410 and Dave (@dave-tucker) suggested kubernetes-api:podspec-v1-core.</p>"},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#netify-preview-in-github-removed-jan-11","title":"netify Preview in Github Removed (Jan 11)","text":"<p>Lastly, there was a discussion on the <code>netify</code> preview being removed from github and a reminder why. Dave (@dave-tucker) explained that with the docs release history now in place, \"current\" is from a branch and it is not easy to preview. So for now, document developers need to run mkdocs locally (See generate-documention).</p>"},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#attendees-jan-11","title":"Attendees (Jan 11)","text":"<ul> <li>Andre Fredette (Red Hat)</li> <li>Andrew Stoycos (Red Hat)</li> <li>Billy McFall (Red Hat)</li> <li>Dave Tucker (Red Hat)</li> <li>Shane Utt (Kong)</li> </ul>"},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#january-18-2024","title":"January 18, 2024","text":""},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#rpm-builds-and-socket-activation-jan-18","title":"RPM Builds and Socket Activation (Jan 18)","text":"<p>RPM Builds for <code>bpfman</code> went in fairly recently and Billy (@billy99) had some questions around their implementation. RPM and Socket Activation were developed and merged around the same time and the RPM builds are not installing socket activation properly. Just verifying that RPMs should be installing the <code>bpfman.socket</code> file. And they should. There were also some questions on how to build RPMs locally. Verified that <code>packit build locally</code> is the way forward.</p> <p>Note: Socket activation was added to RPM Builds along with documentation on building and using RPMs in PR#922</p>"},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#kubecon-eu-discussion-jan-18","title":"KubeCon EU Discussion (Jan 18)","text":"<p>With KubeCon EU just around the corner (March 19-22, 2024 in Paris), discussion around bpfman talks and who was attending. Dave (@dave-tucker) is probably attending and Shane (@shaneutt) might attend. So if you are planning on attending KubeCon EU and are interested in <code>bpfman</code> or just eBPF, keep an eye out for these guys for some lively discussions!</p>"},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#attendees-jan-18","title":"Attendees (Jan 18)","text":"<ul> <li>Billy McFall (Red Hat)</li> <li>Dave Tucker (Red Hat)</li> <li>Shane Utt (Kong)</li> </ul>"},{"location":"blog/2024/01/19/community-meeting-january-11-and-18-2024/#bpfman-community-info","title":"bpfman Community Info","text":"<p>A friendly reminder that the Community Meetings are every Thursday 10am-11am Eastern US Time and all are welcome!</p> <p>Google Meet joining info:</p> <ul> <li>Google Meet</li> <li>Or dial: (US) +1 984-221-0859 PIN: 613 588 790#</li> <li>Agenda Document</li> </ul>"},{"location":"design/clusterVsNamespaceScoped/","title":"bpfman CRDs - Cluster vs Namespace Scoped","text":""},{"location":"design/clusterVsNamespaceScoped/#status","title":"Status","text":"<p>This design was implemented with bpfman-operator pull request #344. The feature was first releases in the bpfman-operator v0.5.5 release.</p>"},{"location":"design/clusterVsNamespaceScoped/#introduction","title":"Introduction","text":"<p>For security reasons, cluster admins may want to limit certain applications to only loading eBPF programs within a given namespace. Currently, all bpfman Custom Resource Definitions (CRDs) are Cluster scoped. To provide cluster admins with tighter controls on eBPF program loading, some of the bpfman CRDs also need to be Namespace scoped.</p> <p>Not all eBPF programs make sense to be namespaced scoped. Some eBPF programs like kprobe cannot be constrained to a namespace. The following programs will have a namespaced scoped variant:</p> <ul> <li>Uprobe</li> <li>TC</li> <li>TCX</li> <li>XDP</li> </ul> <p>There will also be a namespace scoped BpfApplication variant that is limited to namespaced scoped eBPF programs listed above.</p>"},{"location":"design/clusterVsNamespaceScoped/#current-implementation","title":"Current Implementation","text":"<p>Currently, the reconciler code is broken into two layers (for both the bpfman-operator and the bpfman-agent). There is the *Program layer, where there is a reconcile for each program type (Fentry, Fexit, Kprobe, etc). At this layer, the program specific code handles creating the program specific structure. The *Program layer then calls the Common layer to handle processing that is common across all programs.</p> <p>There are some structures, then an interface that defines the set of methods the structure needs to support.</p>"},{"location":"design/clusterVsNamespaceScoped/#struct","title":"struct","text":"<p>There are a set of structures (one for the BPF Program CRD and then one for each *Program CRD) that define the contents of the CRDs (bpfman-operator/apis/v1alpha). Each object (BPF Program CRD and *Program CRD) also has a List object.</p> <pre><code>type BpfProgram struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec BpfProgramSpec `json:\"spec\"`\n    // +optional\n    Status BpfProgramStatus `json:\"status,omitempty\"`\n}\ntype BpfProgramList struct {\n    metav1.TypeMeta `json:\",inline\"`\n    metav1.ListMeta `json:\"metadata,omitempty\"`\n    Items           []BpfProgram `json:\"items\"`\n}\n\ntype FentryProgram struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec FentryProgramSpec `json:\"spec\"`\n    // +optional\n    Status FentryProgramStatus `json:\"status,omitempty\"`\n}\ntype FentryProgramList struct {\n    metav1.TypeMeta `json:\",inline\"`\n    metav1.ListMeta `json:\"metadata,omitempty\"`\n    Items           []FentryProgram `json:\"items\"`\n}\n\n:\n</code></pre> <p>There is a reconciler for each *Program. For the implementation, there is a common set of data used by each *Program reconciler which is contained in the base struct <code>ReconcilerCommon</code>. Then there is a *Program struct, which includes each *Program\u2019s Program struct and the base struct <code>ReconcilerCommon</code>. Below are the bpfman-agent structures, but the bpfman-operator follows the same pattern.</p> <pre><code>type ReconcilerCommon struct {\n    client.Client\n    Scheme       *runtime.Scheme\n    GrpcConn     *grpc.ClientConn\n    BpfmanClient gobpfman.BpfmanClient\n    Logger       logr.Logger\n    NodeName     string\n    progId       *uint32\n    finalizer    string\n    recType      string\n    appOwner     metav1.Object // Set if the owner is an application\n}\n\ntype FentryProgramReconciler struct {\n    ReconcilerCommon\n    currentFentryProgram *bpfmaniov1alpha1.FentryProgram\n    ourNode              *v1.Node\n}\n\ntype FexitProgramReconciler struct {\n    ReconcilerCommon\n    currentFexitProgram *bpfmaniov1alpha1.FexitProgram\n    ourNode             *v1.Node\n}\n\n:\n</code></pre>"},{"location":"design/clusterVsNamespaceScoped/#interface","title":"interface","text":"<p>The <code>bpfmanReconciler</code> interface defines the set of methods the *Program structs must implement to use the common reconciler code.  Below are the bpfman-agent structures, but the bpfman-operator uses a <code>ProgramReconciler</code>, which follows the same pattern.</p> <pre><code>type bpfmanReconciler interface {\n    SetupWithManager(mgr ctrl.Manager) error\n    Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error)\n    getFinalizer() string\n    getOwner() metav1.Object\n    getRecType() string\n    getProgType() internal.ProgramType\n    getName() string\n    getExpectedBpfPrograms(ctx context.Context)\n    (*bpfmaniov1alpha1.BpfProgramList, error)\n    getLoadRequest(bpfProgram *bpfmaniov1alpha1.BpfProgram,\n    mapOwnerId *uint32) (*gobpfman.LoadRequest, error)\n    getNode() *v1.Node\n    getBpfProgramCommon() *bpfmaniov1alpha1.BpfProgramCommon\n    setCurrentProgram(program client.Object) error\n    getNodeSelector() *metav1.LabelSelector\n    getBpfGlobalData() map[string][]byte\n    getAppProgramId() string\n}\n</code></pre> <p>There are also some common reconciler functions that perform common code.</p> <pre><code>func (r *ReconcilerCommon) reconcileCommon(ctx context.Context,\n  rec bpfmanReconciler,\n    programs []client.Object) (bool, ctrl.Result, error) {\n:\n}\n\nfunc (r *ReconcilerCommon) reconcileBpfProgram(ctx context.Context,\n    rec bpfmanReconciler,\n    loadedBpfPrograms map[string]*gobpfman.ListResponse_ListResult,\n    bpfProgram *bpfmaniov1alpha1.BpfProgram,\n    isNodeSelected bool,\n    isBeingDeleted bool,\n    mapOwnerStatus *MapOwnerParamStatus)\n(bpfmaniov1alpha1.BpfProgramConditionType, error) {\n:\n}\n\nfunc (r *ReconcilerCommon) reconcileBpfProgramSuccessCondition(\n    isLoaded bool,\n    shouldBeLoaded bool,\n    isNodeSelected bool,\n    isBeingDeleted bool,\n    noContainersOnNode bool,\n  mapOwnerStatus *MapOwnerParamStatus) bpfmaniov1alpha1.BpfProgramConditionType {\n:\n}\n</code></pre> <p>So looks something like this:</p> <pre><code>                     --- FentryProgramReconciler\n                     |     func (r *FentryProgramReconciler) getFinalizer() string {}\n                     |\nbpfmanReconciler   ----- FexitProgramReconciler\n  ReconcilerCommon   |     func (r *FexitProgramReconciler) getFinalizer() string {}\n                     |\n                     --- \u2026\n</code></pre>"},{"location":"design/clusterVsNamespaceScoped/#adding-namespaced-scoped-crds","title":"Adding Namespaced Scoped CRDs","text":"<p>While the contents are mostly the same for the namespace and cluster-scoped CRD in most cases, Kubernetes requires different  CRD for each type.</p>"},{"location":"design/clusterVsNamespaceScoped/#struct_1","title":"struct","text":"<p>The set of CRD structures will need to be duplicated for each Namespaced scoped CRD (bpfman-operator/apis/v1alpha). Note, data is the similar, just a new object. The primary change is the existing <code>ContainerSelector</code> struct will be replaced with a <code>ContainerNsSelector</code>. For Namespaced scoped CRDs, the <code>namespace</code> in the <code>ContainerSelector</code> is removed. The <code>Namespace</code> field for the object is embedded the <code>metav1.ObjectMeta</code> structure. Not all Program Types will have a Namespaced version, only those that can be contained by a namespace:</p> <ul> <li>TC</li> <li>TCX</li> <li>Uprobe</li> <li>XDP</li> </ul> <p>The Application Program will also have a namespaced version, but it will only allow the Program Types that are namespaced.</p> <pre><code>type BpfProgram struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec BpfProgramSpec `json:\"spec\"`\n    // +optional\n    Status BpfProgramStatus `json:\"status,omitempty\"`\n}\ntype BpfProgramList struct {\n    metav1.TypeMeta `json:\",inline\"`\n    metav1.ListMeta `json:\"metadata,omitempty\"`\n    Items           []BpfProgram `json:\"items\"`\n}\n\ntype BpfNsProgram struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec BpfProgramSpec `json:\"spec\"`\n    // +optional\n    Status BpfProgramStatus `json:\"status,omitempty\"`\n}\ntype BpfNsProgramList struct {\n    metav1.TypeMeta `json:\",inline\"`\n    metav1.ListMeta `json:\"metadata,omitempty\"`\n    Items           []BpfProgram `json:\"items\"`\n}\n\ntype TcProgram struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec TcProgramSpec `json:\"spec\"`\n    // +optional\n    Status TcProgramStatus `json:\"status,omitempty\"`\n}\ntype TcProgramList struct {\n    metav1.TypeMeta `json:\",inline\"`\n    metav1.ListMeta `json:\"metadata,omitempty\"`\n    Items           []TcProgram `json:\"items\"`\n}\n\ntype TcNsProgram struct {\n    metav1.TypeMeta   `json:\",inline\"`\n    metav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n    Spec TcNsProgramSpec `json:\"spec\"`\n    // +optional\n    Status TcProgramStatus `json:\"status,omitempty\"`\n}\ntype TcNsProgramList struct {\n    metav1.TypeMeta `json:\",inline\"`\n    metav1.ListMeta `json:\"metadata,omitempty\"`\n    Items           []TcNsProgram `json:\"items\"`\n}\n\n:\n</code></pre>"},{"location":"design/clusterVsNamespaceScoped/#interface_1","title":"interface","text":"<p>The problem is that the <code>bpfmanReconciler</code> interface and common functions use the types <code>bpfmanReconciler</code>, <code>BpfProgram</code> and <code>BpfProgramList</code>, which will need to be cluster or namespaced objects.</p> <p>To allow the common code to act on both Cluster or Namespaced objects, two new interfaces will be introduced. First is <code>BpfProg</code>. Both <code>BpfProgram</code> and <code>BpfNsProgram</code> need to implement these functions.</p> <pre><code>type BpfProg interface {\n    GetName() string\n    GetUID() types.UID\n    GetAnnotations() map[string]string\n    GetLabels() map[string]string\n    GetStatus() *bpfmaniov1alpha1.BpfProgramStatus\n    GetClientObject() client.Object\n}\n</code></pre> <p>The second interface is <code>BpfProgList</code>. Both <code>BpfProgramList</code> and <code>BpfNsProgramList</code> will need to implement these functions. Because the list objects have lists of the <code>BpfProgram</code>or <code>BpfNsProgram</code>, the base interface is a generic, where type T can be a either <code>BpfProgram</code> or <code>BpfNsProgram</code>.</p> <pre><code>type BpfProgList[T any] interface {\n    GetItems() []T\n}\n</code></pre> <p>The reconciler base struct <code>ReconcilerCommon</code> then becomes a generic as well, and all references to the types <code>bpfmanReconciler</code>, <code>BpfProgram</code> and <code>BpfProgramList</code> become the types <code>bpfmanReconciler[T,TL]</code>, <code>T</code> and <code>TL</code>. Below are the bpfman-agent structures, but the bpfman-operator follows the same pattern.</p> <pre><code>type ReconcilerCommon[T BpfProg, TL BpfProgList[T]] struct {\n    : // Data is the same\n}\n\nfunc (r *ReconcilerCommon) reconcileCommon(ctx context.Context,\nrec bpfmanReconciler[T, TL],\n    programs []client.Object) (bool, ctrl.Result, error) {\n:\n}\n\nfunc (r *ReconcilerCommon) reconcileBpfProgram(ctx context.Context,\n    rec bpfmanReconciler[T, TL],\n    loadedBpfPrograms map[string]*gobpfman.ListResponse_ListResult,\n    bpfProgram *T,\n    isNodeSelected bool,\n    isBeingDeleted bool,\n    mapOwnerStatus *MapOwnerParamStatus)\n(bpfmaniov1alpha1.BpfProgramConditionType, error) {\n:\n}\n\nfunc (r *ReconcilerCommon) reconcileBpfProgramSuccessCondition(\n    isLoaded bool,\n    shouldBeLoaded bool,\n    isNodeSelected bool,\n    isBeingDeleted bool,\n    noContainersOnNode bool,\n  mapOwnerStatus *MapOwnerParamStatus) bpfmaniov1alpha1.BpfProgramConditionType {\n:\n}\n</code></pre> <p>Same for the <code>bpfmanReconciler</code> interface. </p> <pre><code>type bpfmanReconciler[T BpfProg, TL BpfProgList[T]] interface {\n    SetupWithManager(mgr ctrl.Manager) error\n    Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error)\n    getFinalizer() string\n    getOwner() metav1.Object\n    getRecType() string\n    getProgType() internal.ProgramType\n    getName() string\n    getExpectedBpfPrograms(ctx context.Context)(*TL, error)\n    getLoadRequest(bpfProgram *T,\n    mapOwnerId *uint32) (*gobpfman.LoadRequest, error)\n    getNode() *v1.Node\n    getBpfProgramCommon() *bpfmaniov1alpha1.BpfProgramCommon\n    setCurrentProgram(program client.Object) error\n    getNodeSelector() *metav1.LabelSelector\n    getBpfGlobalData() map[string][]byte\n    getAppProgramId() string\n}\n</code></pre> <p>Issues arose when <code>ReconcilerCommon</code> functions needed to modify the <code>BpfProgram</code> or <code>BpfNsProgram</code> data. For the modifications to be applied, the types need to be pointers <code>bpfmanReconciler[*T, *TL]</code>, <code>*T</code> and <code>*TL</code>. However, the compiler would not allow this:</p> <pre><code>cannot use type BpfProgList[*T] outside a type constraint: interface contains type constraints\n</code></pre> <p>To work around this, a new layer was added. A struct for cluster scoped code and a one for namespaced code. So looks something like this:</p> <pre><code>                     +--- ClusterProgramReconciler\n                     |     |\n                     |     +--- FentryProgramReconciler\n                     |     |     func (r *FentryProgramReconciler) getFinalizer() string {}\n                     |     |     :\n                     |     |\n                     |     +--- FexitProgramReconciler\n                     |     |     func (r *FexitProgramReconciler) getFinalizer() string {}\n                     |     |     :\n                     |     :\nbpfmanReconciler   --+\n  ReconcilerCommon   |\n                     +--- NamespaceProgramReconciler\n                           |\n                           +--- FentryNsProgramReconciler\n                           |     func (r *FentryProgramReconciler) getFinalizer() string {}\n                           |     :\n                           |\n                           +--- FexitNsProgramReconciler\n                           |     func (r *FexitProgramReconciler) getFinalizer() string {}\n                           |     :\n                           :\n</code></pre> <pre><code>type ClusterProgramReconciler struct {\n    ReconcilerCommon[BpfProgram, BpfProgramList]\n}\n\ntype NamespaceProgramReconciler struct {\n    ReconcilerCommon[BpfNsProgram, BpfNsProgramList]\n}\n</code></pre> <p>Several functions were added to the bpfmanReconciler interface that are implemented by these structures.</p> <pre><code>type bpfmanReconciler[T BpfProg, TL BpfProgList[T]] interface {\n    // BPF Cluster of Namespaced Reconciler\n    getBpfList(ctx context.Context, opts []client.ListOption) (*TL, error)\n    updateBpfStatus(ctx context.Context, bpfProgram *T, condition metav1.Condition) error\n    createBpfProgram(\n        attachPoint string,\n        rec bpfmanReconciler[T, TL],\n        annotations map[string]string,\n    ) (*T, error)\n\n    // *Program Reconciler\n  SetupWithManager(mgr ctrl.Manager) error\n    :\n}\n</code></pre> <p>And the *Programs use the <code>ClusterProgramReconciler</code> or <code>NamespaceProgramReconciler</code> structs instead of the <code>ReconcilerCommon</code> struct.</p> <pre><code>type TcProgramReconciler struct {\n    ClusterProgramReconciler\n    currentTcProgram *bpfmaniov1alpha1.TcProgram\n    interfaces       []string\n    ourNode          *v1.Node\n}\n\ntype TcNsProgramReconciler struct {\n    NamespaceProgramReconciler\n    currentTcNsProgram *bpfmaniov1alpha1.TcNsProgram\n    interfaces         []string\n    ourNode            *v1.Node\n}\n\n:\n</code></pre>"},{"location":"design/clusterVsNamespaceScoped/#naming","title":"Naming","text":"<p>In the existing codebase, all the CRDs are cluster scoped:</p> <ul> <li>BpfApplicationProgram</li> <li>BpfProgram</li> <li>FentryProgram</li> <li>FexitProgram</li> <li>KprobeProgram</li> <li>...</li> </ul> <p>Common practice is for cluster scoped objects to include \"Cluster\" in the name and for namespaced objects to not have an identifier. So the current CRDs SHOULD have been named:</p> <ul> <li>ClusterBpfApplicationProgram</li> <li>ClusterBpfProgram</li> <li>ClusterFentryProgram</li> <li>ClusterFexitProgram</li> <li>ClusterKprobeProgram</li> <li>...</li> </ul> <p>Around the same time this feature is being developed, another feature is being developed which will break the loading and attaching of eBPF programs in bpfman into two steps. As part of this feature, all the CRDs will be completely reworked. With this in mind, the plan for adding namespace scoped CRDs is to make the namespaced CRDs carry the identifier. After the load/attach split work is complete, the CRDs will be renamed to follow the common convention in which the cluster-scoped CRD names are prefixed with \"Cluster\".</p> <p>The current plan is for the namespaced scoped CRDs to use \"NsProgram\" identifier and cluster scoped CRDs to use \"Program\" identifier. With the new namespace scope feature, below are the list of CRDs supported by bpfman-operator: <ul> <li>BpfNsApplicationProgram</li> <li>BpfApplicationProgram</li> <li>BpfNsProgram</li> <li>BpfProgram</li> <li>FentryProgram</li> <li>FexitProgram</li> <li>KprobeProgram</li> <li>TcNsProgram</li> <li>TcProgram</li> <li>TcxNsProgram</li> <li>TcxProgram</li> <li>TracepointProgram</li> <li>UprobeNsProgram</li> <li>UprobeProgram</li> <li>XdpNsProgram</li> <li>XdpProgram</li> </ul>"},{"location":"design/daemonless/","title":"Daemonless bpfd","text":""},{"location":"design/daemonless/#introduction","title":"Introduction","text":"<p>The bpfd daemon is a userspace daemon that runs on the host and responds to gRPC API requests over a unix socket, to load, unload and list the eBPF programs on a host.</p> <p>The rationale behind running as a daemon was because something needs to be listening on the unix socket for API requests, and that we also maintain some state in-memory about the programs that have been loaded. However, since this daemon requires root privileges to load and unload eBPF programs it is a security risk for this to be a long-running - even with the mitigations we have in place to drop privileges and run as a non-root user. This risk is equivalent to that of something like Docker.</p> <p>This document describes the design of a daemonless bpfd, which is a bpfd that runs only runs when required, for example, to load or unload an eBPF program.</p>"},{"location":"design/daemonless/#design","title":"Design","text":"<p>The daemonless bpfd is a single binary that collects some of the functionality from both bpfd and bpfctl.</p> <p>:note: Daemonless, not rootless. Since CAP_BPF (and more) is required to load and unload eBPF programs, we will still need to run as root. But at least we can run as root for a shorter period of time.</p>"},{"location":"design/daemonless/#command-bpfd-system-service","title":"Command: bpfd system service","text":"<p>This command will run the bpfd gRPC API server - for one or more of the gRPC API services we support.</p> <p>It will listen on a unix socket (or tcp socket) for API requests - provided via a positional argument, defaulting to <code>unix:///var/run/bpfd.sock</code>. It will shutdown after a timeout of inactivity - provided by a <code>--timeout</code> flag defaulting to 5 seconds.</p> <p>It will support being run as a systemd service, via socket activation, which will allow it to be started on demand when a request is made to the unix socket. When in this mode it will not create the unix socket itself, but will instead use LISTEN_FDS to determine the file descriptor of the unix socket to use.</p> <p>Usage in local development (or packaged in a container) is still possible by running as follows:</p> <pre><code>sudo bpfd --timeout=0 unix:///var/run/bpfd.sock\n</code></pre> <p>:note: The bpfd user and group will be deprecated. We will also remove some of the unit-file complexity (i.e directories) and handle this in bpfd itself.</p>"},{"location":"design/daemonless/#command-bpfd-load-file","title":"Command: bpfd load file","text":"<p>As the name suggests, this command will load an eBPF program from a file. This was formerly <code>bpfctl load-from-file</code>.</p>"},{"location":"design/daemonless/#command-bpfd-load-image","title":"Command: bpfd load image","text":"<p>As the name suggests, this command will load an eBPF program from a container image. This was formerly <code>bpfctl load-from-image</code>.</p>"},{"location":"design/daemonless/#command-bpfd-unload","title":"Command: bpfd unload","text":"<p>This command will unload an eBPF program. This was formerly <code>bpfctl unload</code>.</p>"},{"location":"design/daemonless/#command-bpfd-list","title":"Command: bpfd list","text":"<p>This command will list the eBPF programs that are currently loaded. This was formerly <code>bpfctl list</code>.</p>"},{"location":"design/daemonless/#command-bpfd-pull","title":"Command: bpfd pull","text":"<p>This command will pull the bpfd container image from a registry. This was formerly <code>bpfctl pull</code>.</p>"},{"location":"design/daemonless/#command-bpfd-images","title":"Command: bpfd images","text":"<p>This command will list the bpfd container images that are available. This command didn't exist, but makes sense to add.</p>"},{"location":"design/daemonless/#command-bpfd-version","title":"Command: bpfd version","text":"<p>This command will print the version of bpfd. This command didn't exist, but makes sense to add.</p>"},{"location":"design/daemonless/#state-management","title":"State Management","text":"<p>This is perhaps the most significant change from how bpfd currently works.</p> <p>Currently bpfd maintains state in-memory about the programs that have been loaded (by bpfd, and the kernel). Some of this state is flushed to disk, so if bpfd is restarted it can reconstruct it.</p> <p>Flushing to disk and state reconstruction is cumbersome at present and having to move all state management out of in-memory stores is a forcing function to improve this. We will replace the existing state management with sled, which gives us a familiar API to work with while also being fast, reliable and persistent.</p>"},{"location":"design/daemonless/#metrics-and-monitoring","title":"Metrics and Monitoring","text":"<p>While adding metrics and monitoring is not a goal of this design, it should nevertheless be a consideration. In order to provide metrics to Prometheus or OpenTelemetry we will require an additional exporter process.</p> <p>We can either:</p> <ol> <li>Use the bpfd socket and retrieve metrics via the gRPC API</li> <li>Place state access + metrics gathering functions in a library, such that    they could be used directly by the exporter process without requiring the    bpfd socket.</li> </ol> <p>The latter would be more inline with how podman-prometheus-exporter works. The benefit here is that, the metrics exporter process can be long running with less privileges - whereas if it were to hit the API over the socket it would effectively negate the point of being daemonless in the first place since collection will likley occur more frequently than the timeout on the socket.</p>"},{"location":"design/daemonless/#benefits","title":"Benefits","text":"<p>The benefits of this design are:</p> <ul> <li>No long-running daemon with root privileges</li> <li>No need to run as a non-root user, this is important since the number of   capabilities required is only getting larger.</li> <li>We only need to ship a single binary.</li> <li>We can use systemd socket activation to start bpfd on demand + timeout   after a period of inactivity.</li> <li>Forcs us to fix state management, since we can never rely on in-memory state.</li> <li>Bpfd becomes more modular - if we wish to add programs for runtime enforcement,   metrics, or any other purpose then it's design is decoupled from that of   bpfd. It could be another binary, or a subcommand on the CLI etc...</li> </ul>"},{"location":"design/daemonless/#drawbacks","title":"Drawbacks","text":"<p>None yet.</p>"},{"location":"design/daemonless/#backwards-compatibility","title":"Backwards Compatibility","text":"<ul> <li>The <code>bpfctl</code> command will be removed and all functionality folded into <code>bpfd</code></li> <li>The <code>bpfd</code> command will be renamed to <code>bpfd system service</code></li> </ul>"},{"location":"developer-guide/api-spec/","title":"API Specification","text":"<p>Packages:</p> <ul> <li> bpfman.io/v1alpha1 </li> </ul>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1","title":"bpfman.io/v1alpha1","text":"<p> <p>Package v1alpha1 contains API Schema definitions for the bpfman.io API group.</p> </p> <p>Resource Types:</p> <ul><li> BpfApplication </li><li> BpfProgram </li><li> FentryProgram </li><li> FexitProgram </li><li> KprobeProgram </li><li> TcProgram </li><li> TracepointProgram </li><li> UprobeProgram </li><li> XdpProgram </li></ul>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfApplication","title":"BpfApplication","text":"<p> <p>BpfApplication is the Schema for the bpfapplications API</p> </p> Field Description <code>apiVersion</code> string <code> bpfman.io/v1alpha1 </code> <code>kind</code> string  <code>BpfApplication</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  BpfApplicationSpec  <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p> <code>programs</code>  []BpfApplicationProgram  <p>Programs is a list of bpf programs supported for a specific application. It\u2019s possible that the application can selectively choose which program(s) to run from this list.</p> <code>status</code>  BpfApplicationStatus"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfProgram","title":"BpfProgram","text":"<p> <p>BpfProgram is the Schema for the Bpfprograms API</p> </p> Field Description <code>apiVersion</code> string <code> bpfman.io/v1alpha1 </code> <code>kind</code> string  <code>BpfProgram</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  BpfProgramSpec  <code>type</code>  string  (Optional) <p>Type specifies the bpf program type</p> <code>status</code>  BpfProgramStatus  (Optional)"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.FentryProgram","title":"FentryProgram","text":"<p> <p>FentryProgram is the Schema for the FentryPrograms API</p> </p> Field Description <code>apiVersion</code> string <code> bpfman.io/v1alpha1 </code> <code>kind</code> string  <code>FentryProgram</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  FentryProgramSpec  <code>FentryProgramInfo</code>  FentryProgramInfo  <p> (Members of <code>FentryProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p> <code>status</code>  FentryProgramStatus  (Optional)"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.FexitProgram","title":"FexitProgram","text":"<p> <p>FexitProgram is the Schema for the FexitPrograms API</p> </p> Field Description <code>apiVersion</code> string <code> bpfman.io/v1alpha1 </code> <code>kind</code> string  <code>FexitProgram</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  FexitProgramSpec  <code>FexitProgramInfo</code>  FexitProgramInfo  <p> (Members of <code>FexitProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p> <code>status</code>  FexitProgramStatus  (Optional)"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.KprobeProgram","title":"KprobeProgram","text":"<p> <p>KprobeProgram is the Schema for the KprobePrograms API</p> </p> Field Description <code>apiVersion</code> string <code> bpfman.io/v1alpha1 </code> <code>kind</code> string  <code>KprobeProgram</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  KprobeProgramSpec  <code>KprobeProgramInfo</code>  KprobeProgramInfo  <p> (Members of <code>KprobeProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p> <code>status</code>  KprobeProgramStatus  (Optional)"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.TcProgram","title":"TcProgram","text":"<p> <p>TcProgram is the Schema for the TcProgram API</p> </p> Field Description <code>apiVersion</code> string <code> bpfman.io/v1alpha1 </code> <code>kind</code> string  <code>TcProgram</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  TcProgramSpec  <code>TcProgramInfo</code>  TcProgramInfo  <p> (Members of <code>TcProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p> <code>status</code>  TcProgramStatus  (Optional)"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.TracepointProgram","title":"TracepointProgram","text":"<p> <p>TracepointProgram is the Schema for the TracepointPrograms API</p> </p> Field Description <code>apiVersion</code> string <code> bpfman.io/v1alpha1 </code> <code>kind</code> string  <code>TracepointProgram</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  TracepointProgramSpec  <code>TracepointProgramInfo</code>  TracepointProgramInfo  <p> (Members of <code>TracepointProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p> <code>status</code>  TracepointProgramStatus  (Optional)"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.UprobeProgram","title":"UprobeProgram","text":"<p> <p>UprobeProgram is the Schema for the UprobePrograms API</p> </p> Field Description <code>apiVersion</code> string <code> bpfman.io/v1alpha1 </code> <code>kind</code> string  <code>UprobeProgram</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  UprobeProgramSpec  <code>UprobeProgramInfo</code>  UprobeProgramInfo  <p> (Members of <code>UprobeProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p> <code>status</code>  UprobeProgramStatus  (Optional)"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.XdpProgram","title":"XdpProgram","text":"<p> <p>XdpProgram is the Schema for the XdpPrograms API</p> </p> Field Description <code>apiVersion</code> string <code> bpfman.io/v1alpha1 </code> <code>kind</code> string  <code>XdpProgram</code> <code>metadata</code>  Kubernetes meta/v1.ObjectMeta   Refer to the Kubernetes API documentation for the fields of the <code>metadata</code> field.  <code>spec</code>  XdpProgramSpec  <code>XdpProgramInfo</code>  XdpProgramInfo  <p> (Members of <code>XdpProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p> <code>status</code>  XdpProgramStatus  (Optional)"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfAppCommon","title":"BpfAppCommon","text":"<p> (Appears on: BpfApplicationSpec,  FentryProgramSpec,  FexitProgramSpec,  KprobeProgramSpec,  TcProgramSpec,  TracepointProgramSpec,  UprobeProgramSpec,  XdpProgramSpec) </p> <p> <p>BpfAppCommon defines the common attributes for all BpfApp programs</p> </p> Field Description <code>nodeselector</code>  Kubernetes meta/v1.LabelSelector  <p>NodeSelector allows the user to specify which nodes to deploy the bpf program to. This field must be specified, to select all nodes use standard metav1.LabelSelector semantics and make it empty.</p> <code>globaldata</code>  map[string][]byte  (Optional) <p>GlobalData allows the user to set global variables when the program is loaded with an array of raw bytes. This is a very low level primitive. The caller is responsible for formatting the byte string appropriately considering such things as size, endianness, alignment and packing of data structures.</p> <code>bytecode</code>  BytecodeSelector  <p>Bytecode configures where the bpf program\u2019s bytecode should be loaded from.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfApplicationProgram","title":"BpfApplicationProgram","text":"<p> (Appears on: BpfApplicationSpec) </p> <p> <p>BpfApplicationProgram defines the desired state of BpfApplication</p> </p> Field Description <code>type</code>  EBPFProgType  <p>Type specifies the bpf program type</p> <code>xdp</code>  XdpProgramInfo  (Optional) <p>xdp defines the desired state of the application\u2019s XdpPrograms.</p> <code>tc</code>  TcProgramInfo  (Optional) <p>tc defines the desired state of the application\u2019s TcPrograms.</p> <code>tcx</code>  TcProgramInfo  (Optional) <p>tcx defines the desired state of the application\u2019s TcPrograms.</p> <code>fentry</code>  FentryProgramInfo  (Optional) <p>fentry defines the desired state of the application\u2019s FentryPrograms.</p> <code>fexit</code>  FexitProgramInfo  (Optional) <p>fexit defines the desired state of the application\u2019s FexitPrograms.</p> <code>kprobe</code>  KprobeProgramInfo  (Optional) <p>kprobe defines the desired state of the application\u2019s KprobePrograms.</p> <code>kretprobe</code>  KprobeProgramInfo  (Optional) <p>kretprobe defines the desired state of the application\u2019s KretprobePrograms.</p> <code>uprobe</code>  UprobeProgramInfo  (Optional) <p>uprobe defines the desired state of the application\u2019s UprobePrograms.</p> <code>uretprobe</code>  UprobeProgramInfo  (Optional) <p>uretprobe defines the desired state of the application\u2019s UretprobePrograms.</p> <code>tracepoint</code>  TracepointProgramInfo  (Optional) <p>tracepoint defines the desired state of the application\u2019s TracepointPrograms.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfApplicationSpec","title":"BpfApplicationSpec","text":"<p> (Appears on: BpfApplication) </p> <p> <p>BpfApplicationSpec defines the desired state of BpfApplication</p> </p> Field Description <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p> <code>programs</code>  []BpfApplicationProgram  <p>Programs is a list of bpf programs supported for a specific application. It\u2019s possible that the application can selectively choose which program(s) to run from this list.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfApplicationStatus","title":"BpfApplicationStatus","text":"<p> (Appears on: BpfApplication) </p> <p> <p>BpfApplicationStatus defines the observed state of BpfApplication</p> </p> Field Description <code>BpfProgramStatusCommon</code>  BpfProgramStatusCommon  <p> (Members of <code>BpfProgramStatusCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfProgramCommon","title":"BpfProgramCommon","text":"<p> (Appears on: FentryProgramInfo,  FexitProgramInfo,  KprobeProgramInfo,  TcProgramInfo,  TracepointProgramInfo,  UprobeProgramInfo,  XdpProgramInfo) </p> <p> <p>BpfProgramCommon defines the common attributes for all BPF programs</p> </p> Field Description <code>bpffunctionname</code>  string  <p>BpfFunctionName is the name of the function that is the entry point for the BPF program</p> <code>mapownerselector</code>  Kubernetes meta/v1.LabelSelector  (Optional) <p>MapOwnerSelector is used to select the loaded eBPF program this eBPF program will share a map with. The value is a label applied to the BpfProgram to select. The selector must resolve to exactly one instance of a BpfProgram on a given node or the eBPF program will not load.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfProgramConditionType","title":"BpfProgramConditionType (<code>string</code> alias)","text":"<p> <p>BpfProgramConditionType is a condition type to indicate the status of a BPF program at the individual node level.</p> </p> Value Description <p>\"BytecodeSelectorError\"</p> <p>BpfProgCondBytecodeSelectorError indicates that an error occurred when trying to process the bytecode selector.</p> <p>\"Loaded\"</p> <p>BpfProgCondLoaded indicates that the eBPF program was successfully loaded into the kernel on a specific node.</p> <p>\"MapOwnerNotFound\"</p> <p>BpfProgCondMapOwnerNotFound indicates that the eBPF program sharing a map with another eBPF program and that program does not exist.</p> <p>\"MapOwnerNotLoaded\"</p> <p>BpfProgCondMapOwnerNotLoaded indicates that the eBPF program sharing a map with another eBPF program and that program is not loaded.</p> <p>\"NoContainersOnNode\"</p> <p>BpfProgCondNoContainersOnNode indicates that there are no containers on the node that match the container selector.</p> <p>\"None\"</p> <p>None of the above conditions apply</p> <p>\"NotLoaded\"</p> <p>BpfProgCondNotLoaded indicates that the eBPF program has not yet been loaded into the kernel on a specific node.</p> <p>\"NotSelected\"</p> <p>BpfProgCondNotSelected indicates that the eBPF program is not scheduled to be loaded on a specific node.</p> <p>\"NotUnLoaded\"</p> <p>BpfProgCondUnloaded indicates that in the midst of trying to remove the eBPF program from the kernel on the node, that program has not yet been removed.</p> <p>\"Unloaded\"</p> <p>BpfProgCondUnloaded indicates that the eBPF program has been unloaded from the kernel on a specific node.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfProgramSpec","title":"BpfProgramSpec","text":"<p> (Appears on: BpfProgram) </p> <p> <p>BpfProgramSpec defines the desired state of BpfProgram</p> </p> Field Description <code>type</code>  string  (Optional) <p>Type specifies the bpf program type</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfProgramStatus","title":"BpfProgramStatus","text":"<p> (Appears on: BpfProgram) </p> <p> <p>BpfProgramStatus defines the observed state of BpfProgram TODO Make these a fixed set of metav1.Condition.types and metav1.Condition.reasons</p> </p> Field Description <code>conditions</code>  []Kubernetes meta/v1.Condition  <p>Conditions houses the updates regarding the actual implementation of the bpf program on the node Known .status.conditions.type are: \u201cAvailable\u201d, \u201cProgressing\u201d, and \u201cDegraded\u201d</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BpfProgramStatusCommon","title":"BpfProgramStatusCommon","text":"<p> (Appears on: BpfApplicationStatus,  FentryProgramStatus,  FexitProgramStatus,  KprobeProgramStatus,  TcProgramStatus,  TracepointProgramStatus,  UprobeProgramStatus,  XdpProgramStatus) </p> <p> <p>BpfProgramStatusCommon defines the BpfProgram status</p> </p> Field Description <code>conditions</code>  []Kubernetes meta/v1.Condition  <p>Conditions houses the global cluster state for the eBPFProgram. The explicit condition types are defined internally.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BytecodeImage","title":"BytecodeImage","text":"<p> (Appears on: BytecodeSelector) </p> <p> <p>BytecodeImage defines how to specify a bytecode container image.</p> </p> Field Description <code>url</code>  string  <p>Valid container image URL used to reference a remote bytecode image.</p> <code>imagepullpolicy</code>  PullPolicy  (Optional) <p>PullPolicy describes a policy for if/when to pull a bytecode image. Defaults to IfNotPresent.</p> <code>imagepullsecret</code>  ImagePullSecretSelector  (Optional) <p>ImagePullSecret is the name of the secret bpfman should use to get remote image repository secrets.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.BytecodeSelector","title":"BytecodeSelector","text":"<p> (Appears on: BpfAppCommon) </p> <p> <p>BytecodeSelector defines the various ways to reference bpf bytecode objects.</p> </p> Field Description <code>image</code>  BytecodeImage  <p>Image used to specify a bytecode container image.</p> <code>path</code>  string  <p>Path is used to specify a bytecode object via filepath.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.ContainerSelector","title":"ContainerSelector","text":"<p> (Appears on: UprobeProgramInfo) </p> <p> <p>ContainerSelector identifies a set of containers. For example, this can be used to identify a set of containers in which to attach uprobes.</p> </p> Field Description <code>namespace</code>  string  (Optional) <p>Target namespaces.</p> <code>pods</code>  Kubernetes meta/v1.LabelSelector  <p>Target pods. This field must be specified, to select all pods use standard metav1.LabelSelector semantics and make it empty.</p> <code>containernames</code>  []string  (Optional) <p>Name(s) of container(s).  If none are specified, all containers in the pod are selected.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.EBPFProgType","title":"EBPFProgType (<code>string</code> alias)","text":"<p> (Appears on: BpfApplicationProgram) </p> <p> <p>EBPFProgType defines the supported eBPF program types</p> </p> Value Description <p>\"Fentry\"</p> <p>ProgTypeFentry refers to the Fentry program type.</p> <p>\"Fexit\"</p> <p>ProgTypeFexit refers to the Fexit program type.</p> <p>\"Kprobe\"</p> <p>ProgTypeKprobe refers to the Kprobe program type.</p> <p>\"Kretprobe\"</p> <p>ProgTypeKretprobe refers to the Kprobe program type.</p> <p>\"TC\"</p> <p>ProgTypeTC refers to the TC program type.</p> <p>\"TCX\"</p> <p>ProgTypeTCX refers to the TCx program type.</p> <p>\"Tracepoint\"</p> <p>ProgTypeTracepoint refers to the Tracepoint program type.</p> <p>\"Uprobe\"</p> <p>ProgTypeUprobe refers to the Uprobe program type.</p> <p>\"Uretprobe\"</p> <p>ProgTypeUretprobe refers to the Uretprobe program type.</p> <p>\"XDP\"</p> <p>ProgTypeXDP refers to the XDP program type.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.FentryProgramInfo","title":"FentryProgramInfo","text":"<p> (Appears on: BpfApplicationProgram,  FentryProgramSpec) </p> <p> <p>FentryProgramInfo defines the Fentry program details</p> </p> Field Description <code>BpfProgramCommon</code>  BpfProgramCommon  <p> (Members of <code>BpfProgramCommon</code> are embedded into this type.) </p> <code>func_name</code>  string  <p>Function to attach the fentry to.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.FentryProgramSpec","title":"FentryProgramSpec","text":"<p> (Appears on: FentryProgram) </p> <p> <p>FentryProgramSpec defines the desired state of FentryProgram</p> </p> Field Description <code>FentryProgramInfo</code>  FentryProgramInfo  <p> (Members of <code>FentryProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.FentryProgramStatus","title":"FentryProgramStatus","text":"<p> (Appears on: FentryProgram) </p> <p> <p>FentryProgramStatus defines the observed state of FentryProgram</p> </p> Field Description <code>BpfProgramStatusCommon</code>  BpfProgramStatusCommon  <p> (Members of <code>BpfProgramStatusCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.FexitProgramInfo","title":"FexitProgramInfo","text":"<p> (Appears on: BpfApplicationProgram,  FexitProgramSpec) </p> <p> <p>FexitProgramInfo defines the Fexit program details</p> </p> Field Description <code>BpfProgramCommon</code>  BpfProgramCommon  <p> (Members of <code>BpfProgramCommon</code> are embedded into this type.) </p> <code>func_name</code>  string  <p>Function to attach the fexit to.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.FexitProgramSpec","title":"FexitProgramSpec","text":"<p> (Appears on: FexitProgram) </p> <p> <p>FexitProgramSpec defines the desired state of FexitProgram</p> </p> Field Description <code>FexitProgramInfo</code>  FexitProgramInfo  <p> (Members of <code>FexitProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.FexitProgramStatus","title":"FexitProgramStatus","text":"<p> (Appears on: FexitProgram) </p> <p> <p>FexitProgramStatus defines the observed state of FexitProgram</p> </p> Field Description <code>BpfProgramStatusCommon</code>  BpfProgramStatusCommon  <p> (Members of <code>BpfProgramStatusCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.ImagePullSecretSelector","title":"ImagePullSecretSelector","text":"<p> (Appears on: BytecodeImage) </p> <p> <p>ImagePullSecretSelector defines the name and namespace of an image pull secret.</p> </p> Field Description <code>name</code>  string  <p>Name of the secret which contains the credentials to access the image repository.</p> <code>namespace</code>  string  <p>Namespace of the secret which contains the credentials to access the image repository.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.InterfaceSelector","title":"InterfaceSelector","text":"<p> (Appears on: TcProgramInfo,  XdpProgramInfo) </p> <p> <p>InterfaceSelector defines interface to attach to.</p> </p> Field Description <code>interfaces</code>  []string  (Optional) <p>Interfaces refers to a list of network interfaces to attach the BPF program to.</p> <code>primarynodeinterface</code>  bool  (Optional) <p>Attach BPF program to the primary interface on the node. Only \u2018true\u2019 accepted.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.KprobeProgramInfo","title":"KprobeProgramInfo","text":"<p> (Appears on: BpfApplicationProgram,  KprobeProgramSpec) </p> <p> <p>KprobeProgramInfo defines the common fields for KprobeProgram</p> </p> Field Description <code>BpfProgramCommon</code>  BpfProgramCommon  <p> (Members of <code>BpfProgramCommon</code> are embedded into this type.) </p> <code>func_name</code>  string  <p>Functions to attach the kprobe to.</p> <code>offset</code>  uint64  (Optional) <p>Offset added to the address of the function for kprobe. Not allowed for kretprobes.</p> <code>retprobe</code>  bool  (Optional) <p>Whether the program is a kretprobe.  Default is false</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.KprobeProgramSpec","title":"KprobeProgramSpec","text":"<p> (Appears on: KprobeProgram) </p> <p> <p>KprobeProgramSpec defines the desired state of KprobeProgram</p> </p> Field Description <code>KprobeProgramInfo</code>  KprobeProgramInfo  <p> (Members of <code>KprobeProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.KprobeProgramStatus","title":"KprobeProgramStatus","text":"<p> (Appears on: KprobeProgram) </p> <p> <p>KprobeProgramStatus defines the observed state of KprobeProgram</p> </p> Field Description <code>BpfProgramStatusCommon</code>  BpfProgramStatusCommon  <p> (Members of <code>BpfProgramStatusCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.ProgramConditionType","title":"ProgramConditionType (<code>string</code> alias)","text":"<p> <p>ProgramConditionType is a condition type to indicate the status of a BPF program at the cluster level.</p> </p> Value Description <p>\"DeleteError\"</p> <p>ProgramDeleteError indicates that the BPF program was marked for deletion, but deletion was unsuccessful.</p> <p>\"NotYetLoaded\"</p> <p>ProgramNotYetLoaded indicates that the program in question has not yet been loaded on all nodes in the cluster.</p> <p>\"ReconcileError\"</p> <p>ProgramReconcileError indicates that an unforeseen situation has occurred in the controller logic, and the controller will retry.</p> <p>\"ReconcileSuccess\"</p> <p>BpfmanProgConfigReconcileSuccess indicates that the BPF program has been successfully reconciled.</p> <p>TODO: we should consider removing \u201creconciled\u201d type logic from the public API as it\u2019s an implementation detail of our use of controller runtime, but not necessarily relevant to human users or integrations.</p> <p>See: https://github.com/bpfman/bpfman/issues/430</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.PullPolicy","title":"PullPolicy (<code>string</code> alias)","text":"<p> (Appears on: BytecodeImage) </p> <p> <p>PullPolicy describes a policy for if/when to pull a container image</p> </p> Value Description <p>\"Always\"</p> <p>PullAlways means that bpfman always attempts to pull the latest bytecode image. Container will fail If the pull fails.</p> <p>\"IfNotPresent\"</p> <p>PullIfNotPresent means that bpfman pulls if the image isn\u2019t present on disk. Container will fail if the image isn\u2019t present and the pull fails.</p> <p>\"Never\"</p> <p>PullNever means that bpfman never pulls an image, but only uses a local image. Container will fail if the image isn\u2019t present</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.TcProceedOnValue","title":"TcProceedOnValue (<code>string</code> alias)","text":"<p> (Appears on: TcProgramInfo) </p> <p> </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.TcProgramInfo","title":"TcProgramInfo","text":"<p> (Appears on: BpfApplicationProgram,  TcProgramSpec) </p> <p> <p>TcProgramInfo defines the tc program details</p> </p> Field Description <code>BpfProgramCommon</code>  BpfProgramCommon  <p> (Members of <code>BpfProgramCommon</code> are embedded into this type.) </p> <code>interfaceselector</code>  InterfaceSelector  <p>Selector to determine the network interface (or interfaces)</p> <code>priority</code>  int32  <p>Priority specifies the priority of the tc program in relation to other programs of the same type with the same attach point. It is a value from 0 to 1000 where lower values have higher precedence.</p> <code>direction</code>  string  <p>Direction specifies the direction of traffic the tc program should attach to for a given network device.</p> <code>proceedon</code>  []TcProceedOnValue  (Optional) <p>ProceedOn allows the user to call other tc programs in chain on this exit code. Multiple values are supported by repeating the parameter.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.TcProgramSpec","title":"TcProgramSpec","text":"<p> (Appears on: TcProgram) </p> <p> <p>TcProgramSpec defines the desired state of TcProgram</p> </p> Field Description <code>TcProgramInfo</code>  TcProgramInfo  <p> (Members of <code>TcProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.TcProgramStatus","title":"TcProgramStatus","text":"<p> (Appears on: TcProgram) </p> <p> <p>TcProgramStatus defines the observed state of TcProgram</p> </p> Field Description <code>BpfProgramStatusCommon</code>  BpfProgramStatusCommon  <p> (Members of <code>BpfProgramStatusCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.TracepointProgramInfo","title":"TracepointProgramInfo","text":"<p> (Appears on: BpfApplicationProgram,  TracepointProgramSpec) </p> <p> <p>TracepointProgramInfo defines the Tracepoint program details</p> </p> Field Description <code>BpfProgramCommon</code>  BpfProgramCommon  <p> (Members of <code>BpfProgramCommon</code> are embedded into this type.) </p> <code>names</code>  []string  <p>Names refers to the names of kernel tracepoints to attach the bpf program to.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.TracepointProgramSpec","title":"TracepointProgramSpec","text":"<p> (Appears on: TracepointProgram) </p> <p> <p>TracepointProgramSpec defines the desired state of TracepointProgram</p> </p> Field Description <code>TracepointProgramInfo</code>  TracepointProgramInfo  <p> (Members of <code>TracepointProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.TracepointProgramStatus","title":"TracepointProgramStatus","text":"<p> (Appears on: TracepointProgram) </p> <p> <p>TracepointProgramStatus defines the observed state of TracepointProgram</p> </p> Field Description <code>BpfProgramStatusCommon</code>  BpfProgramStatusCommon  <p> (Members of <code>BpfProgramStatusCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.UprobeProgramInfo","title":"UprobeProgramInfo","text":"<p> (Appears on: BpfApplicationProgram,  UprobeProgramSpec) </p> <p> <p>UprobeProgramInfo contains the information about the uprobe program</p> </p> Field Description <code>BpfProgramCommon</code>  BpfProgramCommon  <p> (Members of <code>BpfProgramCommon</code> are embedded into this type.) </p> <code>func_name</code>  string  (Optional) <p>Function to attach the uprobe to.</p> <code>offset</code>  uint64  (Optional) <p>Offset added to the address of the function for uprobe.</p> <code>target</code>  string  <p>Library name or the absolute path to a binary or library.</p> <code>retprobe</code>  bool  (Optional) <p>Whether the program is a uretprobe.  Default is false</p> <code>pid</code>  int32  (Optional) <p>Only execute uprobe for given process identification number (PID). If PID is not provided, uprobe executes for all PIDs.</p> <code>containers</code>  ContainerSelector  (Optional) <p>Containers identifes the set of containers in which to attach the uprobe. If Containers is not specified, the uprobe will be attached in the bpfman-agent container.  The ContainerSelector is very flexible and even allows the selection of all containers in a cluster.  If an attempt is made to attach uprobes to too many containers, it can have a negative impact on on the cluster.</p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.UprobeProgramSpec","title":"UprobeProgramSpec","text":"<p> (Appears on: UprobeProgram) </p> <p> <p>UprobeProgramSpec defines the desired state of UprobeProgram</p> </p> Field Description <code>UprobeProgramInfo</code>  UprobeProgramInfo  <p> (Members of <code>UprobeProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.UprobeProgramStatus","title":"UprobeProgramStatus","text":"<p> (Appears on: UprobeProgram) </p> <p> <p>UprobeProgramStatus defines the observed state of UprobeProgram</p> </p> Field Description <code>BpfProgramStatusCommon</code>  BpfProgramStatusCommon  <p> (Members of <code>BpfProgramStatusCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.XdpProceedOnValue","title":"XdpProceedOnValue (<code>string</code> alias)","text":"<p> (Appears on: XdpProgramInfo) </p> <p> </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.XdpProgramInfo","title":"XdpProgramInfo","text":"<p> (Appears on: BpfApplicationProgram,  XdpProgramSpec) </p> <p> <p>XdpProgramInfo defines the common fields for all XdpProgram types</p> </p> Field Description <code>BpfProgramCommon</code>  BpfProgramCommon  <p> (Members of <code>BpfProgramCommon</code> are embedded into this type.) </p> <code>interfaceselector</code>  InterfaceSelector  <p>Selector to determine the network interface (or interfaces)</p> <code>priority</code>  int32  <p>Priority specifies the priority of the bpf program in relation to other programs of the same type with the same attach point. It is a value from 0 to 1000 where lower values have higher precedence.</p> <code>proceedon</code>  []XdpProceedOnValue"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.XdpProgramSpec","title":"XdpProgramSpec","text":"<p> (Appears on: XdpProgram) </p> <p> <p>XdpProgramSpec defines the desired state of XdpProgram</p> </p> Field Description <code>XdpProgramInfo</code>  XdpProgramInfo  <p> (Members of <code>XdpProgramInfo</code> are embedded into this type.) </p> <code>BpfAppCommon</code>  BpfAppCommon  <p> (Members of <code>BpfAppCommon</code> are embedded into this type.) </p>"},{"location":"developer-guide/api-spec/#bpfman.io/v1alpha1.XdpProgramStatus","title":"XdpProgramStatus","text":"<p> (Appears on: XdpProgram) </p> <p> <p>XdpProgramStatus defines the observed state of XdpProgram</p> </p> Field Description <code>BpfProgramStatusCommon</code>  BpfProgramStatusCommon  <p> (Members of <code>BpfProgramStatusCommon</code> are embedded into this type.) </p> <p> Generated with <code>gen-crd-api-reference-docs</code>. </p>"},{"location":"developer-guide/configuration/","title":"Configuration","text":""},{"location":"developer-guide/configuration/#bpfman-configuration-file","title":"bpfman Configuration File","text":"<p>bpfman looks for a configuration file to be present at <code>/etc/bpfman/bpfman.toml</code>. If no file is found, defaults are assumed. There is an example at <code>scripts/bpfman.toml</code>, similar to:</p> <pre><code>[interfaces]\n  [interfaces.eth0]\n  xdp_mode = \"drv\" # Valid xdp modes are \"hw\", \"skb\" and \"drv\". Default: \"drv\", but will fall back to \"skb\" on failure.\n\n[signing]\nallow_unsigned = true\nverify_enabled = true\n\n[database]\nmax_retries = 10\nmillisec_delay = 1000\n</code></pre>"},{"location":"developer-guide/configuration/#config-section-interfaces","title":"Config Section: [interfaces]","text":"<p>This section of the configuration file allows the XDP Mode for a given interface to be set. If not set, the default value of <code>skb</code> will be used. Multiple interfaces can be configured.</p> <pre><code>[interfaces]\n  [interfaces.eth0]\n  xdp_mode = \"drv\"\n  [interfaces.eth1]\n  xdp_mode = \"hw\"\n  [interfaces.eth2]\n  xdp_mode = \"skb\"\n</code></pre> <p>Valid fields:</p> <ul> <li>xdp_mode: XDP Mode for a given interface. Valid values: [\"drv\"|\"hw\"|\"skb\"]</li> </ul>"},{"location":"developer-guide/configuration/#config-section-signing","title":"Config Section: [signing]","text":"<p>This section of the configuration file allows control over whether signatures on OCI packaged eBPF bytecode as container images are verified, and whether they are required to be signed via cosign.</p> <p>By default, images are verified, and unsigned images are allowed. See eBPF Bytecode Image Specifications for more details on building and shipping bytecode in a container image.</p> <p>Valid fields:</p> <ul> <li> <p>allow_unsigned: Flag indicating whether unsigned images are allowed.   Valid values: [\"true\"|\"false\"]</p> </li> <li> <p>verify_enabled: Flag indicating whether signatures should be verified.   Valid values: [\"true\"|\"false\"]</p> </li> </ul>"},{"location":"developer-guide/configuration/#config-section-database","title":"Config Section: [database]","text":"<p><code>bpfman</code> uses an embedded database to store state and persistent data on disk which can only be accessed synchronously by a single process at a time. To avoid returning database lock errors and enhance the user experience, bpfman performs retries when opening of the database. The number of retries and the time between retries is configurable.</p> <p>Valid fields:</p> <ul> <li>max_retries: The number of times to retry opening the database on a given request.</li> <li>millisec_delay: Time in milliseconds to wait between retry attempts.</li> </ul>"},{"location":"developer-guide/configuration/#config-section-registry","title":"Config Section: [registry]","text":"<p><code>bpfman</code> uses the latest public container images for the xdp and tc dispatchers by default.  Optionally, the configuration values for these images are user-configurable. For example, it may be desirable in certain enterprise environments to source the xdp and tc dispatcher images from  a self-hosted OCI image registry.  In this case, the default values for the xdp and tc dispatcher images can be overridden below. </p> <p>Valid fields:</p> <ul> <li>xdp_dispatcher_image: The locator of the xdp dispatcher image in the format <code>quay.io/bpfman/xdp-dispatcher:latest</code></li> <li>tc_dispatcher_image: The locator of the tc dispatcher image in the format <code>quay.io/bpfman/tc-dispatcher:latest</code></li> </ul>"},{"location":"developer-guide/debugging/","title":"Debugging using VSCode and lldb on a remote machine or VM","text":"<ol> <li>Install code-lldb vscode extension</li> <li> <p>Add a configuration to <code>.vscode/launch.json</code> like the following (customizing for a given system using the comment in the configuration file):</p> <pre><code>    {\n        \"name\": \"Remote debug bpfman\",\n        \"type\": \"lldb\",\n        \"request\": \"launch\",\n        \"program\": \"&lt;ABSOLUTE_PATH&gt;/github.com/bpfman/bpfman/target/debug/bpfman\", // Local path to latest debug binary.\n        \"initCommands\": [\n            \"platform select remote-linux\", // Execute `platform list` for a list of available remote platform plugins.\n            \"platform connect connect://&lt;IP_ADDRESS_OF_VM&gt;:8175\", // replace &lt;IP_ADDRESS_OF_VM&gt;\n            \"settings set target.inherit-env false\",\n        ],\n        \"env\": {\n            \"RUST_LOG\": \"debug\"\n        },\n        \"cargo\": {\n            \"args\": [\n                \"build\",\n                \"--bin=bpfman\",\n                \"--package=bpfman\"\n            ],\n            \"filter\": {\n                \"name\": \"bpfman\",\n                \"kind\": \"bin\"\n            }\n        },\n        \"cwd\": \"${workspaceFolder}\",\n    },\n</code></pre> </li> <li> <p>On the VM or Server install <code>lldb-server</code>:</p> <p><code>dnf</code> based OS: <pre><code>    sudo dnf install lldb\n</code></pre></p> <p><code>apt</code> based OS:</p> <pre><code>    sudo apt install lldb\n</code></pre> </li> <li> <p>Start <code>lldb-server</code> on the VM or Server (make sure to do this in the <code>~/home</code> directory)</p> <pre><code>    cd ~\n    sudo lldb-server platform --server --listen 0.0.0.0:8081\n</code></pre> </li> <li> <p>Add breakpoints as needed via the vscode GUI and then hit <code>F5</code> to start debugging!</p> </li> </ol>"},{"location":"developer-guide/develop-operator/","title":"Developing the bpfman-operator","text":"<p>This section is intended to give developer level details regarding the layout and design of the bpfman-operator. At its core the operator was implemented using the operator-sdk framework, which make those docs another good resource if anything is missed here.</p>"},{"location":"developer-guide/develop-operator/#high-level-design-overview","title":"High level design overview","text":"<p>This repository houses two main processes, the <code>bpfman-agent</code> and the <code>bpfman-operator</code>, along with CRD api definitions for <code>BpfProgram</code> and <code>*Program</code> Objects. The following diagram depicts how all these components work together to create a functioning operator.</p> <p></p> <p>The <code>bpfman-operator</code> is running as a Deployment with a ReplicaSet of one. It runs on the control plane and is composed of the containers <code>bpfman-operator</code> and <code>kube-rbac-proxy</code>. The operator is responsible for launching the bpfman Daemonset, which runs on every node. The bpfman Daemonset is composed of the containers <code>bpfman</code>, <code>bpfman-agent</code>, and <code>node-driver-registrar</code>.</p>"},{"location":"developer-guide/develop-operator/#building-and-deploying","title":"Building and Deploying","text":"<p>For building and deploying the bpfman-operator, simply see the attached <code>make help</code> output.</p> <pre><code>$ make help\n\nUsage:\n  make &lt;target&gt;\n\nGeneral\n  help             Display this help.\n\nLocal Dependencies\n  kustomize        Download kustomize locally if necessary.\n  controller-gen   Download controller-gen locally if necessary.\n  register-gen     Download register-gen locally if necessary.\n  informer-gen     Download informer-gen locally if necessary.\n  lister-gen       Download lister-gen locally if necessary.\n  client-gen       Download client-gen locally if necessary.\n  envtest          Download envtest-setup locally if necessary.\n  opm              Download opm locally if necessary.\n\nDevelopment\n  manifests        Generate WebhookConfiguration, ClusterRole and CustomResourceDefinition objects.\n  generate         Generate ALL auto-generated code.\n  generate-register  Generate register code see all `zz_generated.register.go` files.\n  generate-deepcopy  Generate code containing DeepCopy, DeepCopyInto, and DeepCopyObject method implementations see all `zz_generated.register.go` files.\n  generate-typed-clients  Generate typed client code\n  generate-typed-listers  Generate typed listers code\n  generate-typed-informers  Generate typed informers code\n  vendors          Refresh vendors directory.\n  fmt              Run go fmt against code.\n  verify           Verify all the autogenerated code\n  lint             Run linter (golangci-lint).\n  test             Run Unit tests.\n  test-integration  Run Integration tests.\n  bundle           Generate bundle manifests and metadata, then validate generated files.\n  build-release-yamls  Generate the crd install bundle for a specific release version.\n\nBuild\n  build            Build bpfman-operator and bpfman-agent binaries.\n  build-images     Build bpfman-agent and bpfman-operator images.\n  build-operator-image  Build bpfman-operator image.\n  build-agent-image  Build bpfman-agent image.\n  push-images      Push bpfman-agent and bpfman-operator images.\n  load-images-kind  Load bpfman-agent, and bpfman-operator images into the running local kind devel cluster.\n  bundle-build     Build the bundle image.\n  bundle-push      Push the bundle image.\n  catalog-build    Build a catalog image.\n  catalog-push     Push a catalog image.\n\nCRD Deployment\n  install          Install CRDs into the K8s cluster specified in ~/.kube/config.\n  uninstall        Uninstall CRDs from the K8s cluster specified in ~/.kube/config. Call with ignore-not-found=true to ignore resource not found errors during deletion.\n\nVanilla K8s Deployment\n  setup-kind       Setup Kind cluster\n  destroy-kind     Destroy Kind cluster\n  deploy           Deploy bpfman-operator to the K8s cluster specified in ~/.kube/config with the csi driver initialized.\n  undeploy         Undeploy bpfman-operator from the K8s cluster specified in ~/.kube/config. Call with ignore-not-found=true to ignore resource not found errors during deletion.\n  kind-reload-images  Reload locally build images into a kind cluster and restart the ds and deployment so they're picked up.\n  run-on-kind      Kind Deploy runs the bpfman-operator on a local kind cluster using local builds of bpfman, bpfman-agent, and bpfman-operator\n\nOpenshift Deployment\n  deploy-openshift  Deploy bpfman-operator to the Openshift cluster specified in ~/.kube/config.\n  undeploy-openshift  Undeploy bpfman-operator from the Openshift cluster specified in ~/.kube/config. Call with ignore-not-found=true to ignore resource not found errors during deletion.\n  catalog-deploy   Deploy a catalog image.\n  catalog-undeploy  Undeploy a catalog image.\n</code></pre>"},{"location":"developer-guide/develop-operator/#project-layout","title":"Project Layout","text":"<p>The bpfman-operator project layout is guided by the recommendations from both the operator-sdk framework and the standard golang project-layout. The following is a brief description of the main directories under <code>bpfman-operator/</code> and their contents.</p> <p>NOTE: Bolded directories contain auto-generated code</p> <ul> <li><code>apis/v1alpha1/*_types.go</code>: Contains the K8s CRD api definitions (<code>*_types.go</code>) for each program type.</li> <li>apis/v1alpha1/zz_generated.*.go: Contains the auto-generated register (<code>zz_generate.register.go</code>)   and deep copy (<code>zz_generated.deepcopy.go</code>) methods.</li> <li>bundle/: Contains the bundle manifests and metadata for the operator.   More details can be found in the operator-sdk documentation.</li> <li><code>cmd/</code>: Contains the main entry-points for the bpfman-operator and bpfman-agent processes.</li> <li><code>config/</code>: Contains the configuration files for launching the bpfman-operator on a cluster.<ul> <li><code>bpfman-deployment/</code>: Contains static deployment yamls for the bpfman-daemon.   This includes two containers, one for <code>bpfman</code> and the other for the <code>bpfman-agent</code>.   This DaemonSet yaml is NOT deployed statically by kustomize, instead it's statically copied into the operator   image which is then responsible for deploying and configuring the bpfman-daemon DaemonSet.   Lastly, this directory also contains the default config used to configure the bpfman-daemon, along with the   cert-manager certificates used to encrypt communication between the bpfman-agent and bpfman.</li> <li><code>bpfman-operator-deployment/</code>: Contains the static deployment yaml for the bpfman-operator.   This is deployed statically by kustomize.</li> <li><code>crd/</code>: Contains the CRD manifests for all of the bpfman-operator APIs.<ul> <li>bases/: This is where the actual CRD definitions are stored.   These definitions are auto-generated by controller-gen.</li> <li><code>patches/</code>: Contains kustomize patch files for each Program Type, which enables a conversion webhook for    the CRD and adds a directive for certmanager to inject CA into the CRD.</li> </ul> </li> <li><code>default/</code>: Contains the default deployment configuration for the bpfman-operator.</li> <li><code>manifests/</code>: Contains the bases for generating OLM manifests.</li> <li><code>openshift/</code>: Contains the Openshift specific deployment configuration for the bpfman-operator.</li> <li><code>prometheus/</code>: Contains the prometheus manifests used to deploy Prometheus to a cluster.   At the time of writing this the bpfman-operator is NOT exposing any metrics to prometheus, but this is a future goal.</li> <li>rbac/: Contains RBAC yamls for getting bpfman and the bpfman-operator up and running on Kubernetes.<ul> <li>bpfman-agent/: Contains the RBAC yamls for the bpfman-agent. They are automatically generated by kubebuilder via build tags in the bpfman-agent controller code.</li> <li>bpfman-operator/: Contains the RBAC yamls for the bpfman-operator. They are automatically generated by kubebuilder via build tags in the bpfman-operator controller code.</li> </ul> </li> <li><code>samples/</code>: Contains CRD samples that can be deployed by users for each of our supported APIs.</li> <li><code>scorecard/</code>: Contains the scorecard manifests used to deploy scorecard to a cluster. At the time of writing   this the bpfman-operator is NOT running any scorecard tests.</li> <li><code>test/</code>: Contains the test manifests used to deploy the bpfman-operator to a kind cluster for integration testing.</li> </ul> </li> <li><code>controllers/</code>: Contains the controller implementations for all of the bpfman-operator APIs.   Each controller is responsible for reconciling the state of the cluster with the desired state defined by the user.   This is where the source of truth for the auto-generated RBAC can be found, keep an eye out for   <code>//+kubebuilder:rbac:groups=bpfman.io</code> comment tags.<ul> <li><code>bpfmanagent/</code>: Contains the controller implementations which reconcile user created <code>*Program</code> types to multiple   <code>BpfProgram</code> objects.</li> <li><code>bpfmanoperator/</code>: Contains the controller implementations which reconcile global <code>BpfProgram</code> object state back to   the user by ensuring the user created <code>*Program</code> objects are reporting the correct status.</li> </ul> </li> <li><code>hack/</code>: Contains any scripts+static files used by the bpfman-operator to facilitate development.</li> <li><code>internal/</code>: Contains all private library code and is used by the bpfman-operator and bpfman-agent controllers.</li> <li><code>pkg/</code>: Contains all public library code this is consumed externally and internally.<ul> <li>client/: Contains the autogenerated clientset, informers and listers for all of the bpfman-operator APIs.   These are autogenerated by the k8s.io/code-generator project,   and can be consumed by users wishing to programmatically interact with bpfman specific APIs.</li> <li><code>helpers/</code>: Contains helper functions which can be consumed by users wishing to programmatically interact with   bpfman specific APIs.</li> </ul> </li> <li><code>test/integration/</code>: Contains integration tests for the bpfman-operator.   These tests are run against a kind cluster and are responsible for testing the bpfman-operator in a real cluster   environment.   It uses the kubernetes-testing-framework project to   programmatically spin-up all of the required infrastructure for our unit tests.</li> <li><code>Makefile</code>: Contains all of the make targets used to build, test, and generate code used by the bpfman-operator.</li> </ul>"},{"location":"developer-guide/develop-operator/#rpc-protobuf-generation","title":"RPC Protobuf Generation","text":"<p>Technically part of the <code>bpfman</code> API, the RPC Protobufs are usually not coded until a bpfman feature is integrated into the <code>bpfman-operator</code> and <code>bpfman-agent</code> code. To modify the RPC Protobuf definition, edit proto/bpfman.proto. Then to generate the protobufs from the updated RPC Protobuf definitions:</p> <pre><code>cd bpfman/\ncargo xtask build-proto\n</code></pre> <p>This will generate:</p> <ul> <li>bpfman-api/src/bpfman.v1.rs: Generated Rust Protobuf source code.</li> <li>clients/gobpfman/v1/: Directory that contains the generated Go Client code for interacting   with bpfman over RPC from a Go application.</li> </ul> <p>When editing  proto/bpfman.proto, follow best practices describe in Proto Best Practices.</p> <p>Note</p> <p><code>cargo xtask build-proto</code> also pulls in  proto/csi.proto (which is in the same directory as proto/bpfman.proto). proto/csi.proto is taken from container-storage-interface/spec/csi.proto. See container-storage-interface/spec/spec.md for more details.</p>"},{"location":"developer-guide/develop-operator/#generated-files-and-adding-new-program-type","title":"Generated Files and Adding New Program Type","text":"<p>The operator-sdk framework will generate multiple categories of files (Custom Resource Definitions (CRD), RBAC Role and ClusterRole, Webhook Configuration, typed client, listeners and informers code, etc). When adding a new Program Type or if any of these files are modified, then the auto-generated files must be regenerated:</p> <ul> <li>bpfman-operator/apis/v1alpha1/*_types.go:   Contains the K8s CRD api definitions (<code>*_types.go</code>) for each program type.   When adding a new Program Type, add a file here for the new type.</li> <li>bpfman-operator/config/crd/kustomization.yaml:   This file specifies the output location for the generated yaml files that define the Custom Resource   Definitions (CRDs).   This file must be updated when a new CRD needs to be generated.</li> <li>bpfman-operator/config/crd/patches/:   There is a <code>cainjection_in_*programs.yaml</code> and <code>webhook_in_*programs.yaml</code> file for each Program Type   in this directory.   When adding a new Program Type, add files here for the new type.</li> <li>bpfman-operator/config/manifests/bases/bpfman-operator.clusterserviceversion.yaml:   This file has a list of bpfman Custom Resource Definitions.   When adding a new Program Type, an entry for the new type must be added to this file.</li> <li>bpfman-operator/config/samples/bpfman.io_v1alpha1_*_*program.yaml:   Contains a sample of how to deploy each Program Type.   When adding a new Program Type, add a file here for the new type.</li> <li>bpfman-operator/controllers/bpfman-agent/*_program.go:   Contains the Program Type specific reconciler for the bpfman-agent.   If the <code>//+kubebuilder:rbac</code> directives are added or changed, the associated <code>role.yaml</code> must be regenerated.   When adding a new Program Type, add a file here for the new type.</li> <li>bpfman-operator/controllers/bpfman-agent/common.go:   Contains the common reconciler code for the bpfman-agent.   If the <code>//+kubebuilder:rbac</code> directives are added or changed, the associated <code>role.yaml</code> must be regenerated.   When adding a new Program Type, <code>//+kubebuilder:rbac</code> directives need to be added for the new type.</li> <li>bpfman-operator/controllers/bpfman-operator/*_program.go:   Contains the Program Type specific reconciler for the bpfman-operator.   If the <code>//+kubebuilder:rbac</code> directives are added or changed, the associated <code>role.yaml</code> must be regenerated.   When adding a new Program Type, add a file here for the new type.</li> <li>bpfman-operator/controllers/bpfman-operator/common.go:   Contains the common reconciler code for the bpfman-operator.   If the <code>//+kubebuilder:rbac</code> directives are added or changed, the associated <code>role.yaml</code> must be regenerated.   When adding a new Program Type, <code>//+kubebuilder:rbac</code> directives need to be added for the new type.</li> </ul> <p>Then regenerate the generated files using:</p> <pre><code>cd bpfman-operator/\nmake generate\n</code></pre> <p>There are commands to generate each sub-category if needed. See <code>make help</code> to list all the generate commands.</p> <p>This command will generate the following files:</p> <ul> <li>bpfman-operator/apis/v1alpha1/zz_generate.register.go:   Contains the auto-generated register methods for all the Program Types.</li> <li>bpfman-operator/apis/v1alpha1/zz_generated.deepcopy.go:   Contains the deep copy methods for all the Program Types.</li> <li>bpfman-operator/config/crd/bases/bpfman.io_*programs.yaml:   Contains the yaml files that the define the Custom Resource Definitions (CRDs).</li> <li>bpfman-operator/config/rbac/bpfman-agent/role.yaml:   Contains the <code>Role</code> and <code>ClusterRole</code> definitions for bpfman-agent.   Controls the bpfman-agent access rights to each of the Program Type CRDs.   Generated from the <code>//+kubebuilder:rbac</code> directives in source code.</li> <li>bpfman-operator/config/rbac/bpfman-operator/role.yaml:   Contains the <code>Role</code> and <code>ClusterRole</code> definitions for bpfman-operator.   Controls the bpfman-operator access rights to each of the Program Type CRDs.   Generated from the <code>//+kubebuilder:rbac</code> directives in source code.</li> <li>bpfman-operator/pkg/client/*:   Everything under this directory is generated.   Contains client Golang code to enable applications to easily integrate with bpfman.</li> </ul> <p>Then regenerate the generated bundle files using (Note: <code>make bundle</code> calls <code>make generate</code>):</p> <pre><code>cd bpfman-operator/\nmake bundle\n</code></pre> <p>This command will generate the following files:</p> <ul> <li>bpfman-operator/bundle/*:   Contains the bundle manifests and metadata for the operator.   This bundle is used to deploy the CRDs in a cluster.   More details can be found in the operator-sdk documentation. </li> </ul>"},{"location":"developer-guide/develop-operator/#building","title":"Building","text":"<p>To run in Kubernetes, bpfman components need to be containerized. However, building container images can take longer than just building the code. During development, it may be quicker to find and fix build errors by just building the code. To build the code:</p> <pre><code>cd bpfman-operator/\nmake build\n</code></pre> <p>To build the container images, run the following command:</p> <pre><code>cd bpfman-operator/\nmake build-images\n</code></pre> <p>If the <code>make build</code> command is skipped above, the code will be built in the build-images command. If the <code>make build</code> command is run, the built code will be leveraged in this step. This command generates the following local images:</p> <pre><code>docker images\nREPOSITORY                       TAG      IMAGE ID       CREATED          SIZE\nquay.io/bpfman/bpfman            latest   69df038ccea3   43 seconds ago   515MB\nquay.io/bpfman/bpfman-agent      latest   f6af33c5925b   2 minutes ago    464MB\nquay.io/bpfman/bpfman-operator   latest   4fe444b7abf1   2 minutes ago    141MB\n:\n</code></pre> <p>When running in KIND (see below), the local images will be loaded into the KIND environment. There may be times when the image need to be built and pushed to a remote repository like quay.io so they can be shared or loaded in a remote cluster. The <code>Makefile</code> uses the following variables to manage the location of the built images:</p> <ul> <li>BPFMAN_IMG: The bpfman image is not built from the bpfman operator repository, but the   bpfman operator yaml files control which image is loaded in the cluster.   Use this variable to manage the bpfman image loaded by the bpfman-operator.   If not specified, defaults to <code>quay.io/bpfman/bpfman:latest</code>.</li> <li>BPFMAN_AGENT_IMG: The bpfman agent image.   If not specified, defaults to <code>quay.io/bpfman/bpfman-agent:latest</code>.</li> <li>BPFMAN_OPERATOR_IMG: The bpfman operator image.   If not specified, defaults to <code>quay.io/bpfman/bpfman-operatorman:latest</code>.</li> </ul> <p>To build the bpfman operator images with custom image locations, use something similar to:</p> <pre><code>cd bpfman-operator/\nBPFMAN_AGENT_IMG=quay.io/$QUAY_USER/bpfman:test \\\nBPFMAN_AGENT_IMG=quay.io/$QUAY_USER/bpfman-agent:test \\\nBPFMAN_OPERATOR_IMG=quay.io/$QUAY_USER/bpfman-operator:test \\\nmake build-images\n</code></pre>"},{"location":"developer-guide/develop-operator/#running-locally-in-kind","title":"Running Locally in KIND","text":"<p>Deploying the bpfman-operator goes into more detail on ways to launch bpfman in a Kubernetes cluster. To run locally in a Kind cluster with an up to date build simply run:</p> <pre><code>cd bpfman-operator/\nmake run-on-kind\n</code></pre> <p>NOTE: By default, bpfman-operator deploys bpfman with CSI enabled. CSI requires Kubernetes v1.26 due to a PR (kubernetes/kubernetes#112597) that addresses a gRPC Protocol Error that was seen in the CSI client code and it doesn't appear to have been backported. It is recommended to install kind v0.20.0 or later.</p> <p>The <code>make run-on-kind</code> will run the <code>make build-images</code> if the images do not exist or need updating.</p> <p>Then rebuild and load a fresh build run:</p> <pre><code>cd bpfman-operator/\nmake build-images\nmake kind-reload-images\n</code></pre> <p>Which will rebuild the bpfman-operator and bpfman-agent images, and load them into the kind cluster.</p> <p>By default, the <code>make run-on-kind</code> uses the local images described above. The container images used for <code>bpfman</code>, <code>bpfman-agent</code>, and <code>bpfman-operator</code> can also be manually configured:</p> <pre><code>BPFMAN_IMG=&lt;your/image/url&gt; BPFMAN_AGENT_IMG=&lt;your/image/url&gt; BPFMAN_OPERATOR_IMG=&lt;your/image/url&gt; make run-on-kind\n</code></pre>"},{"location":"developer-guide/develop-operator/#testing-locally","title":"Testing Locally","text":"<p>See Kubernetes Operator Tests. </p>"},{"location":"developer-guide/develop-operator/#deploy-to-existing-cluster","title":"Deploy To Existing Cluster","text":"<p>There are several ways to deploy bpfman to an existing Kubernetes cluster. The cluster needs to be up and running and specified in ~/.kube/config file.</p> <ul> <li> <p>OperatorHub: bpfman can be installed in a cluster from either the community OperatorHub   (OperatorHub.io) or to an OpenShift Cluster via the OpenShift   Console and the builtin Console OperatorHub.   This is the recommended method for installing the latest release of bpfman/bpfman-operator.</p> </li> <li> <p>Custom OpenShift Console OperatorHub Bundle: Custom bpfman/bpfman-operator image can be   installed in via OpenShift Console OperatorHub.   This is the recommended method when developing in bpfman/bpfman-operator, building custom images,   and needing to test from OpenShift Console OperatorHub.</p> </li> <li> <p>Manually with Kustomize: bpfman can be manually installed to an OpenShift cluster with   Kustomize and raw manifests.   This is the recommended method when developing in bpfman/bpfman-operator, building custom images,   and wanting to test in an OpenShift cluster.</p> </li> <li> <p>Manually with OLM Bundle: The other option for installing the bpfman-operator is to install   it using OLM bundle.</p> </li> </ul>"},{"location":"developer-guide/develop-operator/#operatorhub","title":"OperatorHub","text":"<p>When installing the latest release of bpfman/bpfman-operator, bpfman can be installed in a cluster from either the community OperatorHub (OperatorHub.io) or to an OpenShift Cluster via the OpenShift Console and the builtin Console OperatorHub.</p>"},{"location":"developer-guide/develop-operator/#operatorhubio","title":"OperatorHub.io","text":"<p>To install from the community OperatorHub, go to (OperatorHub.io) and search for bpfman:</p> <p></p> <p>Click on the bpfman Operator, which will take you to the installation screen:</p> <p></p> <p>Click on the <code>Install</code> button, which will take you to the installation instructions, which are a set of commands to run to install the bpfman Operator:</p> <p></p>"},{"location":"developer-guide/develop-operator/#operatorhub-via-openshift-console","title":"OperatorHub via OpenShift Console","text":"<p>To install from the OpenShift Console, from within the OpenShift Console, find <code>OperatorHub</code>, which is under <code>Operators</code> on the left hand side of the page. Then search for bpfman:</p> <p></p> <p>There should be two options, <code>Community</code> and <code>Red Hat</code>. The <code>Community</code> based Operator tracks the releases from this repository. The <code>Red Hat</code> based Operator is the downstream version from this repository and releases with each OpenShift release. Click on the operator to be installed:</p> <p></p> <p>This provides the details on the operator. Select the desired Version and click the <code>Install</code> button.</p> <p></p> <p>This provides similar details on the operator in a popup window. Select the desired Version and click the <code>Install</code> button. This will install the bpfman Operator on the cluster.</p>"},{"location":"developer-guide/develop-operator/#custom-openshift-console-operatorhub-bundle","title":"Custom OpenShift Console OperatorHub Bundle","text":"<p>If developing in bpfman/bpfman-operator and a custom image needs to be loaded from OpenShift Console OperatorHub, then make the changes to bpfman/bpfman-operator. Once the changes compile and are ready to be tested, build and push the container images:</p> <pre><code>cd bpfman-operator/\n\n# Optionally include BPFMAN_IMG if trying to load private bpfman image\nBPFMAN_IMG=quay.io/$QUAY_USER/bpfman:test \\\nBPFMAN_AGENT_IMG=quay.io/$QUAY_USER/bpfman-agent:test \\\nBPFMAN_OPERATOR_IMG=quay.io/$QUAY_USER/bpfman-operator:test \\\nmake build-images\n\nBPFMAN_AGENT_IMG=quay.io/$QUAY_USER/bpfman-agent:test \\\nBPFMAN_OPERATOR_IMG=quay.io/$QUAY_USER/bpfman-operator:test \\\nmake push-images\n</code></pre> <p>Next, a bundle and catalog needs to be built and pushed:</p> <pre><code>BPFMAN_IMG=quay.io/$QUAY_USER/bpfman:test \\\nBPFMAN_AGENT_IMG=quay.io/$QUAY_USER/bpfman-agent:test \\\nBPFMAN_OPERATOR_IMG=quay.io/$QUAY_USER/bpfman-operator:test \\\nBUNDLE_IMG=quay.io/$QUAY_USER/bpfman-operator-bundle:development \\\nmake bundle bundle-build bundle-push\n\nCATALOG_IMG=quay.io/$QUAY_USER/bpfman-operator-catalog:development \\\nmake catalog-build catalog-push\n</code></pre> <p>Once the bundle and catalog are built, make sure the cluster is up and  running and specified in ~/.kube/config file. Then deploy the catalog:</p> <pre><code>CATALOG_IMG=quay.io/$QUAY_USER/bpfman-operator-catalog:development \\\nmake catalog-deploy\n</code></pre> <p>Now the new catalog should show up in the OperatorHub (may have to refresh or restart the search if OperatorHub was already up). An additional option should be presented, <code>Bpfman Operator development</code>. This can be now be installed as described above.</p> <p></p> <p>To clean up at a later time, execute:</p> <pre><code>make catalog-undeploy\n</code></pre>"},{"location":"developer-guide/develop-operator/#manually-with-kustomize","title":"Manually with Kustomize","text":"<p>To manually install with Kustomize and raw manifests, execute the following commands. The Openshift cluster needs to be up and running and specified in ~/.kube/config file.</p> <pre><code>cd bpfman-operator/\nmake deploy-openshift\n</code></pre> <p>To clean up at a later time, run:</p> <pre><code>make undeploy-openshift\n</code></pre>"},{"location":"developer-guide/develop-operator/#manually-with-olm-bundle","title":"Manually with OLM Bundle","text":"<p>The other option for installing the bpfman-operator is to install it using OLM bundle.</p> <p>First setup the namespace and certificates for the operator with:</p> <pre><code>cd bpfman-operator\nkubectl apply -f ./hack/ocp-scc-hacks.yaml\n</code></pre> <p>Then use <code>operator-sdk</code> to install the bundle like so:</p> <pre><code>./bin/operator-sdk run bundle quay.io/bpfman/bpfman-operator-bundle:latest --namespace openshift-bpfman\n</code></pre> <p>To clean up at a later time, run:</p> <pre><code>./bin/operator-sdk cleanup bpfman-operator\nkubectl delete -f ./hack/ocp-scc-hacks.yaml\n</code></pre>"},{"location":"developer-guide/develop-operator/#verify-the-installation","title":"Verify the Installation","text":"<p>Regardless of the deployment method, if the <code>bpfman-operator</code> was deployed successfully, you will see the <code>bpfman-daemon</code> and <code>bpfman-operator</code> pods running without errors:</p> <pre><code>kubectl get pods -n bpfman\nNAME                             READY   STATUS    RESTARTS   AGE\nbpfman-daemon-w24pr                3/3     Running   0          130m\nbpfman-operator-78cf9c44c6-rv7f2   2/2     Running   0          132m\n</code></pre> <p>For further verification, load a sample eBPF Program onto the cluster using Deploy an eBPF Program to the cluster.</p>"},{"location":"developer-guide/develop-operator/#bpfman-agent-profiling","title":"bpfman-agent Profiling","text":"<p>bpfman-agent process use port <code>6060</code> for Golang profiling to be able to get the different profiles.</p> <ol> <li> <p>Set port-forward rule in a different terminal:</p> <pre><code>kubectl get pods -n bpfman\nNAME                               READY   STATUS    RESTARTS   AGE\nbpfman-daemon-76v57                3/3     Running   0          14m\nbpfman-operator-7f67bc7c57-ww52z   2/2     Running   0          14m\n\nkubectl -n bpfman port-forward bpfman-daemon-76v57 6060\n</code></pre> </li> <li> <p>Download the required profiles:</p> <p><code>curl -o &lt;profile&gt; http://localhost:6060/debug/pprof/&lt;profile&gt;</code></p> <p>Where  can be: profile description allocs A sampling of all memory allocations block Stack traces that led to blocking on synchronization primitives cmdline The command line invocation of the current program goroutine Stack traces of all current goroutines heap A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. mutex Stack traces of holders of contended mutexes profile CPU profile. You can specify the duration in the seconds GET parameter. threadcreate Stack traces that led to the creation of new OS threads trace A trace of execution of the current program. You can specify the duration in the seconds GET parameter. <p>Example:</p> <pre><code>curl \"http://localhost:6060/debug/pprof/trace?seconds=20\" -o trace\ncurl \"http://localhost:6060/debug/pprof/profile?duration=20\" -o cpu\ncurl \"http://localhost:6060/debug/pprof/heap?gc\" -o heap\ncurl \"http://localhost:6060/debug/pprof/allocs\" -o allocs\ncurl \"http://localhost:6060/debug/pprof/goroutine\" -o goroutine\n</code></pre> <li> <p>Use go tool pprof to dig into the profiles (go tool trace    for the trace profile) or use  web interface.    For example:</p> <pre><code>go tool pprof -http=:8080 cpu\n</code></pre> </li>"},{"location":"developer-guide/develop-operator/#troubleshooting","title":"Troubleshooting","text":""},{"location":"developer-guide/develop-operator/#metricshealth-port-issues","title":"Metrics/Health port issues","text":"<p>In some scenarios, the health and metric ports may are already in use by other services on the system. When this happens the bpfman-agent container fails to deploy. The ports currently default to 8175 and 8174.</p> <p>The ports are passed in through the daemonset.yaml for the <code>bpfman-daemon</code> and deployment.yaml and manager_auth_proxy_patch.yaml for the <code>bpfman-operator</code>. The easiest way to change which ports are used is to update these yaml files and rebuild the container images. The container images need to be rebuilt because the <code>bpfman-daemon</code> is deployed from the <code>bpfman-operator</code> and the associated yaml files are copied into the <code>bpfman-operator</code> image.</p> <p>If rebuild the container images is not desirable, then the ports can be changed on the fly. For the <code>bpfman-operator</code>, the ports can be updated by editing the <code>bpfman-operator</code> Deployment.</p> <pre><code>kubectl edit deployment -n bpfman bpfman-operator\n\napiVersion: apps/v1\nkind: Deployment\n:\nspec:\n  template:\n  :\n  spec:\n    containers:\n    -args:\n      - --secure-listen-address=0.0.0.0:8443\n      - --upstream=http://127.0.0.1:8174/        &lt;-- UPDATE\n      - --logtostderr=true\n      - --v=0\n      name: kube-rbac-proxy\n      :\n    - args:\n      - --health-probe-bind-address=:8175        &lt;-- UPDATE\n      - --metrics-bind-address=127.0.0.1:8174    &lt;-- UPDATE\n      - --leader-elect\n      :\n      livenessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /healthz\n            port: 8175                           &lt;-- UPDATE\n            scheme: HTTP\n            :\n      name: bpfman-operator\n      readinessProbe:\n          failureThreshold: 3\n          httpGet:\n            path: /readyz\n            port: 8175                           &lt;-- UPDATE\n            scheme: HTTP\n      :\n</code></pre> <p>For the <code>bpfman-daemon</code>, the ports could be updated by editing the <code>bpfman-daemon</code> DaemonSet. However, if <code>bpfman-daemon</code> is restarted for any reason by the <code>bpfman-operator</code>, the changes will be lost. So it is recommended to update the ports for the <code>bpfman-daemon</code> via the bpfman <code>bpfman-config</code> ConfigMap.</p> <pre><code>kubectl edit configmap -n bpfman bpfman-config\n\napiVersion: v1\ndata:\n  bpfman.agent.healthprobe.addr: :8175                    &lt;-- UPDATE\n  bpfman.agent.image: quay.io/bpfman/bpfman-agent:latest\n  bpfman.agent.log.level: info\n  bpfman.agent.metric.addr: 127.0.0.1:8174                &lt;-- UPDATE\n  bpfman.image: quay.io/bpfman/bpfman:latest\n  bpfman.log.level: debug\nkind: ConfigMap\n:\n</code></pre>"},{"location":"developer-guide/documentation/","title":"Documentation","text":"<p>This section describes how to modify the related documentation around bpfman. All bpfman's documentation is written in Markdown, and leverages mkdocs to generate a static site, which is hosted on netlify.</p> <p>If this is the first time building using <code>mkdocs</code>, jump to the Development Environment Setup section for help installing the tooling.</p>"},{"location":"developer-guide/documentation/#documentation-notes","title":"Documentation Notes","text":"<p>This section describes some notes on the dos and don'ts when writing documentation.</p>"},{"location":"developer-guide/documentation/#website-management","title":"Website Management","text":"<p>The headings and layout of the website, as well as other configuration settings, are managed from the mkdocs.yml file in the project root directory.</p>"},{"location":"developer-guide/documentation/#markdown-style","title":"Markdown Style","text":"<p>When writing documentation via a Markdown file, the following format has been followed:</p> <ul> <li>Text on a given line should not exceed 100 characters, unless it's example syntax or a link   that should be broken up.</li> <li>Each new sentence should start on a new line.   That way, if text needs to be inserted, whole paragraphs don't need to be adjusted.</li> <li>Links to other markdown files are relative to the file the link is placed in.</li> </ul>"},{"location":"developer-guide/documentation/#governance-files","title":"Governance Files","text":"<p>There are a set of well known governance files that are typically placed in the root directory of most projects, like README.md, MAINTAINERS.md, CONTRIBUTING.md, etc. <code>mkdocs</code> expects all files used in the static website to be located under a common directory, <code>docs/</code> for bpfman. To reference the governance files from the static website, a directory (<code>docs/governance/</code>) was created with a file for each governance file, the only contains <code>--8&lt;--</code> and the file name. This indicates to <code>mkdocs</code> to pull the additional file from the project root directory.</p> <p>For example: docs/governance/MEETINGS.md</p> <p>Note</p> <p>This works for the website generation, but if a Markdown file is viewed through Github (not the website), the link is broken. So these files should only be linked from <code>docs/index.md</code> and <code>mkdocs.yml</code>.</p>"},{"location":"developer-guide/documentation/#docsdeveloper-guideapi-specmd","title":"docs/developer-guide/api-spec.md","text":"<p>The file docs/developer-guide/api-spec.md documents the CRDs used in a Kubernetes deployment. The contents are auto-generated when PRs are pushed to Github.</p> <p>The contents can be generated locally by running the command <code>./scripts/api-docs/generate.sh apidocs.html</code> from the root bpfman directory.</p>"},{"location":"developer-guide/documentation/#generate-documentation","title":"Generate Documentation","text":"<p>If you would like to test locally, build and preview the generated documentation, from the bpfman root directory, use <code>mkdocs</code> to build:</p> <pre><code>cd bpfman/\nuv run mkdocs build\n</code></pre> <p>Note</p> <p>If <code>mkdocs build</code> gives you an error, make sure you have the mkdocs packages listed below installed.</p> <p>To preview from a build on a local machine, start the mkdocs dev-server with the command below, then open up <code>http://127.0.0.1:8000/</code> in your browser, and you'll see the default home page being displayed:</p> <pre><code>uv run mkdocs serve\n</code></pre> <p>To preview from a build on a remote machine, start the mkdocs dev-server with the command below, then open up <code>http://&lt;ServerIP&gt;:8000/</code> in your browser, and you'll see the default home page being displayed:</p> <pre><code>uv run mkdocs serve -a 0.0.0.0:8000\n</code></pre>"},{"location":"developer-guide/documentation/#development-environment-setup","title":"Development Environment Setup","text":"<p>The documentation generation uses <code>uv</code>. To install <code>uv</code>:</p> <pre><code>pip install uv\n</code></pre> <p>The recommended installation method for <code>mkdocs</code> is using <code>uv</code>.</p> <pre><code>uv sync\n</code></pre> <p>Once installed, ensure the <code>mkdocs</code> is in your PATH:</p> <pre><code>uv run mkdocs -V\nmkdocs, version 1.5.3 from /home/$USER/&lt;bpfman project location&gt;/.venv/lib/python3.13/site-packages/mkdocs (Python 3.13)\n</code></pre> <p>Note</p> <p>If you have an older version of mkdocs installed, you may need to use the <code>--upgrade</code> option (e.g., <code>uv add --upgrade mkdocs</code>) to get it to work.</p>"},{"location":"developer-guide/documentation/#document-images","title":"Document Images","text":"<p>Source of images used in the example documentation can be found in bpfman Upstream Images. Request access if required.</p>"},{"location":"developer-guide/image-build/","title":"bpfman Container Images","text":"<p>Container images for <code>bpfman</code> are automatically built and pushed to <code>quay.io/</code> under the <code>:latest</code> tag whenever code is merged into the <code>main</code> branch of the bpfman and bpfman-operator repositories.</p> <ul> <li>quay.io/bpfman:  This repository contains images needed   to run bpfman.   It contains the <code>xdp-dispatcher</code> and <code>tc-dispatcher</code> eBPF container images, which are used by   bpfman to allow multiple XDP or TC programs to be loaded on a given interface.   It also includes the container images which are used to deploy bpfman in a Kubernetes deployment:<ul> <li>bpfman: Packages all the bpfman binaries, including <code>bpfman</code> CLI, <code>bpfman-ns</code> and <code>bpfman-rpc</code>.</li> <li>bpfman-agent: Agent that listens to KubeAPI Server and makes calls to bpfman to load or unload   eBPF programs based on user intent.</li> <li>bpfman-operator: Operator for deploying bpfman.</li> <li>tc-dispatcher: eBPF container image containing the TC Dispatcher, which is used by bpfman   to manage and allow multiple TC based programs to be loaded on a given TC hook point.</li> <li>xdp-dispatcher: eBPF container image containing the XDP Dispatcher, which is used by bpfman   to manage and allow multiple TC based programs to be loaded on a given XDP hook point.</li> <li>csi-node-driver-registrar: CSI Driver used by bpfman.</li> <li>bpfman-operator-bundle: Image containing all the CRDs (Custom-Resource-Definitions) used   by bpfman-agent to define Kubernetes objects used to manage eBPF programs.</li> </ul> </li> <li>quay.io/bpfman-bytecode: This repository contains   eBPF container images for all of the generated bytecode from   examples/ and   integration-test/.</li> <li>quay.io/bpfman-userspace:  This repository contains   userspace container images for all of the example programs in   examples/.</li> </ul>"},{"location":"developer-guide/image-build/#multiple-architecture-support","title":"Multiple Architecture Support","text":"<p>All <code>bpfman</code> related container images that are automatically built and pushed to <code>quay.io/</code> contain a manifest file and images built for the following architectures:</p> <ul> <li>x86_64</li> <li>arm64</li> <li>ppc64le</li> <li>s390x</li> </ul>"},{"location":"developer-guide/image-build/#locally-build-bpfman-operator-and-bpfman-agent-container-images","title":"Locally Build bpfman-operator and bpfman-agent Container Images","text":"<p>When testing or developing in bpfman-operator, it may be necessary to run with updated changes to the bpfman-operator or bpfman-agent container images. The local Makefile will build and load both images based on the current changes:</p> <pre><code>cd bpfman-operator/\n\nmake build-images\nmake run-on-kind\n</code></pre>"},{"location":"developer-guide/image-build/#locally-build-bpfman-container-image","title":"Locally Build bpfman Container Image","text":"<p>When testing or developing in bpfman-operator, it may be necessary to run with updated changes to bpfman. By default, bpfman-agent uses <code>quay.io/bpfman/bpfman:latest</code>. To build the bpfman binaries in a container image, run:</p> <pre><code>cd bpfman/\n\ndocker build -f ./Containerfile.bpfman.local . -t quay.io/$QUAY_USER/bpfman:test\n</code></pre> <p>Use any registry, image name and tag, above is just an example. Next, build and deploy the bpfman-operator and bpfman-agent with the locally built bpfman container image.</p> <pre><code>cd bpfman-operator/\n\nBPFMAN_IMG=quay.io/$QUAY_USER/bpfman:test make build-images\nBPFMAN_IMG=quay.io/$QUAY_USER/bpfman:test make run-on-kind\n</code></pre> <p>To use, the Kind cluster must have access to the image. So either the image needs to be pushed to a registry and made public (make public via the repo GUI after the push) before executing the <code>make run-on-kind</code> command shown above:</p> <pre><code>docker push quay.io/$QUAY_USER/bpfman:test\n</code></pre> <p>OR it can be loaded into the kind cluster after the cluster is running:</p> <pre><code>kind load docker-image quay.io/$QUAY_USER/bpfman:test --name bpfman-deployment\n</code></pre> <p>Now the image should be running in the Kind cluster:</p> <pre><code>kubectl get pods -A\n NAMESPACE   NAME                               READY   STATUS    RESTARTS   AGE\n bpfman      bpfman-daemon-87fqg                3/3     Running   0          16m\n bpfman      bpfman-operator-7f67bc7c57-bc6lk   2/2     Running   0          16m\n :\n\nkubectl describe pod -n bpfman bpfman-daemon-87fqg\n Name:             bpfman-daemon-87fqg\n Namespace:        bpfman\n :\n Containers:\n  bpfman:\n    Container ID:  containerd://1777d1810f3648f43df775e9d9af79406eaffc5694aa712da04c3f4e578093b3\n    Image:         quay.io/$QUAY_USER/bpfman:test\n    Image ID:      quay.io/$QUAY_USER/bpfman@sha256:f2c94b7acff6b463fc55232a1896816283521dd1ba5560b0d0779af99f811cd0\n:\n</code></pre>"},{"location":"developer-guide/image-build/#locally-build-tc-or-xdp-dispatcher-container-image","title":"Locally Build TC or XDP Dispatcher Container Image","text":"<p>The TC and XDP Dispatcher images are automatically built and pushed to <code>quay.io/</code> under the <code>:latest</code> tag whenever code is merged into the <code>main</code> branch of the <code>github.com/bpfman/bpfman</code>. If a dispatcher container image needs to be built locally, use the following steps.</p> <p>Build the object files:</p> <pre><code>cargo xtask build-ebpf --libbpf-dir ~/src/libbpf/\n\n$ ls .output/tc_dispatcher.bpf/\nbpf_arm64_bpfel.o  bpf_powerpc_bpfel.o  bpf_s390_bpfeb.o  bpf_x86_bpfel.o\n\n$ ls .output/xdp_dispatcher_v2.bpf/\nbpf_arm64_bpfel.o  bpf_powerpc_bpfel.o  bpf_s390_bpfeb.o  bpf_x86_bpfel.o\n</code></pre> <p>Then build the bytecode image files:</p> <pre><code>bpfman image build -f Containerfile.bytecode -t quay.io/$QUAY_USER/tc-dispatcher:test -b .output/tc_dispatcher.bpf/bpf_x86_bpfel.o\nbpfman image build -f Containerfile.bytecode -t quay.io/$QUAY_USER/xdp-dispatcher:test -b .output/xdp_dispatcher_v2.bpf/bpf_x86_bpfel.o\n</code></pre> <p>If a multi-arch image is needed, use:</p> <pre><code>bpfman image build -f Containerfile.bytecode.multi.arch -t quay.io/$QUAY_USER/tc-dispatcher:test -c .output/tc_dispatcher.bpf/\nbpfman image build -f Containerfile.bytecode.multi.arch -t quay.io/$QUAY_USER/xdp-dispatcher:test -c .output/xdp_dispatcher_v2.bpf/\n</code></pre> <p>Note</p> <p>To build images for multiple architectures on a local system, docker (or podman) may need additional configuration settings to allow for caching of non-native images. See https://docs.docker.com/build/building/multi-platform/ for more details.</p>"},{"location":"developer-guide/image-build/#csi-node-driver-registrar-container-image","title":"CSI Node Driver Registrar Container Image","text":"<p>The <code>csi-node-driver-registrar</code> is a community image. It is built from https://github.com/kubernetes-csi/node-driver-registrar. Images are pushed to <code>registry.k8s.io/sig-storage/csi-node-driver-registrar</code>.</p> <p><code>registry.k8s.io</code> is GA and is the replacement for <code>k8s.gcr.io</code>. <code>registry.k8s.io</code> recommends not pulling from it in production (from https://github.com/kubernetes/registry.k8s.io?tab=readme-ov-file#stability):</p> <pre><code>However, unequivocally: DO NOT depend on the implementation details of this\nregistry.\n\nPlease note that there is NO uptime SLA as this is a free, volunteer managed\nservice. We will however do our best to respond to issues and the system is\ndesigned to be reliable and low-maintenance. If you need higher uptime\nguarantees please consider mirroring images to a location you control.\n</code></pre> <p>Following the mirroring link, the following command is an example of how to copy the <code>registry.k8s.io/sig-storage</code> image to <code>quay.io/bpfman</code>:</p> <pre><code>crane copy registry.k8s.io/sig-storage/csi-node-driver-registrar:v2.13.0 quay.io/bpfman/csi-node-driver-registrar:v2.13.0\n</code></pre>"},{"location":"developer-guide/image-build/#locally-build-example-container-images","title":"Locally Build Example Container Images","text":"<p>The example images are automatically built and pushed to <code>quay.io/</code> under the <code>:latest</code> tag whenever code is merged into the <code>main</code> branch of the <code>github.com/bpfman/bpfman</code>. For each example, there is a bytecode and a userspace image. For official bpfman images, bytecode images are pushed to quay.io/bpfman-bytecode and userspace images are pushed to quay.io/bpfman-userspace. For example:</p> <ul> <li>quay.io/bpfman-bytecode/go-kprobe-counter</li> <li>quay.io/bpfman-bytecode/go-tc-counter</li> <li>quay.io/bpfman-bytecode/go-tracepoint-counter</li> <li> <p>...</p> </li> <li> <p>quay.io/bpfman-userspace/go-kprobe-counter</p> </li> <li>quay.io/bpfman-userspace/go-tc-counter</li> <li>quay.io/bpfman-userspace/go-tracepoint-counter</li> <li>...</li> </ul> <p>The Makefile in the examples directory has commands to build both sets of images. Image names and tags can be controlled using environment variables. If private images are being generated, both bytecode and userspace images will probably be pushed to the same account, so bytecode and userspace images will need to be distinguished by either fully qualified image names (using IMAGE_TC_BC, IMAGE_TC_US, IMAGE_XDP_BC, IMAGE_XDP_US, etc) or unique tags for each (TAG_BC, TAG_US). See <code>make help</code> in the examples directory and the samples below.</p>"},{"location":"developer-guide/image-build/#example-bytecode-container-images","title":"Example Bytecode Container Images","text":"<p>If an example bytecode container image needs to be built locally, use the following to build the bytecode container image, (optionally passing the <code>USER_BC</code> and <code>TAG_BC</code> for the image):</p> <pre><code># Build images for all eBPF program types\n$ make build-bc-images USER_BC=$QUAY_USER TAG_BC=test-bc\n:\n =&gt; pushing quay.io/$QUAY_USER/go-kprobe-counter:test-bc with docker\n:\n =&gt; pushing quay.io/$QUAY_USER/go-tc-counter:test-bc with docker\n:\n =&gt; pushing quay.io/$QUAY_USER/go-tracepoint-counter:test-bc with docker\n:\n\n-- OR --\n\n# Build image for a single eBPF program type, XDP in this example\n$ make build-bc-xdp USER_BC=$QUAY_USER TAG_BC=test-bc\n:\n =&gt; pushing quay.io/$QUAY_USER/go-xdp-counter:test-bc with docker\n</code></pre> <p>If a multi-arch image is needed, use (appending <code>PLATFORM</code>):</p> <pre><code>$ make build-bc-xdp USER_BC=$QUAY_USER TAG_BC=test-bc PLATFORM=linux/amd64,linux/arm64,linux/ppc64le,linux/s390x\n:\n =&gt; pushing quay.io/$QUAY_USER/go-xdp-counter:test-bc with docker\n</code></pre> <p>Note</p> <p>To build images for multiple architectures on a local system, docker (or podman) may need additional configuration settings to allow for caching of non-native images. See https://docs.docker.com/build/building/multi-platform/ for more details.</p>"},{"location":"developer-guide/image-build/#example-userspace-container-images","title":"Example Userspace Container Images","text":"<p>If an example userspace container image needs to be built locally, use the following to build the userspace container images, (optionally passing the <code>USER_US</code> and <code>TAG_US</code> for the image):</p> <pre><code>cd bpfman/examples/\n\n# Build all images\n$ make build-us-images USER_US=$QUAY_USER TAG_US=test-us\n:\n =&gt; pushing quay.io/$QUAY_USER/go-kprobe-counter:test-us with docker\n:\n =&gt; pushing quay.io/$QUAY_USER/go-tc-counter:test-us with docker\n:\n =&gt; pushing quay.io/$QUAY_USER/go-tracepoint-counter:test-us with docker\n:\n\n-- OR --\n\n# Build a single image\n$ make build-us-xdp USER_US=$QUAY_USER TAG_US=test-us\n:\n =&gt; pushing quay.io/$QUAY_USER/go-xdp-counter:test-us with docker\n</code></pre> <p>If a multi-arch image is needed, use (appending <code>PLATFORM</code>):</p> <pre><code>$ make build-us-xdp USER_US=$QUAY_USER TAG_US=test-us PLATFORM=linux/amd64,linux/arm64,linux/ppc64le,linux/s390x\n:\n =&gt; pushing quay.io/$QUAY_USER/go-xdp-counter:test-us with docker\n</code></pre> <p>Note</p> <p>To build images for multiple architectures on a local system, docker (or podman) may need additional configuration settings to allow for caching of non-native images. See https://docs.docker.com/build/building/multi-platform/ for more details.</p>"},{"location":"developer-guide/image-build/#adding-additional-container-images","title":"Adding Additional Container Images","text":"<p>When adding a new container image to one of the bpfman repositories, whether it be via the examples or integration tests, several steps need to be performed.</p> <ul> <li>One of the maintainers of the bpfman quay.io repositories must:<ul> <li>Add the image to the quay.io repository.</li> <li>Make the new image public.</li> <li>On the image, provide <code>Write</code> access to the <code>bpfman+github_actions</code> robot account.</li> </ul> </li> <li>Add the new image to the   bpfman/.github/workflows/image-build.yml   so the image is built and pushed on each PR merge.</li> <li>For examples, update the <code>examples/Makefile</code> to build the new images.</li> </ul>"},{"location":"developer-guide/image-build/#signing-container-images","title":"Signing Container Images","text":"<p>Signing eBPF container images is encouraged and can be easily done using cosign. Below is a summary of the steps needed to sign an image.</p> <p>First, install <code>cosign</code>:</p> <pre><code>go install github.com/sigstore/cosign/v2/cmd/cosign@latest\n</code></pre> <p>Then sign the image. The <code>cosign</code> command will generate a URL. Follow the <code>sigstore</code> URL and login with either GitHub, Google to Microsoft. That will generate a verification code that will complete the <code>cosign</code> command.</p> <pre><code>cosign sign -y quay.io/$QUAY_USER/test-image@sha256:55fe3cfe46409939876be27f7ed4d2948842918145f6cda167d0c31fdea2046f\nGenerating ephemeral keys...\nRetrieving signed certificate...\n:\nhttps://oauth2.sigstore.dev/auth/auth?access_type=online&amp;client_id=sigstore&amp;code_challenge=EwHYBahRxlbli-oEXxS9DoEzEWcyuS_f1lLBhntCVFI&amp;code_challenge_method=S256&amp;nonce=2kR9mJbP0eUxFBAQI9Nhs6LyS4l&amp;redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&amp;response_type=code&amp;scope=openid+email&amp;state=2kR9mIqOn6IgmAw46BxVrnEEi0M\nEnter verification code: wq3g58qhw6y25wwibcz2kgzfx\n\nSuccessfully verified SCT...\ntlog entry created with index: 120018072\nPushing signature to: quay.io/$QUAY_USER/test-image\n</code></pre>"},{"location":"developer-guide/image-build/#containerfiles","title":"Containerfiles","text":"<p>There are multiple Containerfiles in the bpfman repositories. Below is a summary of the files and their purpose.</p>"},{"location":"developer-guide/image-build/#userspace-containerfiles","title":"Userspace Containerfiles","text":"<ul> <li>bpfman/Containerfile.bpfman.local: This file is used to create a userspace container image   with bpfman binaries (<code>bpfman</code> CLI, <code>bpfman-rpc</code> and <code>bpfman-ns</code>).   It can be used to run local bpfman code in a Kubernetes cluster with the <code>bpfman-operator</code> and <code>bpfman-agent</code>.</li> <li>bpfman/Containerfile.bpfman.multi.arch: This file is used to create a userspace container image   with bpfman binaries (<code>bpfman</code> CLI, <code>bpfman-rpc</code> and <code>bpfman-ns</code>), but for multiple architectures.   It is used by the <code>bpfman/.github/workflows/image-build.yaml</code> file to build bpfman multi-arch images   on every github Pull Request merge.   The resulting images are stored in <code>quay.io</code>.</li> <li>bpfman/Containerfile.bpfman.openshift: This file is used to create a userspace container image   with bpfman binaries (<code>bpfman</code> CLI, <code>bpfman-rpc</code> and <code>bpfman-ns</code>).   It is used by internal OpenShift build processes.</li> <li>bpfman/examples/go-*-counter/container-deployment/Containerfile.go-*-counter: Where '*' is one of the   bpfman supported program types (tc, tcx, tracepoint, etc.).   These files are used to create the userspace container images associated with the examples.</li> <li>bpfman-operator/Containerfile.bpfman-agent: This file is used to create a userspace   container image with bpfman-agent.</li> <li>bpfman-operator/Containerfile.bpfman-agent.openshift: This file is used to create a userspace   container image with bpfman-agent.   It is used by internal OpenShift build processes.</li> <li>bpfman-operator/Containerfile.bpfman-operator: This file is used to create a userspace   container image with bpfman-operator.</li> <li>bpfman-operator/Containerfile.bpfman-operator.openshift: This file is used to create a userspace   container image with bpfman-operator.   It is used by internal OpenShift build processes.</li> <li>bpfman-operator/Containerfile.bundle: This file is used to create a container image with   all the Kubernetes object definitions (ConfigMaps, Custom Resource Definitions (CRDs), Roles,   Role Bindings, Service, Service Accounts, etc) bpfman needs to be deployed in a Kubernetes cluster.</li> </ul>"},{"location":"developer-guide/image-build/#bytecode-containerfiles","title":"Bytecode Containerfiles","text":"<ul> <li>bpfman/Containerfile.bytecode: This file is used to create a container image with eBPF bytecode   packaged inside.   The Containerfile applies labels to the container image describing the bytecode for consumers of the image.   See eBPF Bytecode Image Specifications for more details.</li> <li>bpfman/Containerfile.bytecode.multi.arch: This file is used to create a container image with eBPF bytecode   packaged inside, but packages eBPF bytecode for multiple architectures.   The Containerfile applies labels to the container image describing the bytecode for consumers of the image.   See eBPF Bytecode Image Specifications for more details.</li> </ul>"},{"location":"developer-guide/k8s-selinux-distros/","title":"Running the Examples as Non-Root on SELinux Distributions","text":"<p>Developer instances of Kubernetes such as kind often set SELinux to permissive mode, ensuring the security subsystem does not interfere with the local cluster operations.  However, in production distributions such as Openshift, EKS, GKE and AWS where security is paramount, SELinux and other security subsystems are often enabled by default.  This among other things presents unique challenges when determining how to deploy unprivileged applications with bpfman.</p> <p>In order to deploy the provided examples on SELinux distributions, users must first install the security-profiles-operator. This will allow bpfman to deploy custom SELinux policies which will allow container users access to bpf maps (i.e <code>map_read</code> and <code>map_write</code> actions).</p> <p>It can easily be installed via operatorhub.io from here.</p> <p>Once the security-profiles-operator and bpfman are installed simply deploy desired examples:</p> <pre><code>cd examples/\nmake deploy-tc-selinux\nmake deploy-xdp-selinux\n:\nmake undeploy-tc-selinux\nmake undeploy-xdp-selinux\n</code></pre>"},{"location":"developer-guide/linux-capabilities/","title":"Linux Capabilities","text":"<p>Linux divides the privileges traditionally associated with superuser into distinct units, known as capabilities, which can be independently enabled and disabled. Capabilities are a per-thread attribute. See capabilities man-page.</p> <p>When <code>bpfman</code> is run as a systemd service, the set of linux capabilities are restricted to only the required set of capabilities via the <code>bpfman.service</code> file using the <code>AmbientCapabilities</code> and <code>CapabilityBoundingSet</code> fields (see bpfman.service). All spawned threads are stripped of all capabilities, removing all sudo privileges (see <code>drop_linux_capabilities()</code> usage), leaving only the main thread with only the needed set of capabilities.</p>"},{"location":"developer-guide/linux-capabilities/#current-bpfman-linux-capabilities","title":"Current bpfman Linux Capabilities","text":"<p>Below are the current set of Linux capabilities required by bpfman to operate:</p> <ul> <li>CAP_BPF:<ul> <li>Required to load BPF programs and create BPF maps.</li> </ul> </li> <li>CAP_DAC_READ_SEARCH:<ul> <li>Required by Tracepoint programs, needed by aya to check the tracefs mount point.   For example, trying to read \"/sys/kernel/tracing\" and \"/sys/kernel/debug/tracing\".</li> </ul> </li> <li>CAP_NET_ADMIN:<ul> <li>Required for TC programs to attach/detach to/from a qdisc.</li> </ul> </li> <li>CAP_SETPCAP:<ul> <li>Required to allow bpfman to drop Linux Capabilities on spawned threads.</li> </ul> </li> <li>CAP_SYS_ADMIN: <ul> <li>Kprobe (Kprobe and Uprobe) and Tracepoint programs are considered perfmon programs and require CAP_PERFMON and CAP_SYS_ADMIN to load.</li> <li>TC and XDP programs are considered admin programs and require CAP_NET_ADMIN and CAP_SYS_ADMIN to load.</li> </ul> </li> <li>CAP_SYS_RESOURCE:<ul> <li>Required by bpfman to call <code>setrlimit()</code> on <code>RLIMIT_MEMLOCK</code>.</li> </ul> </li> </ul>"},{"location":"developer-guide/linux-capabilities/#debugging-linux-capabilities","title":"Debugging Linux Capabilities","text":"<p>As new features are added, the set of Linux capabilities required by bpfman may change over time. The following describes the steps to determine the set of capabilities required by bpfman. If there are any <code>Permission denied (os error 13)</code> type errors when starting or running bpfman as a systemd service, adjusting the linux capabilities is a good place to start.</p>"},{"location":"developer-guide/linux-capabilities/#determine-required-capabilities","title":"Determine Required Capabilities","text":"<p>The first step is to turn all capabilities on and see if that fixes the problem. This can be done without recompiling the code by editing <code>bpfman.service</code>. Comment out the finite list of granted capabilities and set to <code>~</code>,  which indicates all capabilities.</p> <pre><code>sudo vi /usr/lib/systemd/system/bpfman.service\n:\n[Service]\n:\nAmbientCapabilities=~\nCapabilityBoundingSet=~\n#AmbientCapabilities=CAP_BPF CAP_DAC_OVERRIDE CAP_DAC_READ_SEARCH CAP_NET_ADMIN CAP_PERFMON CAP_SETPCAP CAP_SYS_ADMIN CAP_SYS_RESOURCE\n#CapabilityBoundingSet=CAP_BPF CAP_DAC_OVERRIDE CAP_DAC_READ_SEARCH CAP_NET_ADMIN CAP_PERFMON CAP_SETPCAP CAP_SYS_ADMIN CAP_SYS_RESOURCE\n</code></pre> <p>Reload the service file and start/restart bpfman and watch the bpfman logs and see if the problem is resolved:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl start bpfman\n</code></pre> <p>If so, then the next step is to watch the set of capabilities being requested by bpfman. Run the bcc <code>capable</code> tool to watch capabilities being requested real-time and restart bpfman:</p> <pre><code>$ sudo /usr/share/bcc/tools/capable\nTIME      UID    PID    COMM             CAP  NAME                 AUDIT\n:\n16:36:00  979    75553  tokio-runtime-w  8    CAP_SETPCAP          1\n16:36:00  979    75553  tokio-runtime-w  8    CAP_SETPCAP          1\n16:36:00  979    75553  tokio-runtime-w  8    CAP_SETPCAP          1\n16:36:00  0      616    systemd-journal  19   CAP_SYS_PTRACE       1\n16:36:00  0      616    systemd-journal  19   CAP_SYS_PTRACE       1\n16:36:00  979    75550  bpfman             24   CAP_SYS_RESOURCE     1\n16:36:00  979    75550  bpfman             1    CAP_DAC_OVERRIDE     1\n16:36:00  979    75550  bpfman             21   CAP_SYS_ADMIN        1\n16:36:00  979    75550  bpfman             21   CAP_SYS_ADMIN        1\n16:36:00  0      75555  modprobe         16   CAP_SYS_MODULE       1\n16:36:00  0      628    systemd-udevd    2    CAP_DAC_READ_SEARCH  1\n16:36:00  0      75556  bpf_preload      24   CAP_SYS_RESOURCE     1\n16:36:00  0      75556  bpf_preload      39   CAP_BPF              1\n16:36:00  0      75556  bpf_preload      39   CAP_BPF              1\n16:36:00  0      75556  bpf_preload      39   CAP_BPF              1\n16:36:00  0      75556  bpf_preload      38   CAP_PERFMON          1\n16:36:00  0      75556  bpf_preload      38   CAP_PERFMON          1\n16:36:00  0      75556  bpf_preload      38   CAP_PERFMON          1\n:\n</code></pre> <p>Compare the output to list in <code>bpfman.service</code> and determine the delta.</p>"},{"location":"developer-guide/linux-capabilities/#determine-capabilities-per-thread","title":"Determine Capabilities Per Thread","text":"<p>For additional debugging, it may be helpful to know the granted capabilities on a per thread basis. As mentioned above, all spawned threads are stripped of all Linux capabilities, so if a thread is requesting a capability, that functionality should be moved off the spawned thread and onto the main thread.</p> <p>First, determine the <code>bpfman</code> process id, then determine the set of threads:</p> <pre><code>$ ps -ef | grep bpfman\n:\nbpfman       75550       1  0 16:36 ?        00:00:00 /usr/sbin/bpfman\n:\n\n$ ps -T -p 75550\n    PID    SPID TTY          TIME CMD\n  75550   75550 ?        00:00:00 bpfman\n  75550   75551 ?        00:00:00 tokio-runtime-w\n  75550   75552 ?        00:00:00 tokio-runtime-w\n  75550   75553 ?        00:00:00 tokio-runtime-w\n  75550   75554 ?        00:00:00 tokio-runtime-w\n</code></pre> <p>Then dump the capabilities of each thread:</p> <pre><code>$ grep Cap /proc/75550/status\nCapInh: 000000c001201106\nCapPrm: 000000c001201106\nCapEff: 000000c001201106\nCapBnd: 000000c001201106\nCapAmb: 000000c001201106\n\n$ grep Cap /proc/75551/status\nCapInh: 0000000000000000\nCapPrm: 0000000000000000\nCapEff: 0000000000000000\nCapBnd: 0000000000000000\nCapAmb: 0000000000000000\n\n$ grep Cap /proc/75552/status\nCapInh: 0000000000000000\nCapPrm: 0000000000000000\nCapEff: 0000000000000000\nCapBnd: 0000000000000000\nCapAmb: 0000000000000000\n\n:\n\n$ capsh --decode=000000c001201106\n0x000000c001201106=cap_dac_override,cap_dac_read_search,cap_setpcap,cap_net_admin,cap_sys_admin,cap_sys_resource,cap_perfmon,cap_bpf\n</code></pre>"},{"location":"developer-guide/linux-capabilities/#removing-cap_bpf-from-bpfman-clients","title":"Removing CAP_BPF from bpfman Clients","text":"<p>One of the advantages of using bpfman is that it is doing all the loading and unloading of eBPF programs, so it requires CAP_BPF, but clients of bpfman are just making gRPC calls to bpfman, so they do not need to be privileged or require CAP_BPF. It must be noted that this is only true for kernels 5.19 or higher. Prior to kernel 5.19, all eBPF sys calls required CAP_BPF, which are used to access maps shared between the BFP program and the userspace program. In kernel 5.19, a change went in that only requires CAP_BPF for map creation (BPF_MAP_CREATE) and loading programs (BPF_PROG_LOAD). See bpf: refine kernel.unprivileged_bpf_disabled behaviour.</p>"},{"location":"developer-guide/logging/","title":"Logging","text":"<p>This section describes how to enable logging in different <code>bpfman</code> deployments.</p>"},{"location":"developer-guide/logging/#logs-from-bpfman-cli-commands","title":"Logs From bpfman CLI Commands","text":"<p><code>bpfman</code> uses the env_logger crate to log messages to the terminal. By default, only <code>error</code> messages are logged, but that can be overwritten by setting the <code>RUST_LOG</code> environment variable. Valid values:</p> <ul> <li><code>error</code></li> <li><code>warn</code></li> <li><code>info</code></li> <li><code>debug</code></li> <li><code>trace</code></li> </ul> <p>Example:</p> <pre><code>$ sudo RUST_LOG=info bpfman load image ...\n[INFO  bpfman] Request to load 1 programs\n[INFO  bpfman::oci_utils::cosign] Fetching Sigstore TUF data\n[INFO  bpfman::oci_utils::cosign] fetching fulcio_certs\n[INFO  bpfman::oci_utils::cosign] Creating ManualTrustRoot\n[INFO  bpfman::oci_utils::cosign] Starting Cosign Verifier, downloading data from Sigstore TUF repository\n:\n</code></pre>"},{"location":"developer-guide/logging/#logs-from-bpfman-running-as-systemd-service","title":"Logs From bpfman Running as Systemd Service","text":"<p>If <code>bpfman</code> is running as a systemd service, then <code>bpfman</code> will log to journald. By default, <code>info</code> and higher messages are logged, but that can be overwritten by setting the <code>RUST_LOG</code> environment variable.</p> <p>Example:</p> <pre><code>sudo vi /usr/lib/systemd/system/bpfman.service\n[Unit]\nDescription=Run bpfman as a service\nDefaultDependencies=no\nAfter=network.target\n\n[Service]\nEnvironment=\"RUST_LOG=Info\"    &lt;==== Set Log Level Here\nExecStart=/usr/sbin/bpfman system service\nAmbientCapabilities=CAP_BPF CAP_DAC_READ_SEARCH CAP_NET_ADMIN CAP_PERFMON CAP_SYS_ADMIN CAP_SYS_RESOURCE\nCapabilityBoundingSet=CAP_BPF CAP_DAC_READ_SEARCH CAP_NET_ADMIN CAP_PERFMON CAP_SYS_ADMIN CAP_SYS_RESOURCE\n</code></pre> <p>Start the service:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable --now bpfman.socket\n</code></pre> <p>Check the logs:</p> <pre><code>$ sudo journalctl -u bpfman.service -u bpfman.socket -f\nFeb 23 22:02:02 ebpf03 systemd[1]: bpfman.service: Deactivated successfully.\nFeb 25 13:21:49 ebpf03 systemd[1]: bpfman.socket: Deactivated successfully.\nFeb 25 13:21:49 ebpf03 systemd[1]: Closed bpfman.socket - bpfman API Socket.\nFeb 25 13:21:56 ebpf03 systemd[1]: Listening on bpfman.socket - bpfman API Socket.\nFeb 26 09:32:38 ebpf03 systemd[1]: bpfman.socket: Deactivated successfully.\nFeb 26 09:32:38 ebpf03 systemd[1]: Closed bpfman.socket - bpfman API Socket.\n:\n</code></pre> <p>Stop the service:</p> <pre><code>sudo systemctl stop bpfman.socket\n</code></pre>"},{"location":"developer-guide/logging/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>When <code>bpfman</code> is run in a Kubernetes deployment, there is the bpfman Daemonset that runs on every node and the bpfman Operator that runs on the control plane:</p> <pre><code>kubectl get pods -A\nNAMESPACE            NAME                                                    READY   STATUS    RESTARTS   AGE\nbpfman               bpfman-daemon-dgqzw                                     3/3     Running   0          3d22h\nbpfman               bpfman-daemon-gqsgd                                     3/3     Running   0          3d22h\nbpfman               bpfman-daemon-zx9xr                                     3/3     Running   0          3d22h\nbpfman               bpfman-operator-7fbf4888c4-z8w76                        2/2     Running   0          3d22h\n:\n</code></pre>"},{"location":"developer-guide/logging/#bpfman-daemonset","title":"bpfman Daemonset","text":"<p><code>bpfman</code> and <code>bpfman-agent</code> are running in the bpfman daemonset.</p>"},{"location":"developer-guide/logging/#view-logs","title":"View Logs","text":"<p>To view the <code>bpfman</code> logs:</p> <pre><code>kubectl logs -n bpfman bpfman-daemon-dgqzw -c bpfman\n[INFO  bpfman_rpc::serve] Using no inactivity timer\n[INFO  bpfman_rpc::serve] Using default Unix socket\n[INFO  bpfman_rpc::serve] Listening on /run/bpfman-sock/bpfman.sock\n[INFO  bpfman_rpc::storage] CSI Plugin Listening on /run/bpfman/csi/csi.sock\n:\n</code></pre> <p>To view the <code>bpfman-agent</code> logs:</p> <pre><code>kubectl logs -n bpfman bpfman-daemon-dgqzw -c bpfman-agent\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:37:08Z\",\"logger\":\"setup\",\"msg\":\"Waiting for active connection to bpfman\"}\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:37:08Z\",\"logger\":\"setup\",\"msg\":\"starting Bpfman-Agent\"}\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:37:08Z\",\"logger\":\"controller-runtime.metrics\",\"msg\":\"Starting metrics server\"}\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:37:08Z\",\"msg\":\"starting server\",\"name\":\"health probe\",\"addr\":\"[::]:8175\"}\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:37:08Z\",\"msg\":\"starting server\",\"name\":\"pprof\",\"addr\":\"[::]:6060\"}\n:\n</code></pre>"},{"location":"developer-guide/logging/#change-log-level","title":"Change Log Level","text":"<p>To change the log level of the agent or daemon, edit the <code>bpfman-config</code> ConfigMap. The <code>bpfman-operator</code> will detect the change and restart the bpfman daemonset with the updated values.</p> <pre><code>kubectl edit configmaps -n bpfman bpfman-config\napiVersion: v1\ndata:\n  bpfman.agent.image: quay.io/bpfman/bpfman-agent:latest\n  bpfman.image: quay.io/bpfman/bpfman:latest\n  bpfman.log.level: info                     &lt;==== Set bpfman Log Level Here\n  bpfman.agent.log.level: info               &lt;==== Set bpfman agent Log Level Here\nkind: ConfigMap\nmetadata:\n  creationTimestamp: \"2023-05-05T14:41:19Z\"\n  name: bpfman-config\n  namespace: bpfman\n  resourceVersion: \"700803\"\n  uid: 0cc04af4-032c-4712-b824-748b321d319b\n</code></pre> <p>Valid values for the daemon (<code>bpfman.log.level</code>) are:</p> <ul> <li><code>error</code></li> <li><code>warn</code></li> <li><code>info</code></li> <li><code>debug</code></li> <li><code>trace</code></li> </ul> <p><code>trace</code> can be very verbose. More information can be found regarding Rust's env_logger here.</p> <p>Valid values for the agent (<code>bpfman.agent.log.level</code>) are:</p> <ul> <li><code>info</code></li> <li><code>debug</code></li> <li><code>trace</code></li> </ul>"},{"location":"developer-guide/logging/#bpfman-operator","title":"bpfman Operator","text":"<p>The bpfman Operator is running as a Deployment with a ReplicaSet of one. It runs with the containers <code>bpfman-operator</code> and <code>kube-rbac-proxy</code>.</p>"},{"location":"developer-guide/logging/#view-logs_1","title":"View Logs","text":"<p>To view the <code>bpfman-operator</code> logs:</p> <pre><code>kubectl logs -n bpfman bpfman-operator-7fbf4888c4-z8w76 -c bpfman-operator\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:36:57Z\",\"logger\":\"setup\",\"msg\":\"Discovering APIs\"}\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:36:57Z\",\"logger\":\"setup\",\"msg\":\"detected platform version\",\"PlatformVersion\":\"v1.32.2\"}\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:36:57Z\",\"logger\":\"setup\",\"msg\":\"starting manager\"}\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:36:57Z\",\"logger\":\"controller-runtime.metrics\",\"msg\":\"Starting metrics server\"}\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:36:57Z\",\"msg\":\"starting server\",\"name\":\"health probe\",\"addr\":\"[::]:8175\"}\n{\"level\":\"info\",\"ts\":\"2025-03-06T13:36:57Z\",\"logger\":\"controller-runtime.metrics\",\"msg\":\"Serving metrics server\",\"bindAddress\":\"127.0.0.1:8174\",\"secure\":false}\n:\n</code></pre> <p>To view the <code>kube-rbac-proxy</code> logs:</p> <pre><code>kubectl logs -n bpfman bpfman-operator-7fbf4888c4-z8w76 -c kube-rbac-proxy\nI0509 18:37:11.063386       1 main.go:186] Valid token audiences: \nI0509 18:37:11.063485       1 main.go:316] Generating self signed cert as no cert is provided\nI0509 18:37:11.955256       1 main.go:366] Starting TCP socket on 0.0.0.0:8443\nI0509 18:37:11.955849       1 main.go:373] Listening securely on 0.0.0.0:8443\n</code></pre>"},{"location":"developer-guide/logging/#change-log-level_1","title":"Change Log Level","text":"<p>To change the log level, edit the <code>bpfman-operator</code> Deployment. The change will get detected and the bpfman operator pod will get restarted with the updated log level.</p> <pre><code>kubectl edit deployment -n bpfman bpfman-operator\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: \"1\"\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/component\":\"manager\",\"app.kubernetes.io/create&gt;\n  creationTimestamp: \"2023-05-09T18:37:08Z\"\n  generation: 1\n:\nspec:\n:\n  template:\n    metadata:\n:\n    spec:\n      containers:\n      - args:\n:\n      - args:\n        - --health-probe-bind-address=:8175\n        - --metrics-bind-address=127.0.0.1:8174\n        - --leader-elect\n        command:\n        - /bpfman-operator\n        env:\n        - name: GO_LOG\n          value: info                   &lt;==== Set Log Level Here\n        image: quay.io/bpfman/bpfman-operator:latest\n        imagePullPolicy: IfNotPresent\n:\n</code></pre> <p>Valid values are:</p> <ul> <li><code>error</code></li> <li><code>info</code></li> <li><code>debug</code></li> <li><code>trace</code></li> </ul>"},{"location":"developer-guide/observability/","title":"Observability","text":""},{"location":"developer-guide/observability/#ebpf-metrics-exporter","title":"eBPF Metrics Exporter","text":"<p>The eBPF Metrics Exporter (<code>bpf-metrics-exporter</code>) exports metrics from the kernel's BPF subsystem to OpenTelmetry.</p> <p>Note</p> <p>An initial set of metrics have been added as a proof of concept. The metrics can be enriched with other metrics from the system as use cases are identified. For example, a possible improvement could be to correlate process IDs -&gt; containers -&gt; k8s pods.</p>"},{"location":"developer-guide/observability/#metrics","title":"Metrics","text":"<p>The following metrics are currently exported, this list will continue to expand:</p>"},{"location":"developer-guide/observability/#gauges","title":"Gauges","text":"<ul> <li><code>bpf_program_info</code>: Information on each loaded BPF Program<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF program</li> <li><code>name</code>: The name of the BPF program</li> <li><code>type</code>: The type of the BPF program as a readable string</li> <li><code>tag</code>: The tag of the BPF program</li> <li><code>gpl_compatible</code>: Whether the BPF program is GPL compatible</li> <li><code>map_ids</code>: List of associated maps, if any</li> <li><code>load_time</code>: The time the BPF program was loaded</li> </ul> </li> </ul> </li> <li><code>bpf_map_info</code>: Information of each loaded BPF Map<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF map</li> <li><code>name</code>: The name of the BPF map</li> <li><code>type</code>: The type of the BPF map as an <code>u32</code> which corresponds to the following    kernel enumeration</li> <li><code>key_size</code>: The key size in bytes for the BPF map</li> <li><code>value_size</code>: The value size for the BPF map</li> <li><code>max_entries</code>: The maximum number of entries for the BPF map.</li> <li><code>flags</code>: Loadtime specific flags for the BPF map</li> </ul> </li> </ul> </li> <li><code>bpf_link_info</code>: Information on each of the loaded BPF Link<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the bpf Link</li> <li><code>prog_id</code>: The Program ID of the BPF program which is using the Link.</li> <li><code>type</code>: The BPF Link type as a <code>u32</code> which corresponds to the following    kernel enumeration</li> </ul> </li> </ul> </li> <li><code>bpf_program_load_time</code>: The standard UTC time the program was loaded in seconds<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF program</li> <li><code>name</code>: The name of the BPF program</li> <li><code>type</code>: The type of the BPF program as a readable string</li> </ul> </li> </ul> </li> </ul>"},{"location":"developer-guide/observability/#counters","title":"Counters","text":"<ul> <li><code>bpf_program_size_jitted_bytes</code>: The size in bytes of the program's JIT-compiled machine code.<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF program</li> <li><code>name</code>: The name of the BPF program</li> <li><code>type</code>: The type of the BPF program as a readable string</li> </ul> </li> </ul> </li> <li><code>bpf_program_size_translated_bytes</code>: The size of the BPF program in bytes.<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF program</li> <li><code>name</code>: The name of the BPF program</li> <li><code>type</code>: The type of the BPF program as a readable string</li> </ul> </li> </ul> </li> <li><code>bpf_program_mem_bytes</code>: The amount of memory used by the BPF program in bytes.<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF program</li> <li><code>name</code>: The name of the BPF program</li> <li><code>type</code>: The type of the BPF program as a readable string</li> </ul> </li> </ul> </li> <li><code>bpf_program_verified_instructions</code>: The number of instructions in the BPF program.<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF program</li> <li><code>name</code>: The name of the BPF program</li> <li><code>type</code>: The type of the BPF program as a readable string</li> </ul> </li> </ul> </li> <li><code>bpf_map_key_size</code>: The size of the BPF map key<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF map</li> <li><code>name</code>: The name of the BPF map</li> <li><code>type</code>: The type of the BPF map as an <code>u32</code> which corresponds to the following kernel enumeration</li> </ul> </li> </ul> </li> <li><code>bpf_map_value_size</code>: The size of the BPF map value<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF map</li> <li><code>name</code>: The name of the BPF map</li> <li><code>type</code>: The type of the BPF map as an <code>u32</code> which corresponds to the following kernel enumeration</li> </ul> </li> </ul> </li> <li><code>bpf_map_max_entries</code>: The maximum number of entries allowed for the BPF map<ul> <li>Labels:<ul> <li><code>id</code>: The ID of the BPF map</li> <li><code>name</code>: The name of the BPF map</li> <li><code>type</code>: The type of the BPF map as an <code>u32</code> which corresponds to the following kernel enumeration</li> </ul> </li> </ul> </li> </ul> <p>Note</p> <p>All counters will need to have the suffix <code>_total</code> appended when exposed as a sample metric (For an example, search for <code>_total</code> in bpf-metrics-exporter/metrics-stack.yaml).</p>"},{"location":"developer-guide/observability/#try-it-out","title":"Try it Out","text":"<p>Grafana Stack:</p> <p>You'll need a Grafana stack set up. You can quickly deploy one using:</p> <pre><code>podman play kube metrics-stack.yaml\n</code></pre> <p>Installation:</p> <p><code>bpf-metrics-exporter</code> can be installed using the installation script:</p> <pre><code>cd bpfman/\nsudo ./scripts/setup.sh install\n</code></pre> <p>Run:</p> <p>Then, you can deploy the exporter:</p> <pre><code>sudo bpf-metrics-exporter\n</code></pre> <p>Verify:</p> <p>You can log into grafana at <code>http://localhost:3000/</code> using the default user:password <code>admin:admin</code>.</p> <p>From there simply select the default dashboard titled <code>eBPF Subsystem Metrics</code>:</p> <p></p> <p>Cleanup:</p> <p>In order to clean everything up simply exit the bpf-metrics-exporter process with <code>&lt;CTRL&gt;C</code> and run:</p> <pre><code>podman kube down metrics-stack.yaml\n</code></pre>"},{"location":"developer-guide/observability/#ebpf-log-exporter","title":"eBPF Log Exporter","text":"<p>The eBPF Log Exporter (<code>bpf-log-exporter</code>) is a utility tool that registers with the kernel auditing service to receive audit events. The eBPF Log Exporter filters out eBPF related events. Currently, these events are then printed to the terminal. Long term, these events will be forwarded as logs to OpenTelemetry.</p> <p>Note</p> <p>eBPF Log Exporter is a work in progress. Currently, audit events are just printed to a terminal, but the long term plan is for these events to be forwarded as logs to OpenTelemetry similar to how bpf-metric-exporter is implemented.</p> <p>Prerequisites:</p> <ul> <li>Auditing must be enabled in the kernel.</li> </ul> <p>Installation:</p> <p><code>bpf-log-exporter</code> can be installed using the installation script:</p> <pre><code>cd bpfman/\nsudo ./scripts/setup.sh install\n</code></pre> <p>Run:</p> <p><code>bpf-log-exporter</code> needs root privileges to run. To see the logs, run with at least <code>info</code> level logs enabled.</p> <pre><code>$ sudo RUST_LOG=info bpf-log-exporter\n[INFO  bpf_log_exporter] AUDIT_BPF: LogMessage { timestamp: \"1727301213.084\", prog_id: 326, op: \"LOAD\", syscall_op: 0, pid: 0, uid: 0, gid: 0, comm: \"\", cmdline: \"\" }\n[INFO  bpf_log_exporter] AUDIT_BPF: LogMessage { timestamp: \"1727301213.095\", prog_id: 327, op: \"LOAD\", syscall_op: 0, pid: 0, uid: 0, gid: 0, comm: \"\", cmdline: \"\" }\n[INFO  bpf_log_exporter] AUDIT_BPF: LogMessage { timestamp: \"1727301213.109\", prog_id: 326, op: \"UNLOAD\", syscall_op: 0, pid: 0, uid: 0, gid: 0, comm: \"\", cmdline: \"\" }\n[INFO  bpf_log_exporter] AUDIT_BPF: LogMessage { timestamp: \"1727301213.109\", prog_id: 327, op: \"UNLOAD\", syscall_op: 0, pid: 0, uid: 0, gid: 0, comm: \"\", cmdline: \"\" }\n[INFO  bpf_log_exporter] AUDIT_BPF: LogMessage { timestamp: \"1727301228.487\", prog_id: 328, op: \"LOAD\", syscall_op: 0, pid: 0, uid: 0, gid: 0, comm: \"\", cmdline: \"\" }\n[INFO  bpf_log_exporter] AUDIT_BPF: LogMessage { timestamp: \"1727301228.488\", prog_id: 328, op: \"UNLOAD\", syscall_op: 0, pid: 0, uid: 0, gid: 0, comm: \"\", cmdline: \"\" }\n[INFO  bpf_log_exporter] AUDIT_BPF: LogMessage { timestamp: \"1727301228.488\", prog_id: 329, op: \"LOAD\", syscall_op: 0, pid: 0, uid: 0, gid: 0, comm: \"\", cmdline: \"\" }\n[INFO  bpf_log_exporter] AUDIT_BPF: LogMessage { timestamp: \"1727301228.488\", prog_id: 329, op: \"UNLOAD\", syscall_op: 0, pid: 0, uid: 0, gid: 0, comm: \"\", cmdline: \"\" }\n:\n</code></pre> <p>Then use <code>&lt;CTRL&gt;C</code> to stop.</p>"},{"location":"developer-guide/pre-commit-hook/","title":"Pre-Commit Configuration","text":"<p>This repository uses pre-commit to automate code quality checks and formatting for YAML and Rust files. The following hooks are configured to ensure code consistency and quality.</p>"},{"location":"developer-guide/pre-commit-hook/#prerequisites","title":"Prerequisites","text":"<ul> <li>Ensure you have Python and <code>pip</code> installed.</li> <li>Install <code>pre-commit</code> by running:</li> </ul> <pre><code>pip install pre-commit\n</code></pre> <ul> <li>Make sure you have Rust and Cargo installed. You can install them from   rust-lang.org.</li> </ul>"},{"location":"developer-guide/pre-commit-hook/#setup","title":"Setup","text":"<p>To set up the pre-commit hooks in your repository, run:</p> <pre><code>pre-commit install\n</code></pre> <p>This will install the hooks defined in <code>.pre-commit-config.yaml</code>.</p>"},{"location":"developer-guide/pre-commit-hook/#hooks-overview","title":"Hooks Overview","text":""},{"location":"developer-guide/pre-commit-hook/#yaml-linting","title":"YAML Linting","text":"<ul> <li>Hook ID: <code>yamllint</code></li> <li>Description: This hook checks YAML files for syntax errors and best   practices.</li> <li>Command:   <pre><code>yamllint -c .yamllint.yaml --strict\n</code></pre></li> </ul>"},{"location":"developer-guide/pre-commit-hook/#rust-clippy","title":"Rust Clippy","text":"<ul> <li>Hook ID: <code>clippy</code></li> <li>Description: This hook runs Clippy, a linting tool for Rust, to catch   common mistakes and improve your code.</li> <li>Command:   <pre><code>bash -c 'export NIGHTLY_VERSION=nightly-2024-09-24 &amp;&amp; cargo +${NIGHTLY_VERSION}\nclippy --all -- --deny warnings'\n</code></pre></li> </ul>"},{"location":"developer-guide/pre-commit-hook/#rust-formatting","title":"Rust Formatting","text":"<ul> <li>Hook ID: <code>fmt</code></li> <li>Description: This hook formats Rust code according to the standard Rust   style.</li> <li>Command:   <pre><code>bash -c 'export NIGHTLY_VERSION=nightly-2024-09-24 &amp;&amp; cargo +${NIGHTLY_VERSION}\nfmt --all -- --check'\n</code></pre></li> </ul>"},{"location":"developer-guide/pre-commit-hook/#xtask-public-api","title":"Xtask Public API","text":"<ul> <li>Hook ID: <code>xtask-public-api</code></li> <li>Description: This hook runs a custom command defined in <code>xtask</code> to   check the public API of the Rust project.</li> <li>Command:   <pre><code>bash -c 'export NIGHTLY_VERSION=nightly-2024-09-24 &amp;&amp; cargo xtask public-api\n--toolchain ${NIGHTLY_VERSION}'\n</code></pre></li> </ul>"},{"location":"developer-guide/pre-commit-hook/#usage","title":"Usage","text":"<p>To manually run all configured hooks, execute:</p> <pre><code>pre-commit run --all-files\n</code></pre> <p>You can also run a specific hook by specifying its ID. For example, to run Clippy, use:</p> <pre><code>pre-commit run clippy --all-files\n</code></pre>"},{"location":"developer-guide/pre-commit-hook/#customizing-the-toolchain","title":"Customizing the Toolchain","text":"<p>The hooks are configured to use a specific nightly version of Rust (<code>nightly-2024-09-24</code>). If you want to change the nightly version, simply update the <code>NIGHTLY_VERSION</code> variable in the respective hook commands in <code>.pre-commit-config.yaml</code>.</p>"},{"location":"developer-guide/release/","title":"Release Process","text":"<p>This document describes the process for making a release for the bpfman project.</p>"},{"location":"developer-guide/release/#overview","title":"Overview","text":"<p>The bpfman project includes both the bpfman and bpfman-operator repositories. When a release is made for the project, a release is created for each repository with the same version number.</p> <p>Each bpfman project release is comprised of the following major components:</p> <ul> <li>bpfman (Core library) and bpfman-api (Core GRPC API protobuf definitions)   library crates</li> <li>bpfman (CLI), and bpfman-rpc (gRPC server) binary crates</li> <li>bpf-metrics-exporter and bpf-log-exporter binary crates</li> <li>bpfman RPMs stored in the bpfman COPR repository.</li> <li>Kubernetes Custom Resource Definitions (CRDs):<ul> <li><code>BpfApplication</code> and <code>BpfNsApplication</code></li> <li><code>BpfProgram</code> and <code>BpfNsProgram</code></li> <li><code>FentryProgram</code></li> <li><code>FexitProgram</code></li> <li><code>KprobeProgram</code></li> <li><code>TcProgram</code> and <code>TcNsProgram</code></li> <li><code>TcxProgram</code> and <code>TcxNsProgram</code></li> <li><code>TracepointProgram</code></li> <li><code>UprobeProgram</code> and <code>UprobeNsProgram</code></li> <li><code>XdpProgram</code> and <code>XdpNsProgram</code></li> </ul> </li> <li>Corresponding go pkgs in the form of <code>github.com/bpfman/bpfman</code> which includes   the following:<ul> <li><code>github.com/bpfman/bpfman/clients/gobpfman/v1</code>: The go client for the   bpfman GRPC API API helpers.</li> </ul> </li> <li>Corresponding go pkgs in the form of <code>github.com/bpfman/bpfman-operator</code> which   includes the following:<ul> <li><code>github.com/bpfman/bpfman-operator/apis</code>: The go bindings for the bpfman   CRD API</li> <li><code>github.com/bpfman/bpfman-operator/pkg/client</code>: The autogenerated   clientset for the bpfman CRD API</li> <li><code>github.com/bpfman/bpfman-operator/pkg/helpers</code>: The provided bpfman CRD   API helpers.</li> </ul> </li> <li>The following core component container images with tag <code>&lt;RELEASE_VERSION&gt;</code>:<ul> <li><code>quay.io/bpfman/bpfman-agent</code></li> <li><code>quay.io/bpfman/bpfman-operator-bundle</code></li> <li><code>quay.io/bpfman/bpfman-operator</code></li> <li><code>quay.io/bpfman/bpfman</code></li> <li><code>quay.io/bpfman/tc-dispatcher</code></li> <li><code>quay.io/bpfman/xdp-dispatcher</code></li> </ul> </li> <li>The relevant example bytecode container images with tag <code>&lt;RELEASE_VERSION&gt;</code> from   source code located in the bpfman project:<ul> <li><code>quay.io/bpfman-bytecode/fentry</code></li> <li><code>quay.io/bpfman-bytecode/fexit</code></li> <li><code>quay.io/bpfman-bytecode/go-app-counter</code></li> <li><code>quay.io/bpfman-bytecode/go-kprobe-counter</code></li> <li><code>quay.io/bpfman-bytecode/go-tc-counter</code></li> <li><code>quay.io/bpfman-bytecode/go-tracepoint-counter</code></li> <li><code>quay.io/bpfman-bytecode/go-uprobe-counter</code></li> <li><code>quay.io/bpfman-bytecode/go-xdp-counter</code></li> <li><code>quay.io/bpfman-bytecode/kprobe</code></li> <li><code>quay.io/bpfman-bytecode/kretprobe</code></li> <li><code>quay.io/bpfman-bytecode/tc-pass</code></li> <li><code>quay.io/bpfman-bytecode/tcx-test</code></li> <li><code>quay.io/bpfman-bytecode/tracepoint</code></li> <li><code>quay.io/bpfman-bytecode/uprobe</code></li> <li><code>quay.io/bpfman-bytecode/uretprobe</code></li> <li><code>quay.io/bpfman-bytecode/xdp-pass-private</code></li> <li><code>quay.io/bpfman-bytecode/xdp-pass</code></li> </ul> </li> <li>The relevant example userspace container images with tag <code>&lt;RELEASE_VERSION&gt;</code>   from source code located in the bpfman project:<ul> <li><code>quay.io/bpfman-userspace/go-app-counter</code></li> <li><code>quay.io/bpfman-userspace/go-kprobe-counter</code></li> <li><code>quay.io/bpfman-userspace/go-target</code></li> <li><code>quay.io/bpfman-userspace/go-tc-counter</code></li> <li><code>quay.io/bpfman-userspace/go-tcx-counter</code></li> <li><code>quay.io/bpfman-userspace/go-tracepoint-counter</code></li> <li><code>quay.io/bpfman-userspace/go-uprobe-counter</code></li> <li><code>quay.io/bpfman-userspace/go-xdp-counter</code></li> </ul> </li> <li>The OLM (Operator Lifecycle Manager) for the Kubernetes Operator.<ul> <li>This includes a <code>bundle</code> directory on disk as well as the   <code>quay.io/bpfman/bpfman-operator-bundle</code> image with the tag   <code>&lt;RELEASE_VERSION&gt;</code>.</li> </ul> </li> </ul>"},{"location":"developer-guide/release/#versioning-strategy","title":"Versioning strategy","text":""},{"location":"developer-guide/release/#release-version-number","title":"Release Version Number","text":"<p><code>bpfman</code> uses the MAJOR.MINOR.PATCH scheme defined by SemVer for version numbers in which the components are defined as follows:</p> <ul> <li>MAJOR: Incremented for incompatible API changes.</li> <li>MINOR: Incremented for adding functionality in a backward-compatible manner.</li> <li>PATCH: Incremented for backward-compatible bug fixes.</li> </ul> <p>Major version zero (0.y.z) is for initial development. If the MAJOR version is 0, anything MAY change at any time, and the public API SHOULD NOT be considered stable.</p> <p>Releases are tagged in git with the version number prefixed by \"v\".  For example, release version 0.5.6 is tagged as v0.5.6.</p>"},{"location":"developer-guide/release/#kubernetes-api-versions-eg-v1alpha2-v1beta1","title":"Kubernetes API Versions (e.g. v1alpha2, v1beta1)","text":"<p>Within the bpfman-operator, API versions are primarily used to indicate the stability of a resource. For example, if a resource has not yet graduated to beta, it is still possible that it could either be removed from the API or changed in backward incompatible ways. For more information on API versions, refer to the Kubernetes API versioning documentation.</p>"},{"location":"developer-guide/release/#releasing-a-new-version","title":"Releasing a New Version","text":""},{"location":"developer-guide/release/#release-process-overview","title":"Release Process Overview","text":"<p>Since bpfman and bpfman-operator are maintained in separate repositories, each requires an independent release. However, to ensure version consistency, we plan to synchronize the release versions of both projects. Therefore, whenever a release is needed for either bpfman or bpfman-operator, both repositories will be released with the same version number.</p> <p>As bpfman-operator depends on bpfman, it is essential to release bpfman first, followed by bpfman-operator.</p> <p>Whenever possible, releases are made on the main branch of each repository and should follow the Standard Release from Main Branch process.  However, it is sometimes necessary to \"patch\" a previous release with some but not all of the changes that exist on the main branch.  In those cases, a patch branch is created from the tag of the release being patched and the release is done on that branch as described in the Patch Branch Release section. Finally, if it is necessary to test the release automation, the simplified process described in the Release Candidate Release section can be used.</p>"},{"location":"developer-guide/release/#generating-release-notes","title":"Generating Release Notes","text":"<p>The release notes are contained in <code>CHANGELOG</code> files stored in the <code>changelogs</code> directory of each repository.  The change log name must contain the release version (e.g., <code>CHANGELOG-v0.5.6.md</code>).</p> <p>To simplify the generation of the release notes details, we are using the GitHub release page as described below.  Note that we only use the release page to generate a starting point for the release notes, and don't actually create a tag or do a release from it. </p> <ol> <li>Go to the bpfman releases page or the     bpfman-operator releases page.</li> <li>Push the \"Draft a new release\" button.</li> <li>Enter the new release number in the \"Choose a tag\" pull-down.</li> <li>Choose the most recent release in the \"Previous tag\" pull-down.</li> <li>Push the \"Generate release notes\" button.</li> <li>The automatically generated output will likely need to be reorganized and    cleaned up a bit, but it provides a good starting point.</li> <li>The generated content will be used in the next section and copied into a    CHANGELOG-vX.Y.Z.md file.</li> </ol> <p>The format for the CHANGELOG file is as follows:</p> <ol> <li>Summary of the major changes and highlights. For example: \"The v0.5.6 release    is a patch release that introduced...\"</li> <li>What's Changed (minor changes may be removed from the list generated by GitHub)</li> <li>Full Changelog</li> <li>New Contributors</li> <li>Known Issues</li> </ol> <p>Notes on generating the changelog</p> <ul> <li>Empty sections should be omitted.</li> <li>Sections 2-3 may be copied and pasted from the text generated with the GitHub   releases page process described above.</li> <li>The CHANGELOG for a given release is used by GitHub to generate the initial   content for that release on the bpfman releases page or the   bpfman-operator releases page.   However, after the release has been generated, updates to the CHANGELOG file   are not automatically reflected on the GitHub releases page, so the GitHub   releases page must be manually edited using the GitHub GUI.</li> <li>Unlike most markdown, the generated output on the GitHub releases page renders   each newline in the CHANGELOG file. So each paragraph should be on a single   line, or it will not flow as intended.</li> </ul>"},{"location":"developer-guide/release/#standard-release-from-main-branch","title":"Standard Release from Main Branch","text":"<p>This section describes the standard release process used when making a release from the main branch and may be used for major, minor, or patch releases.  As mentioned above, we first complete the release for <code>bpfman</code> and then follow that up with a release for <code>bpfman-operator</code>.</p>"},{"location":"developer-guide/release/#bpfman-release","title":"bpfman Release","text":"<ul> <li>Create a new branch in your <code>bpfman</code> fork, for example   <code>&lt;githubuser&gt;/release-x.y.z</code>, and use the new branch in the upcoming steps.</li> <li>Make the following changes<ul> <li>Add a new changelog file for the release using the process described in   Generating Release Notes and copy the generated   content into a new CHANGELOG-vX.Y.Z.md file in   bpfman/changelogs.</li> <li>Update the   Cargo.toml   version for the workspace:<ul> <li><code>version = \"x.y.z\"</code></li> <li><code>bpfman = { version = \"x.y.z\", path = \"./bpfman\" }\"</code></li> <li><code>bpfman-api = { version = \"x.y.z\", path = \"./bpfman-api\" }</code></li> <li>Note: <code>bpfman-csi</code> does not need to be updated.</li> </ul> </li> <li>Run <code>cargo generate-lockfile</code></li> <li>Update the bpfman version in the bpfman/examples/Makefile:<ul> <li>VERSION ?= x.y.z</li> </ul> </li> <li>Add a new <code>bpfman/examples/config/v0.x.y/</code> and   <code>bpfman/examples/config/v0.x.y-selinux/</code> config directory for the release   version by copying the latest release directory and running a search for   the current release and replace with the new release.</li> <li>Add new example config directories for any new examples added since the   last release.</li> <li>Search the code and docs for the current version number without the \"v\"   (e.g., 0.5.6) and replace it with the new version number where it makes   sense.  (Be careful, though, because not all should be replaced.)</li> </ul> </li> <li>Commit the changes, push them to your repo, and open a PR against the <code>bpfman</code>   repo.</li> <li>After the PR is reviewed, merged, and all GitHub actions have completed   successfully, tag the release with the version number (e.g., v0.5.6).<ul> <li>Tag the release using the commit on <code>main</code> where the changelog update   merged.</li> <li>A maintainer or someone with write permission on the repo must create the   tag.</li> <li>This can be done using the <code>git</code> CLI or Github's bpfman release page.</li> </ul> </li> <li>The Release will be automatically created by GitHub actions when the tag is   applied.</li> </ul> <p>After these steps are completed, the following should occur:</p> <ul> <li>All GitHub actions should complete successfully.</li> <li>The release appears on the GitHub Releases Page.</li> <li>Images are built and updated with the new version tag at:<ul> <li>quay.io/bpfman</li> <li>quay.io/bpfman-bytecode</li> <li>quay.io/bpfman-userspace</li> </ul> </li> <li>The new version appears at crates.io</li> <li>New RPMs are built and pushed to the bpfman COPR   repository.</li> </ul> <p>After the release is complete do the following:</p> <ul> <li>Run <code>make build-release-yamls</code> from the <code>bpfman/examples</code> directory.   Next, on the GitHub <code>Releases</code> webpage, find the newly generated release notes   and click on the edit icon (a pencil icon).   Then copy (drag and drop) the generated yaml files to the release as <code>Assets</code>   on the webpage and click <code>Update release</code> button.<ul> <li>The yaml files generated include:<ul> <li><code>go-app-counter-install-selinux.yaml</code></li> <li><code>go-app-counter-install.yaml</code></li> <li><code>go-kprobe-counter-install-selinux.yaml</code></li> <li><code>go-kprobe-counter-install.yaml</code></li> <li><code>go-tc-counter-install-selinux.yaml</code></li> <li><code>go-tc-counter-install.yaml</code></li> <li><code>go-tcx-counter-install-selinux.yaml</code></li> <li><code>go-tcx-counter-install.yaml</code></li> <li><code>go-tracepoint-counter-install-selinux.yaml</code></li> <li><code>go-tracepoint-counter-install.yaml</code></li> <li><code>go-uprobe-counter-install-selinux.yaml</code></li> <li><code>go-uprobe-counter-install.yaml</code></li> <li><code>go-uretprobe-counter-install-selinux.yaml</code></li> <li><code>go-uretprobe-counter-install.yaml</code></li> <li><code>go-xdp-counter-install-selinux.yaml</code></li> <li><code>go-xdp-counter-install.yaml</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"developer-guide/release/#bpfman-operator-release","title":"bpfman-operator Release","text":"<ul> <li>Create a new branch in your <code>bpfman-operator</code> fork, for example   <code>&lt;githubuser&gt;/release-x.y.z</code>, and use the new branch in the upcoming steps.</li> <li>Make the following changes<ul> <li>Add a new changelog for the release using the process described in   Generating Release Notes and copy the generated   content into a new CHANGELOG-vX.Y.Z.md file in   bpfman-operator/changelogs.</li> <li>Update the bpfman version in go.mod</li> <li>Run the following commands from the bpfman-operator directory:   <pre><code>go mod tidy\ngo mod vendor\n</code></pre></li> <li>Update the bpfman-operator version in the Makefile:<ul> <li><code>VERSION ?= x.y.z</code></li> </ul> </li> <li>Run <code>make bundle</code> from the bpfman-operator directory to update the bundle   version.</li> <li>Update the version in the OpenShift Containerfiles.</li> <li>Search the bpfman-operator directory and make sure there are no remaining <code>x.y.z</code>   strings that need to be replaced.</li> </ul> </li> <li>Commit the changes, push them to your repo, and open a PR against the   <code>bpfman-operator</code> repo.</li> <li>After the PR is reviewed, merged, and all GitHub actions have completed   successfully, tag the release with the version number (e.g., v0.5.6).<ul> <li>Tag the release using the commit on <code>main</code> where the changelog update   merged.</li> <li>A maintainer or someone with write permission on the repo must create the   tag.</li> <li>This can be done using the <code>git</code> CLI or Github's bpfman-operator release page.</li> </ul> </li> <li>The Release will be automatically created by GitHub actions when the tag is   applied.</li> </ul> <p>After these steps are completed, the following should occur:</p> <ul> <li>All GitHub actions should complete successfully.</li> <li>The release appears on the GitHub Releases Page.</li> <li>Images are built and updated with the new version tag at:<ul> <li><code>quay.io/bpfman/bpfman-operator</code></li> <li><code>quay.io/bpfman/bpfman-agent</code></li> </ul> </li> </ul> <p>After the release is complete do the following:</p> <ul> <li>Run <code>make build-release-yamls</code> from the <code>bpfman-operator/</code> directory, and then   Next, on the GitHub <code>Releases</code> webpage, find the newly generated release notes   and click on the edit icon (a pencil icon).   Then copy (drag and drop) the generated yaml files to the release as <code>Assets</code>   on the webpage and click <code>Update release</code> button.<ul> <li>The yaml files generated include:<ul> <li><code>bpfman-crds-install.yaml</code></li> <li><code>bpfman-operator-install.yaml</code></li> </ul> </li> </ul> </li> <li>Update the community-operator and   community-operators-prod repositories with the   latest bundle manifests.<ul> <li>Run <code>IMAGE_TAG=vx.y.z make bundle</code> from <code>bpfman-operator</code>.</li> <li>Manually update the following tags in   <code>bpfman-operator/bundle/manifests/bpfman-operator.clusterserviceversion.yaml</code> (TODO: automate   this step).<ul> <li>Change <code>:latest</code> to <code>:vx.y.z</code> in all the example image URLs: <pre><code>\"url\": \"quay.io/bpfman-bytecode/&lt;example&gt;&gt;:latest\"\n</code></pre> to <pre><code>\"url\": \"quay.io/bpfman-bytecode/&lt;example&gt;:v0.5.6\"\n</code></pre></li> <li>Change <code>:latest</code> to <code>:vx.y.z</code> in the bpfman-operator container image reference: <pre><code>containerImage: quay.io/bpfman/bpfman-operator:latest\n</code></pre> to <pre><code>containerImage: quay.io/bpfman/bpfman-operator:vx.y.z\n</code></pre></li> </ul> </li> <li>Open a PR in the community-operator repository with the following:<ul> <li>Create a new release directory under <code>operator/bpfman-operator/</code> named <code>x.y.z</code>:   <pre><code>cd $SRC_DIR/community-operators/operators/bpfman-operator/\nmkdir x.y.z\n</code></pre></li> <li>Copy the directories <code>bpfman-operator/bundle/{manifests, metadata, tests}</code> and the file   <code>bpfman-operator/bundle.Dockerfile</code> to the new release directory.   <pre><code>cd x.y.z\ncp -r $SRC_DIR/bpfman-operator/bundle/manifests/ .\ncp -r $SRC_DIR/bpfman-operator/bundle/metadata/ .\ncp -r $SRC_DIR/bpfman-operator/bundle/tests/ .\ncp $SRC_DIR/bpfman-operator/bundle.Dockerfile .\n</code></pre></li> <li>Push the PR as a draft PR to allow for review (see Note).   Once the PR is reviewed and all checks pass, mark it as ready for review.   Once it merges, move to the next repository.</li> </ul> </li> <li>Open a PR in the community-operators-prod repository.   Repeat the previous steps, but don't push PR as draft.</li> <li>NOTE: Lessons learned about updating the community operators: <ul> <li>These PRs usually auto-merge as soon as all checks pass, and once a   bundle for a release is merged, it cannot be modified. If any errors   are found in the bundle files after merging, the only solution is to   create a new release and open a new PR in each community operator   repository.</li> <li>If you start a PR in the community-operator repository as a draft and   later mark it as ready for review, it will still auto-merge. However,   this auto-merge behavior doesn\u2019t apply in the community-operators-prod   repository, where a maintainer must manually merge the PR if you start   it as draft.</li> <li>To streamline the process, it\u2019s recommended that you begin with a   draft PR in the community-operator repository to allow for review.   Once the PR is reviewed and all checks pass, mark it as ready for   review. After it merges, submit a PR with the same bundle to the   community-operators-prod repository.</li> </ul> </li> </ul> </li> </ul>"},{"location":"developer-guide/release/#patch-branch-release","title":"Patch Branch Release","text":"<p>The patch branch release process is essentially the same as that for the standard release with the following exceptions.</p> <p>Do the following for each repo:</p> <ul> <li>If this is the first patch release for a given release, someone with write   permissions on the repo (e.g., one of the maintainers) must create a branch   from the git tag of the release you want to patch.<ul> <li>If patching vx.y.z, the patch branch should be named release-vx.y.z-patch.</li> </ul> </li> <li>Create a branch for your changes from the upstream branch.</li> <li>Cherry pick the relevant commits.</li> <li>Do other fixups if necessary.</li> </ul> <p>Then, follow the steps from Standard Release from Main Branch section, except open your PRs against the release branch.</p>"},{"location":"developer-guide/release/#release-candidate-release","title":"Release Candidate Release","text":"<p>Often times cutting a release candidate is a great way to test any changes to our release infrastructure before cutting an official release. Make sure release candidate versions contain an <code>rc</code> suffix (e.g., <code>0.4.0-rc1</code>).  This is a lighter-weight process meaning many of the versioned manifests do not necessarily need to be created.</p> <p>As in the other releases, first complete the release for <code>bpfman</code> and then follow that up with a release for <code>bpfman-operator</code>.</p>"},{"location":"developer-guide/release/#bpfman-release_1","title":"bpfman Release","text":"<ul> <li>Create a new branch in your <code>bpfman</code> fork based on the upstream patch branch   named, for example <code>&lt;githubuser&gt;/release-x.y.z-rc1</code>, and use the new branch in   the upcoming steps.</li> <li>Make the following changes<ul> <li>Add a new changelog for the release.  A full set of release notes is not   required.  A single line that says something like \"Pre-release 1 for   v0.5.6\" is sufficient.</li> <li>Update the   Cargo.toml   version for the workspace:<ul> <li><code>version = \"x.y.z-rc1\"</code></li> <li><code>bpfman = { version = \"x.y.z-rc1\", path = \"./bpfman\" }\"</code></li> <li><code>bpfman-api = { version = \"x.y.z-rc1\", path = \"./bpfman-api\" }</code></li> <li>Note: <code>bpfman-csi</code> does not need to be updated.</li> </ul> </li> <li>Run <code>cargo generate-lockfile</code></li> </ul> </li> <li>Commit the changes, push them to your repo, and open a PR against the <code>bpfman</code>   repo.</li> <li>After the PR is reviewed, merged, and all GitHub actions have completed   successfully, tag the release with the version number (e.g., vx.y.z-rc1).<ul> <li>Tag the release using the commit on <code>main</code> where the changelog update   merged.</li> <li>A maintainer or someone with write permission on the repo must create the   tag.</li> <li>This can be done using the <code>git</code> CLI or Github's bpfman release page.</li> </ul> </li> <li>The Release will be automatically created by GitHub actions when the tag is   applied.</li> </ul> <p>After these steps are completed, the following should occur:</p> <ul> <li>All GitHub actions should complete successfully.</li> <li>The release appears on the GitHub Releases Page.</li> <li>Images are built and updated with the new version tag at:<ul> <li>quay.io/bpfman</li> <li>quay.io/bpfman-bytecode</li> <li>quay.io/bpfman-userspace</li> </ul> </li> <li>The new version appears at crates.io</li> <li>A new RPM is built and pushed to the bpfman COPR   repository.</li> </ul>"},{"location":"developer-guide/release/#bpfman-operator-release_1","title":"bpfman-operator Release","text":"<ul> <li>Create a new branch in your <code>bpfman</code> fork based on the upstream patch branch   named, for example <code>&lt;githubuser&gt;/release-x.y.z-rc1</code>, and use the new branch in   the upcoming steps.</li> <li>Make the following changes<ul> <li>Add a new changelog for the release.  A full set of release notes is not   required.  A single line that says something like \"Pre-release 1 for   v0.5.6\" is sufficient.</li> <li>Update the bpfman-operator version in the Makefile:<ul> <li><code>VERSION ?= x.y.z-rc1</code></li> </ul> </li> </ul> </li> <li>Commit the changes, push them to your repo, and open a PR against the   <code>bpfman-operator</code> repo.</li> <li>After the PR is reviewed, merged, and all GitHub actions have completed   successfully, tag the release with the version number (e.g., vx.y.z-rc1).<ul> <li>Tag the release using the commit on <code>main</code> where the changelog update   merged.</li> <li>A maintainer or someone with write permission on the repo must create the   tag.</li> <li>This can be done using the <code>git</code> CLI or Github's bpfman-operator release page.</li> </ul> </li> <li>The Release will be automatically created by GitHub actions when the tag is   applied.</li> </ul> <p>After these steps are completed, the following should occur:</p> <ul> <li>All GitHub actions should complete successfully.</li> <li>The release appears on the GitHub Releases Page.</li> <li>Images are built and updated with the new version tag at:<ul> <li><code>quay.io/bpfman/bpfman-operator</code></li> <li><code>quay.io/bpfman/bpfman-agent</code></li> </ul> </li> </ul>"},{"location":"developer-guide/shipping-bytecode/","title":"eBPF Bytecode Image Specifications","text":""},{"location":"developer-guide/shipping-bytecode/#introduction","title":"Introduction","text":"<p>The eBPF Bytecode Image specification defines how to package eBPF bytecode as container images. The initial primary use case focuses on the containerization and deployment of eBPF programs within container orchestration systems such as Kubernetes, where it is necessary to provide a portable way to distribute bytecode to all nodes which need it.</p>"},{"location":"developer-guide/shipping-bytecode/#specifications","title":"Specifications","text":"<p>We provide two distinct spec variants here to ensure interoperability with existing registries and packages which do not support the new custom media types defined here.</p> <ul> <li>custom-data-type-spec</li> <li>backwards-compatable-spec</li> </ul>"},{"location":"developer-guide/shipping-bytecode/#backwards-compatible-oci-compliant-spec","title":"Backwards compatible OCI compliant spec","text":"<p>This variant makes use of existing OCI conventions to represent eBPF Bytecode as container images.</p>"},{"location":"developer-guide/shipping-bytecode/#image-layers","title":"Image Layers","text":"<p>The container images following this variant must contain exactly one layer who's media type is one of the following:</p> <ul> <li><code>application/vnd.oci.image.layer.v1.tar+gzip</code> or the compliant <code>application/vnd.docker.image.rootfs.diff.tar.gzip</code></li> </ul> <p>Additionally the image layer must contain a valid eBPF object file (generally containing a <code>.o</code> extension) placed at the root of the layer <code>./</code>.</p>"},{"location":"developer-guide/shipping-bytecode/#image-labels","title":"Image Labels","text":"<p>To provide relevant metadata regarding the bytecode to any consumers, some relevant labels MUST be defined on the image.</p> <p>These labels are dynamic and defined as follows:</p> <ul> <li> <p><code>io.ebpf.programs</code>: A label which defines the eBPF programs stored in the bytecode image.    The value of the label is a list which must contain a valid JSON object with    Key's specifying the program name, and values specifying the program type i.e:    \"{ \"pass\" : \"xdp\" , \"counter\" : \"tc\", ...}\".</p> </li> <li> <p><code>io.ebpf.maps</code>: A label which defines the eBPF maps stored in the bytecode image.    The value of the label is a list which must contain a valid JSON object with    Key's specifying the map name, and values specifying the map type i.e:    \"{ \"xdp_stats_map\" : \"per_cpu_array\", ...}\".</p> </li> </ul>"},{"location":"developer-guide/shipping-bytecode/#building-a-backwards-compatible-oci-compliant-image","title":"Building a Backwards compatible OCI compliant image","text":"<p>Bpfman does not provide wrappers around compilers like clang since many eBPF libraries (i.e aya, libbpf, cilium-ebpf) already do so, meaning users are expected to pass in the correct ebpf program bytecode for the appropriate platform. However, bpfman does provide a few image builder commands to make this whole process easier.</p> <p>Example Containerfiles for single-arch and multi-arch can be found at <code>Containerfile.bytecode</code> and <code>Containerfile.bytecode.multi.arch</code>.</p>"},{"location":"developer-guide/shipping-bytecode/#host-platform-architecture-image-build","title":"Host Platform Architecture Image Build","text":"<pre><code>bpfman image build -b ./examples/go-xdp-counter/bpf_x86_bpfel.o -f Containerfile.bytecode --tag quay.io/&lt;USER&gt;/go-xdp-counter\n</code></pre> <p>Where <code>./examples/go-xdp-counter/bpf_x86_bpfel.o</code> is the path to the bytecode object file.</p> <p>Users can also use <code>skopeo</code> to ensure the image follows the backwards compatible version of the spec:</p> <ul> <li><code>skopeo inspect</code> will show the correctly configured labels stored in the   configuration layer (<code>application/vnd.oci.image.config.v1+json</code>) of the image.</li> </ul> <pre><code>skopeo inspect docker://quay.io/bpfman-bytecode/go-xdp-counter\n{\n    \"Name\": \"quay.io/bpfman-bytecode/go-xdp-counter\",\n    \"Digest\": \"sha256:e8377e94c56272937689af88a1a6231d4d594f83218b5cda839eaeeea70a30d3\",\n    \"RepoTags\": [\n        \"latest\"\n    ],\n    \"Created\": \"2024-05-30T09:17:15.327378016-04:00\",\n    \"DockerVersion\": \"\",\n    \"Labels\": {\n        \"io.ebpf.maps\": \"{\\\"xdp_stats_map\\\":\\\"per_cpu_array\\\"}\",\n        \"io.ebpf.programs\": \"{\\\"xdp_stats\\\":\\\"xdp\\\"}\"\n    },\n    \"Architecture\": \"amd64\",\n    \"Os\": \"linux\",\n    \"Layers\": [\n        \"sha256:c0d921d3f0d077da7cdfba8c0240fb513789e7698cdf326f80f30f388c084cff\"\n    ],\n    \"LayersData\": [\n        {\n            \"MIMEType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\",\n            \"Digest\": \"sha256:c0d921d3f0d077da7cdfba8c0240fb513789e7698cdf326f80f30f388c084cff\",\n            \"Size\": 2656,\n            \"Annotations\": null\n        }\n    ],\n    \"Env\": [\n        \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\"\n    ]\n}\n</code></pre>"},{"location":"developer-guide/shipping-bytecode/#multi-architecture-image-build","title":"Multi-Architecture Image build","text":"<pre><code>bpfman image build -t quay.io/bpfman-bytecode/go-xdp-counter-multi --container-file ./Containerfile.bytecode.multi.arch --bc-amd64-el ./examples/go-xdp-counter/bpf_arm64_bpfel.o --bc-s390x-eb ./examples/go-xdp-counter/bpf_s390_bpfeb.o\n</code></pre> <p>To better understand the available architectures users can use <code>podman manifest-inspect</code></p> <pre><code>podman manifest inspect quay.io/bpfman-bytecode/go-xdp-counter:test-manual-build\n{\n    \"schemaVersion\": 2,\n    \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\",\n    \"manifests\": [\n        {\n            \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\n            \"size\": 478,\n            \"digest\": \"sha256:aed62d2e5867663fac66822422512a722003b40453325fd873bbb5840d78cba9\",\n            \"platform\": {\n                \"architecture\": \"amd64\",\n                \"os\": \"linux\"\n            }\n        },\n        {\n            \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\n            \"size\": 478,\n            \"digest\": \"sha256:a348fe2f26dc0851518d8d82e1049d2c39cc2e4f37419fe9231c1967abc4828c\",\n            \"platform\": {\n                \"architecture\": \"arm64\",\n                \"os\": \"linux\"\n            }\n        },\n        {\n            \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\n            \"size\": 478,\n            \"digest\": \"sha256:d5c5d41d2d21e0cb5fb79fe9f343e540942c9a1657cf0de96b8f63e43d369743\",\n            \"platform\": {\n                \"architecture\": \"ppc64le\",\n                \"os\": \"linux\"\n            }\n        },\n        {\n            \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\",\n            \"size\": 478,\n            \"digest\": \"sha256:7915c83838d73268690381b313fb84b5509912aa351c98c78204584cced50efd\",\n            \"platform\": {\n                \"architecture\": \"s390x\",\n                \"os\": \"linux\"\n            }\n        },\n    ]\n}\n</code></pre>"},{"location":"developer-guide/shipping-bytecode/#custom-oci-compatible-spec","title":"Custom OCI compatible spec","text":"<p>This variant of the eBPF bytecode image spec uses custom OCI medium types to represent eBPF bytecode as container images. Many toolchains and registries may not support this yet.</p> <p>TODO https://github.com/bpfman/bpfman/issues/1162</p>"},{"location":"developer-guide/testing/","title":"Testing","text":"<p>This document describes the automated testing that is done for each pull request submitted to bpfman, and also provides instructions for running them locally when doing development.</p>"},{"location":"developer-guide/testing/#unit-testing","title":"Unit Testing","text":"<p>Unit testing is executed as part of the <code>build</code> job by running the following command in the top-level bpfman directory.</p> <pre><code>cd bpfman/\ncargo test\n</code></pre>"},{"location":"developer-guide/testing/#go-example-tests","title":"Go Example Tests","text":"<p>Tests are run for each of the example programs found in directory <code>examples</code></p> <p>Detailed description TBD</p>"},{"location":"developer-guide/testing/#basic-integration-tests","title":"Basic Integration Tests","text":"<p>The full set of basic integration tests are executed by running the following command in the top-level bpfman directory.</p> <pre><code>cd bpfman/\ncargo xtask integration-test\n</code></pre> <p>Optionally, a subset of the integration tests can be run by adding the \"--\" and a test filter string.  For example, to run only the tests that load and unload XDP programs, run the following command:</p> <pre><code>cargo xtask integration-test -- test_load_unload_xdp test_proceed_on_xdp\n</code></pre> <p>Test filter strings are documented here</p> <p>The integration tests start a <code>bpfman</code> daemon process, and issue CLI commands to verify a range of functionality.  For XDP and TC programs that are installed on network interfaces, the integration test code creates a test network namespace connected to the host by a veth pair on which the programs are attached. The test code uses the IP subnet 172.37.37.1/24 for the namespace. If that address conflicts with an existing network on the host, it can be changed by setting the <code>BPFMAN_IP_PREFIX</code> environment variable to one that is available as shown below.</p> <pre><code>export BPFMAN_IP_PREFIX=\"192.168.50\"\n</code></pre> <p>There are two categories of integration tests: basic and e2e.  The basic tests verify basic CLI functionality such as loading, listing, and unloading programs.  The e2e tests verify more advanced functionality such as the setting of global variables, priority, and proceed-on by installing the programs, creating traffic if needed, and examining logs to confirm that things are running as expected.</p> <p>Most eBPF test programs are loaded from container images stored on quay.io. The source code for the eBPF test programs can be found in the <code>tests/integration-test/bpf</code> directory.  These programs are compiled by executing <code>cargo xtask build-ebpf --libbpf-dir &lt;libbpf dir&gt;</code></p> <p>We also load some tests from local files to test the <code>bpfman load file</code> option.</p>"},{"location":"developer-guide/testing/#kubernetes-operator-tests","title":"Kubernetes Operator Tests","text":""},{"location":"developer-guide/testing/#kubernetes-operator-unit-tests","title":"Kubernetes Operator Unit Tests","text":"<p>To run all of the unit tests defined in the bpfman-operator controller code run <code>make test</code> in the bpfman-operator directory.</p> <pre><code>cd bpfman-operator/\nmake test\n</code></pre>"},{"location":"developer-guide/testing/#kubernetes-operator-integration-tests","title":"Kubernetes Operator Integration Tests","text":"<p>To run the Kubernetes Operator integration tests locally:</p> <ol> <li> <p>Build the example test code userspace images locally.</p> <pre><code>cd bpfman/examples/\nmake build-us-images\n</code></pre> </li> <li> <p>(optional) build the bytecode images</p> <p>In order to rebuild all of the bytecode images for a PR, ask a maintainer to do so, they will be built and generate by github actions with the tag <code>quay.io/bpfman-bytecode/&lt;example&gt;:&lt;branch-name&gt;</code></p> </li> <li> <p>Build the bpfman images locally with a unique tag, for example: <code>int-test</code></p> <pre><code>cd bpfman-operator/\nBPFMAN_AGENT_IMG=quay.io/bpfman/bpfman-agent:int-test BPFMAN_OPERATOR_IMG=quay.io/bpfman/bpfman-operator:int-test make build-images\n</code></pre> </li> <li> <p>Run the integration test suite with the images from the previous step:</p> <pre><code>cd bpfman-operator/\nBPFMAN_AGENT_IMG=quay.io/bpfman/bpfman-agent:int-test BPFMAN_OPERATOR_IMG=quay.io/bpfman/bpfman-operator:int-test make test-integration\n</code></pre> <p>If an update <code>bpfman</code> image is required, build it separately and pass to <code>make test-integration</code> using <code>BPFMAN_IMG</code>. See Locally Build bpfman Container Image.</p> <p>Additionally the integration test can be configured with the following environment variables:</p> <ul> <li>KEEP_TEST_CLUSTER: If set to <code>true</code> the test cluster will not be torn down   after the integration test suite completes.</li> <li>USE_EXISTING_KIND_CLUSTER: If this is set to the name of the existing kind   cluster the integration test suite will use that cluster instead of creating a   new one.</li> </ul> </li> </ol>"},{"location":"developer-guide/xdp-overview/","title":"XDP Tutorial","text":"<p>The XDP hook point is unique in that the associated eBPF program attaches to an interface and only one eBPF program is allowed to attach to the XDP hook point for a given interface. Due to this limitation, the libxdp protocol was written. The one program that is attached to the XDP hook point is an eBPF dispatcher program. The dispatcher program contains a list of 10 stub functions. When XDP programs wish to be loaded, they are loaded as extension programs which are then called in place of one of the stub functions.</p> <p>bpfman is leveraging the libxdp protocol and dispatcher program to allow it's users to load up to 10 XDP programs on a given interface. This tutorial will show you how to use <code>bpfman</code> to load multiple XDP programs on an interface.</p> <p>Note</p> <p>The TC hook point is also associated with an interface. Within bpfman, TC is implemented in a similar fashion to XDP in that it uses a dispatcher with stub functions. TCX is a fairly new kernel feature that improves how the kernel handles multiple TC programs on a given interface and does not use the dispatcher program.</p> <p>See Launching bpfman for more detailed instructions on building and loading bpfman. This tutorial assumes bpfman has been built and the <code>bpfman</code> CLI is in $PATH.</p>"},{"location":"developer-guide/xdp-overview/#load-xdp-program","title":"Load XDP program","text":"<p>We will load and attach the simple <code>xdp-pass</code> program, which permits all traffic to the attached interface, <code>eno3</code> in this example. We will use the priority of 100. Find a deeper dive into CLI syntax in CLI Guide.</p> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/xdp_pass:latest --application XdpPassProgram \\\n     --programs xdp:pass\n Bpfman State\n---------------\n Name:          pass\n Image URL:     quay.io/bpfman-bytecode/xdp_pass:latest\n Pull Policy:   IfNotPresent\n Global:        None\n Metadata:      bpfman_application=XdpPassProgram\n Map Pin Path:  /run/bpfman/fs/maps/63336\n Map Owner ID:  None\n Maps Used By:  63336\n Links:         None\n\n Kernel State\n----------------------------------\n Program ID:                       63336\n Name:                             pass\n Type:                             xdp\n Loaded At:                        2025-03-31T17:49:22-0400\n Tag:                              4b9d1b2c140e87ce\n GPL Compatible:                   true\n Map IDs:                          [21009]\n BTF ID:                           31179\n Size Translated (bytes):          96\n JITted:                           true\n Size JITted:                      75\n Kernel Allocated Memory (bytes):  4096\n Verified Instruction Count:       9\n</code></pre> <p>Using the <code>Program ID</code> from the output from the <code>bpfman load</code> command, the eBPF Program can then be attached to the interface.</p> <pre><code>sudo bpfman attach 63336 xdp --iface eno3 --priority 100\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63336\n Link ID:            3736854134\n Interface:          eno3\n Priority:           100\n Position:           0\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <p><code>bpfman load image</code> returns the same data as a <code>bpfman get program</code> command and the <code>bpfman attach</code> returns the same data as a <code>bpfman get link</code> command. From the output, the <code>Program ID</code> of <code>63336</code> can be found in the <code>Kernel State</code> section. This id can be used to perform a <code>bpfman get program</code> to retrieve all relevant program data and a <code>bpfman unload</code> when the program needs to be unloaded.</p> <pre><code>sudo bpfman list programs\n Program ID  Application     Type  Function Name  Links\n 63336       XdpPassProgram  xdp   pass           (1) 3736854134\n</code></pre> <p>We can recheck the details about the loaded program with the <code>bpfman get program</code> command:</p> <pre><code>sudo bpfman get program 63336\n Bpfman State\n---------------\n Name:          pass\n Image URL:     quay.io/bpfman-bytecode/xdp_pass:latest\n Pull Policy:   IfNotPresent\n Global:        None\n Metadata:      bpfman_application=XdpPassProgram\n Map Pin Path:  /run/bpfman/fs/maps/63336\n Map Owner ID:  None\n Maps Used By:  63336\n Links:         3736854134 (eno3 pos-0)\n\n Kernel State\n----------------------------------\n Program ID:                       63336\n Name:                             pass\n Type:                             xdp\n Loaded At:                        2025-03-31T17:49:22-0400\n Tag:                              4b9d1b2c140e87ce\n GPL Compatible:                   true\n Map IDs:                          [21009]\n BTF ID:                           31179\n Size Translated (bytes):          96\n JITted:                           true\n Size JITted:                      75\n Kernel Allocated Memory (bytes):  4096\n Verified Instruction Count:       9\n</code></pre> <p>We can also recheck the details about the attached program with the <code>bpfman get link</code> command:</p> <pre><code>sudo bpfman get link 3736854134\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63336\n Link ID:            3736854134\n Interface:          eno3\n Priority:           100\n Position:           0\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <p>From the link output above you can see the program was loaded to position 0 on our interface and thus will be executed first.</p>"},{"location":"developer-guide/xdp-overview/#loading-additional-xdp-programs","title":"Loading Additional XDP Programs","text":"<p>We will now attach 2 more programs with different priorities to demonstrate how bpfman will ensure they are ordered correctly:</p> <pre><code>sudo bpfman attach 63336 xdp --iface eno3 --priority 50\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63336\n Link ID:            155072461\n Interface:          eno3\n Priority:           50\n Position:           0\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <pre><code>sudo bpfman attach 63336 xdp --iface eno3 --priority 200\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63336\n Link ID:            454777406\n Interface:          eno3\n Priority:           200\n Position:           2\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <p>Using <code>bpfman list links</code> we can see all the programs that were attached.</p> <pre><code>sudo bpfman list links --application XdpPassProgram\n Program ID  Link ID     Application     Type  Function Name  Attachment\n 63336       155072461   XdpPassProgram  xdp   pass           eno3 pos-0\n 63336       3736854134  XdpPassProgram  xdp   pass           eno3 pos-1\n 63336       454777406   XdpPassProgram  xdp   pass           eno3 pos-2\n</code></pre> <p>The lowest priority program is executed first, while the highest is executed last. As can be seen from the detailed output for each command below:</p> <ul> <li>Link <code>155072461</code> is at position <code>0</code> with a priority of <code>50</code></li> <li>Link <code>3736854134</code> is at position <code>1</code> with a priority of <code>100</code></li> <li>Link <code>454777406</code> is at position <code>2</code> with a priority of <code>200</code></li> </ul> <pre><code>sudo bpfman get link 3736854134\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63336\n Link ID:            3736854134\n Interface:          eno3\n Priority:           100\n Position:           1\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <pre><code>sudo bpfman get link 155072461\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63336\n Link ID:            155072461\n Interface:          eno3\n Priority:           50\n Position:           0\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <pre><code>sudo bpfman get link 454777406\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63336\n Link ID:            454777406\n Interface:          eno3\n Priority:           200\n Position:           2\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <p>By default, the next program in the chain will only be executed if a given program returns <code>pass</code> (see <code>proceed-on</code> field in the <code>bpfman get link</code> output above). If the next program in the chain should be called even if a different value is returned, then the program can be loaded with those additional return values using the <code>proceed-on</code> parameter (see <code>bpfman load attach xdp --help</code> for list of valid values):</p> <pre><code>sudo bpfman attach 63336 xdp --iface eno3 --priority 150 \\\n   --proceed-on pass --proceed-on dispatcher_return --proceed-on drop\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63336\n Link ID:            702908334\n Interface:          eno3\n Priority:           150\n Position:           2\n Proceed On:         pass, dispatcher_return, drop\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <p>Which results in being loaded in position <code>2</code> because it was loaded at priority <code>150</code>, which is lower than the previous program at that position with a priority of <code>200</code>.</p>"},{"location":"developer-guide/xdp-overview/#delete-xdp-program","title":"Delete XDP Program","text":"<p>Let's detach the program at position 1.</p> <pre><code>sudo bpfman list links --application XdpPassProgram\n Program ID  Link ID     Application     Type  Function Name  Attachment \n 63336       155072461   XdpPassProgram  xdp   pass           eno3 pos-0\n 63336       3736854134  XdpPassProgram  xdp   pass           eno3 pos-1\n 63336       454777406   XdpPassProgram  xdp   pass           eno3 pos-3\n 63336       702908334   XdpPassProgram  xdp   pass           eno3 pos-2\n</code></pre> <pre><code>sudo bpfman detach 3736854134\n</code></pre> <p>And we can verify that it has been removed and the other programs re-ordered:</p> <pre><code>sudo bpfman list links --application XdpPassProgram\n Program ID  Link ID    Application     Type  Function Name  Attachment\n 63336       155072461  XdpPassProgram  xdp   pass           eno3 pos-0\n 63336       454777406  XdpPassProgram  xdp   pass           eno3 pos-2\n 63336       702908334  XdpPassProgram  xdp   pass           eno3 pos-1\n</code></pre>"},{"location":"getting-started/building-bpfman/","title":"Setup and Building bpfman","text":"<p>This section describes how to build bpfman. If this is the first time building bpfman, the Development Environment Setup section describes all packages needed to build bpfman.</p> <p>There is also an option to run prebuilt images from a given release or from an RPM, as opposed to building locally. Jump to:</p> <ul> <li>Run bpfman From Release Image for installing from a prebuilt fixed release.</li> <li>Run bpfman From RPM for installing from a prebuilt RPM.</li> </ul>"},{"location":"getting-started/building-bpfman/#kernel-versions","title":"Kernel Versions","text":"<p>eBPF is still a relatively new technology that is being actively developed. To take advantage of this constantly evolving technology, it is best to use the newest kernel version possible. If bpfman needs to be run on an older kernel, this section describes some of the kernel features bpfman relies on to work and which kernel the feature was first introduced.</p> <p>Major kernel features leveraged by bpfman:</p> <ul> <li>Program Extensions: Program Extensions allows bpfman to load multiple XDP or TC eBPF programs   on an interface, which is not natively supported in the kernel.   A <code>dispatcher</code> program is loaded as the one program on a given interface, and the user's XDP or TC   programs are loaded as extensions to the <code>dispatcher</code> program.   Introduced in Kernel 5.6.</li> <li>Pinning: Pinning allows the eBPF program to remain loaded when the loading process (bpfman) is   stopped or restarted.   Introduced in Kernel 4.11.</li> <li>BPF Perf Link: Support BPF perf link for tracing programs (Tracepoint, Uprobe and Kprobe)   which enables pinning for these program types.   Introduced in Kernel 5.15.</li> <li>Relaxed CAP_BPF Requirement: Prior to Kernel 5.19, all eBPF system calls required CAP_BPF.   This required userspace programs that wanted to access eBPF maps to have the CAP_BPF Linux capability.   With the kernel 5.19 change, CAP_BPF is only required for load and unload requests.</li> <li>TCX: TCX has performance improvements over TC and adds support in the kernel for multiple TCX   programs to run on a given TC hook point. TCX support was added in Kernel 6.6.</li> </ul> <p>bpfman tested on older kernel versions:</p> <ul> <li>Fedora 34: Kernel 5.17.6-100.fc34.x86_64<ul> <li>XDP, TC, Tracepoint, Uprobe and Kprobe programs all loaded with bpfman running on localhost   and running as systemd service.</li> </ul> </li> <li>Fedora 33: Kernel 5.14.18-100.fc33.x86_64<ul> <li>XDP and TC programs loaded with bpfman running on localhost and running as systemd service   once SELinux was disabled (see https://github.com/fedora-selinux/selinux-policy/pull/806).</li> <li>Tracepoint, Uprobe and Kprobe programs failed to load because they require the <code>BPF Perf Link</code>   support.</li> </ul> </li> <li>Fedora 32: Kernel 5.11.22-100.fc32.x86_64<ul> <li>XDP and TC programs loaded with bpfman running on localhost once SELinux was disabled   (see https://github.com/fedora-selinux/selinux-policy/pull/806).</li> <li>bpfman fails to run as a systemd service because of some capabilities issues in the   bpfman.service file.</li> <li>Tracepoint, Uprobe and Kprobe programs failed to load because they require the <code>BPF Perf Link</code>   support.</li> </ul> </li> <li>Fedora 31: Kernel 5.8.18-100.fc31.x86_64<ul> <li>bpfman was able to start on localhost, but XDP and TC programs wouldn't load because   <code>BPF_LINK_CREATE</code> call was updated in newer kernels.</li> <li>bpfman fails to run as a systemd service because of some capabilities issues in the   bpfman.service file.</li> </ul> </li> </ul>"},{"location":"getting-started/building-bpfman/#development-environment-setup","title":"Development Environment Setup","text":"<p>To build bpfman, the following packages must be installed.</p>"},{"location":"getting-started/building-bpfman/#install-rust-toolchain","title":"Install Rust Toolchain","text":"<p>For further detailed instructions, see Rust Stable &amp; Rust Nightly.</p> <pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource \"$HOME/.cargo/env\"\nrustup toolchain install nightly -c rustfmt,clippy,rust-src\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-llvm","title":"Install LLVM","text":"<p>LLVM 11 or later must be installed. Linux package managers should provide a recent enough release.</p> <p><code>dnf</code> based OS:</p> <pre><code>sudo dnf install llvm-devel clang-devel elfutils-libelf-devel\n</code></pre> <p><code>apt</code> based OS:</p> <pre><code>sudo apt install clang lldb lld libelf-dev gcc-multilib\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-ssl-library","title":"Install SSL Library","text":"<p><code>dnf</code> based OS:</p> <pre><code>sudo dnf install openssl-devel\n</code></pre> <p><code>apt</code> based OS:</p> <pre><code>sudo apt install libssl-dev\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-bpf-helper-header-files","title":"Install bpf Helper Header Files","text":"<p><code>apt</code> based OS:</p> <pre><code>sudo apt install libbpf-dev\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-protobuf-compiler","title":"Install Protobuf Compiler","text":"<p>If any of the Protobuf files need to be updated, then the protobuf-compiler will need to be installed. See RPC Protobuf Generation for bpfman use of protobufs and see protoc for more detailed installation instructions.</p> <p><code>dnf</code> based OS:</p> <pre><code>sudo dnf install protobuf-compiler\n</code></pre> <p><code>apt</code> based OS:</p> <pre><code>sudo apt install protobuf-compiler\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-go-protobuf-compiler-extensions","title":"Install GO protobuf Compiler Extensions","text":"<p>See Quick Start Guide for gRPC in Go for installation instructions.</p>"},{"location":"getting-started/building-bpfman/#local-libbpf","title":"Local libbpf","text":"<p>Checkout a local copy of libbpf.</p> <pre><code>git clone https://github.com/libbpf/libbpf --branch v0.8.0\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-perl","title":"Install perl","text":"<p>Install <code>perl</code>:</p> <p><code>dnf</code> based OS:</p> <pre><code>sudo dnf install perl\n</code></pre> <p><code>apt</code> based OS:</p> <pre><code>sudo apt install perl\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-docker-or-podman","title":"Install docker or podman","text":"<p>To build the <code>bpfman-agent</code> and <code>bpfman-operator</code> using the provided Makefile and the <code>make build-images</code> command, <code>docker</code> or <code>podman</code> needs to be installed. There are several existing guides:</p> <ul> <li>Fedora: https://developer.fedoraproject.org/tools/docker/docker-installation.html</li> <li>Linux: https://docs.docker.com/engine/install/</li> </ul>"},{"location":"getting-started/building-bpfman/#install-kind","title":"Install Kind","text":"<p>Optionally, to test <code>bpfman</code> running in Kubernetes, the easiest method and the one documented throughout the <code>bpfman</code> documentation is to run a Kubernetes Kind cluster. See kind for documentation and installation instructions. <code>kind</code> also requires <code>docker</code> to be installed.</p> <p>Note</p> <p>By default, bpfman-operator deploys bpfman with CSI enabled. CSI requires Kubernetes v1.26 due to a PR (kubernetes/kubernetes#112597) that addresses a gRPC Protocol Error that was seen in the CSI client code and it doesn't appear to have been backported. kind v0.20.0 or later is recommended.</p> <p>If the following error is seen, it means there is an older version of Kubernetes running and it needs to be upgraded.</p> <pre><code>kubectl get pods -A\nNAMESPACE   NAME                               READY   STATUS             RESTARTS      AGE\nbpfman      bpfman-daemon-2hnhx                2/3     CrashLoopBackOff   4 (38s ago)   2m20s\nbpfman      bpfman-operator-6b6cf97857-jbvv4   2/2     Running            0             2m22s\n:\n\nkubectl logs -n bpfman bpfman-daemon-2hnhx -c node-driver-registrar\n:\nE0202 15:33:12.342704       1 main.go:101] Received NotifyRegistrationStatus call: &amp;RegistrationStatus{PluginRegistered:false,Error:RegisterPlugin error -- plugin registration failed with err: rpc error: code = Internal desc = stream terminated by RST_STREAM with error code: PROTOCOL_ERROR,}\nE0202 15:33:12.342723       1 main.go:103] Registration process failed with error: RegisterPlugin error -- plugin registration failed with err: rpc error: code = Internal desc = stream terminated by RST_STREAM with error code: PROTOCOL_ERROR, restarting registration container.\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-bash-completion","title":"Install bash-completion","text":"<p><code>bpfman</code> uses the Rust crate <code>clap</code> for the CLI implementation. <code>clap</code> has an optional Rust crate <code>clap_complete</code>. For <code>bash</code> shell, it leverages <code>bash-completion</code> for CLI Command  completion. So in order for CLI  completion to work in a <code>bash</code> shell, <code>bash-completion</code> must be installed. This feature is optional. <p>For the CLI  completion to work after installation, <code>/etc/profile.d/bash_completion.sh</code> must be sourced in the running sessions. New login sessions should pick it up automatically. <p><code>dnf</code> based OS:</p> <pre><code>sudo dnf install bash-completion\nsource /etc/profile.d/bash_completion.sh\n</code></pre> <p><code>apt</code> based OS:</p> <pre><code>sudo apt install bash-completion\nsource /etc/profile.d/bash_completion.sh\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-yaml-formatter","title":"Install Yaml Formatter","text":"<p>As part of CI, the Yaml files are validated with a Yaml formatter. Optionally, to verify locally, install the YAML Language Support by Red Hat VsCode Extension, or to format in bulk, install <code>prettier</code>.</p> <p>To install <code>prettier</code>:</p> <pre><code>npm install -g prettier\n</code></pre> <p>Then to flag which files are violating the formatting guide, run:</p> <pre><code>prettier -l \"*.yaml\"\n</code></pre> <p>And to write changes in place, run:</p> <pre><code> prettier -f \"*.yaml\"\n</code></pre>"},{"location":"getting-started/building-bpfman/#install-toml-formatter","title":"Install toml Formatter","text":"<p>As part of CI, the toml files are validated with a toml formatter. Optionally, to verify locally, install <code>taplo</code>.</p> <pre><code>cargo install taplo-cli\n</code></pre> <p>And to verify locally:</p> <pre><code>taplo fmt --check\n</code></pre>"},{"location":"getting-started/building-bpfman/#clone-the-bpfman-and-bpfman-operator-repositories","title":"Clone the bpfman and bpfman-operator Repositories","text":"<p>You can build and run bpfman from anywhere. For simplicity throughout this documentation, all examples will reference <code>bpfman/</code> and <code>bpfman-operator/</code> to indicate which repository is being used. bpfman-operator only needs to be cloned if deploying in Kubernetes.</p> <pre><code>cd $SRC_DIR\ngit clone https://github.com/bpfman/bpfman.git\ngit clone https://github.com/bpfman/bpfman-operator.git\n</code></pre>"},{"location":"getting-started/building-bpfman/#building-bpfman","title":"Building bpfman","text":"<p>If you are building bpfman for the first time OR the eBPF code has changed:</p> <pre><code>cd bpfman/\ncargo xtask build-ebpf --libbpf-dir /path/to/libbpf\n</code></pre> <p>If protobuf files have changed (see RPC Protobuf Generation):</p> <pre><code>cargo xtask build-proto\n</code></pre> <p>To build bpfman:</p> <pre><code>cargo build\n</code></pre>"},{"location":"getting-started/building-bpfman/#building-cli-tab-completion-files","title":"Building CLI TAB completion files","text":"<p>Optionally, to build the CLI TAB completion files, run the following command:</p> <pre><code>cd bpfman/\ncargo xtask build-completion\n</code></pre> <p>Files are generated for different shells:</p> <pre><code>ls .output/completions/\n_bpfman  bpfman.bash  bpfman.elv  bpfman.fish  _bpfman.ps1\n</code></pre>"},{"location":"getting-started/building-bpfman/#bash","title":"bash","text":"<p>For <code>bash</code>, this generates a file that can be used by the linux <code>bash-completion</code> utility (see Install bash-completion for installation instructions).</p> <p>If the files are generated, they are installed automatically when using the install script (i.e. <code>sudo ./scripts/setup.sh install</code> - See Run as a systemd Service). To install the files manually, copy the file associated with a given shell to <code>/usr/share/bash-completion/completions/</code>. For example:</p> <pre><code>sudo cp .output/completions/bpfman.bash /usr/share/bash-completion/completions/.\n\nbpfman g&lt;TAB&gt;\n</code></pre>"},{"location":"getting-started/building-bpfman/#other-shells","title":"Other shells","text":"<p>Files are generated other shells (Elvish, Fish, PowerShell and zsh). For these shells, generated file must be manually installed.</p>"},{"location":"getting-started/building-bpfman/#building-cli-manpages","title":"Building CLI Manpages","text":"<p>Optionally, to build the CLI Manpage files, run the following command:</p> <pre><code>cd bpfman/\ncargo xtask build-man-page\n</code></pre> <p>If the files are generated, they are installed automatically when using the install script (i.e. <code>sudo ./scripts/setup.sh install</code> - See Run as a systemd Service). To install the files manually, copy the generated files to <code>/usr/local/share/man/man1/</code>. For example:</p> <pre><code>sudo cp .output/manpage/bpfman*.1 /usr/local/share/man/man1/.\n</code></pre> <p>Once installed, use <code>man</code> to view the pages.</p> <pre><code>man bpfman attach\n</code></pre> <p>Note</p> <p><code>bpfman</code> commands with subcommands (specifically <code>bpfman load</code>, <code>bpfman list</code> and <code>bpfman get</code>) have <code>-</code> in the manpage subcommand generation. So use <code>man bpfman load-file</code>, <code>man bpfman load-image</code>, <code>man bpfman load-image-xdp</code>, <code>man bpfman list-programs</code>, etc. to display the subcommand manpage files.</p>"},{"location":"getting-started/building-bpfman/#building-bpfman-operator","title":"Building bpfman-operator","text":"<p>Building and deploying bpfman-operator is covered in it's own section. See Deploying Example eBPF Programs On Kubernetes and Developing the bpfman-operator.</p>"},{"location":"getting-started/cli-guide/","title":"CLI Guide","text":"<p><code>bpfman</code> offers several CLI commands to manage eBPF programs. The CLI allows you to <code>load</code>, <code>attach</code>, <code>detach</code>, <code>unload</code>, <code>get</code> and <code>list</code> eBPF programs.</p>"},{"location":"getting-started/cli-guide/#notes-for-this-guide","title":"Notes For This Guide","text":"<p>As described in other sections, <code>bpfman</code> can be run as either a privileged process or a systemd service. If run as a privileged process, <code>bpfman</code> will most likely be run from your local development branch and will require <code>sudo</code>. Example:</p> <pre><code>sudo ./target/debug/bpfman list programs\n</code></pre> <p>If run as a systemd service, <code>bpfman</code> will most likely be installed in your $PATH, and will also require <code>sudo</code>. Example:</p> <pre><code>sudo bpfman list programs\n</code></pre> <p>The examples here use <code>sudo bpfman</code> in place of <code>sudo ./target/debug/bpfman</code> for readability, use as your system is deployed.</p> <p>eBPF object files used in the examples are taken from the examples and integration-test directories from the <code>bpfman</code> repository.</p>"},{"location":"getting-started/cli-guide/#basic-syntax","title":"Basic Syntax","text":"<p>Below are the commands supported by <code>bpfman</code>.</p> <pre><code>sudo bpfman --help\nAn eBPF manager focusing on simplifying the deployment and administration of eBPF programs.\n\nUsage: bpfman &lt;COMMAND&gt;\n\nCommands:\n  load    Load an eBPF program on the system\n  unload  Unload an eBPF program using the Program Id\n  attach  Attach an eBPF program to a hook point using the Program Id\n  detach  Detach an eBPF program from a hook point using the Link Id\n  list    List all loaded eBPF programs or attached links\n  get     Get a loaded eBPF program or program attachment link\n  image   eBPF Bytecode Image related commands\n  help    Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help\n          Print help (see a summary with '-h')\n</code></pre> <p>The general flow for using the CLI is as follows:</p> <ul> <li>Load Program: The first step is to load the eBPF Program (or Programs) using the   <code>bpfman load</code> command.   The programs can be from a locally built eBPF program (.o file) or an eBPF program   packaged in a OCI container image from a given registry.   Once the command completes successfully, the eBPF programs are loaded in kernel memory,   but have not been attached to any hook points yet.</li> <li>Attach Program: The next step is to attach a loaded eBPF Program to a hook point   using the <code>bpfman attach</code> command.   Each program type (kprobe, tc, tracepoint, xdp, etc) has unique hook points and unique   configuration data which is provided with the attach command.   Once attached, the eBPF Program will be called if it's hook point is triggered.</li> <li>Display Programs: At any time, the set of programs loaded and attach can be displayed.   To get a list of all the programs, use the <code>bpfman list programs</code> command.   If a program shows up in the list then the program has been loaded.   One of the attributes in the output is  the <code>Links</code> parameter.   If there is a values in the <code>Links</code> parameter, then the program has also been attached.   To retrieve all the parameters of a given program, use the <code>bpfman get program</code> command, which   displays a given program based its <code>Program ID</code>, which can be found in the list output.   To get a list of all the links, use the <code>bpfman list links</code> command.   To retrieve all the parameters of a given link, use the <code>bpfman get link</code> command, which   displays a given link based its <code>Link ID</code>, which can be found in the list output.</li> <li>Detach Program: Optionally, an eBPF Program can be detached from a hook point if desired   using the <code>bpfman detach</code> command.</li> <li>Unload Program: Once an eBPF Program is no longer needed, the program can be unloaded   using the <code>bpfman unload</code> command.   The program does not need to be detached before being unloaded.</li> </ul>"},{"location":"getting-started/cli-guide/#bpfman-load","title":"bpfman load","text":"<p>The <code>bpfman load file</code> and <code>bpfman load image</code> commands are used to load eBPF programs. If the command is successful, the eBPF programs are loaded in kernel memory, but have not been attached to any hook points yet (see bpfman attach). If the bytecode file contains multiple eBPF programs, they should be loaded in a single command by passing multiple &lt;TYPE&gt;:&lt;NAME&gt; pairs to the <code>--programs</code> parameters. They need to be loaded in one command so each those eBPF programs can share any global data and maps between the eBPF programs.</p> <p>The <code>bpfman load file</code> command is used to load a locally built eBPF program. The <code>bpfman load image</code> command is used to load an eBPF program packaged in a OCI container image from a given registry.</p> <pre><code>sudo bpfman load file --help\nLoad an eBPF program from a local .o file\n\nUsage: bpfman load file [OPTIONS] --programs &lt;PROGRAMS&gt;... --path &lt;PATH&gt;\n\nOptions:\n      --programs &lt;PROGRAMS&gt;...\n          Required: The program type and eBPF function name that is the entry point\n          for the eBPF program.\n          Format &lt;TYPE&gt;:&lt;FUNC_NAME&gt;\n\n          For fentry and fexit, the function that is being attached to is also\n          required at load time, so the format for fentry and fexit includes attach\n          function.\n          Format &lt;TYPE&gt;:&lt;FUNC_NAME&gt;:&lt;ATTACH_FUNC&gt;\n\n          If the bytecode file contains multiple eBPF programs that need to be\n          loaded, multiple eBPF programs can be entered by separating each\n          &lt;TYPE&gt;:&lt;FUNC_NAME&gt; pair with a space.\n          Example: --programs xdp:xdp_stats kprobe:kprobe_counter\n          Example: --programs fentry:test_fentry:do_unlinkat\n\n          [possible values for &lt;TYPE&gt;: fentry, fexit, kprobe, tc, tcx, tracepoint,\n                                       uprobe, xdp]\n\n  -p, --path &lt;PATH&gt;\n          Required: Location of local bytecode file\n          Example: --path /run/bpfman/examples/go-xdp-counter/bpf_x86_bpfel.o\n\n  -g, --global &lt;GLOBAL&gt;...\n          Optional: Global variables to be set when program is loaded.\n          Format: &lt;NAME&gt;=&lt;Hex Value&gt;\n\n          This is a very low level primitive. The caller is responsible for formatting\n          the byte string appropriately considering such things as size, endianness,\n          alignment and packing of data structures. Multiple values can be enter by\n          separating each &lt;NAME&gt;=&lt;Hex Value&gt; pair with a space.\n          Example: -g GLOBAL_u8=01 GLOBAL_u32=0A0B0C0D\n\n  -a, --application &lt;APPLICATION&gt;\n          Optional: Application is used to group multiple programs that are loaded together\n          under the same load command. This actually creates a special &lt;KEY&gt;=&lt;VALUE&gt; in the\n          metadata parameter. It can be used to filer on list commands.\n          Example: --application TestEbpfApp\n\n  -m, --metadata &lt;METADATA&gt;\n          Optional: Specify Key/Value metadata to be attached to a program when it\n          is loaded by bpfman.\n          Format: &lt;KEY&gt;=&lt;VALUE&gt;\n\n          This can later be used to `list` a certain subset of programs which contain\n          the specified metadata.\n          Example: --metadata owner=acme\n\n      --map-owner-id &lt;MAP_OWNER_ID&gt;\n          Optional: Program Id of loaded eBPF program this eBPF program will share a map with.\n          Only used when multiple eBPF programs need to share a map.\n          Example: --map-owner-id 63178\n\n  -h, --help\n          Print help (see a summary with '-h')\n</code></pre> <p>and</p> <pre><code>sudo bpfman load image --help\nLoad an eBPF program packaged in a OCI container image from a given registry\n\nUsage: bpfman load image [OPTIONS] --programs &lt;PROGRAMS&gt;... --image-url &lt;IMAGE_URL&gt;\n\nOptions:\n      --programs &lt;PROGRAMS&gt;...\n          Required: The program type and eBPF function name that is the entry point\n          for the eBPF program.\n          Format &lt;TYPE&gt;:&lt;FUNC_NAME&gt;\n\n          For fentry and fexit, the function that is being attached to is also\n          required at load time, so the format for fentry and fexit includes attach\n          function.\n          Format &lt;TYPE&gt;:&lt;FUNC_NAME&gt;:&lt;ATTACH_FUNC&gt;\n\n          If the bytecode file contains multiple eBPF programs that need to be\n          loaded, multiple eBPF programs can be entered by separating each\n          &lt;TYPE&gt;:&lt;FUNC_NAME&gt; pair with a space.\n          Example: --programs xdp:xdp_stats kprobe:kprobe_counter\n          Example: --programs fentry:test_fentry:do_unlinkat\n\n          [possible values for &lt;TYPE&gt;: fentry, fexit, kprobe, tc, tcx, tracepoint,\n                                       uprobe, xdp]\n\n  -i, --image-url &lt;IMAGE_URL&gt;\n          Required: Container Image URL.\n          Example: --image-url quay.io/bpfman-bytecode/xdp_pass:latest\n\n  -r, --registry-auth &lt;REGISTRY_AUTH&gt;\n          Optional: Registry auth for authenticating with the specified image registry.\n          This should be base64 encoded from the '&lt;username&gt;:&lt;password&gt;' string just like\n          it's stored in the docker/podman host config.\n          Example: --registry_auth \"YnjrcKw63PhDcQodiU9hYxQ2\"\n\n  -p, --pull-policy &lt;PULL_POLICY&gt;\n          Optional: Pull policy for remote images.\n\n          [possible values: Always, IfNotPresent, Never]\n\n          [default: IfNotPresent]\n\n  -g, --global &lt;GLOBAL&gt;...\n          Optional: Global variables to be set when program is loaded.\n          Format: &lt;NAME&gt;=&lt;Hex Value&gt;\n\n          This is a very low level primitive. The caller is responsible for formatting\n          the byte string appropriately considering such things as size, endianness,\n          alignment and packing of data structures. Multiple values can be enter by\n          separating each &lt;NAME&gt;=&lt;Hex Value&gt; pair with a space.\n          Example: -g GLOBAL_u8=01 GLOBAL_u32=0A0B0C0D\n\n  -a, --application &lt;APPLICATION&gt;\n          Optional: Application is used to group multiple programs that are loaded together\n          under the same load command. This actually creates a special &lt;KEY&gt;=&lt;VALUE&gt; in the\n          metadata parameter. It can be used to filer on list commands.\n          Example: --application TestEbpfApp\n\n  -m, --metadata &lt;METADATA&gt;\n          Optional: Specify Key/Value metadata to be attached to a program when it\n          is loaded by bpfman.\n          Format: &lt;KEY&gt;=&lt;VALUE&gt;\n\n          This can later be used to list a certain subset of programs which contain\n          the specified metadata.\n          Example: --metadata owner=acme\n\n      --map-owner-id &lt;MAP_OWNER_ID&gt;\n          Optional: Program Id of loaded eBPF program this eBPF program will share a map with.\n          Only used when multiple eBPF programs need to share a map.\n          Example: --map-owner-id 63178\n\n  -h, --help\n          Print help (see a summary with '-h')\n</code></pre>"},{"location":"getting-started/cli-guide/#example-load-commands","title":"Example Load Commands","text":"<p>Below are some different examples for using the <code>bpfmam load</code> command.</p>"},{"location":"getting-started/cli-guide/#loading-from-local-file","title":"Loading From Local File","text":"<p>The following is an example of the <code>tc</code> command from local file:</p> <pre><code>cd bpfman/\nsudo bpfman load file -p tests/integration-test/bpf/.output/tc_pass.bpf/bpf_x86_bpfel.o \\\n     --programs tc:pass --application TcPassProgram\n</code></pre> <p>For the <code>--programs tc:pass</code> program loaded with the command above, the <code>&lt;FUNC_NAME&gt;</code> would be set as shown in the following snippet, taken from the function name, not <code>SEC()</code>:</p> <pre><code>SEC(\"classifier/pass\")\nint pass(struct __sk_buff *skb) {\n{\n    :\n}\n</code></pre>"},{"location":"getting-started/cli-guide/#loading-from-remote-repository","title":"Loading From Remote Repository","text":"<p>Below is an example loading an eBPF program packaged in a OCI container image from a given registry:</p> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/xdp_pass:latest \\\n     --programs xdp:pass --application XdpPassProgram\n</code></pre>"},{"location":"getting-started/cli-guide/#loading-multiple-programs","title":"Loading Multiple Programs","text":"<p>An eBPF bytecode image can can contain multiple programs. Below is an example of how to load multiple eBPF programs in one load command. Commands that are loaded together can share global data and maps. Optionally, include an <code>application</code> name that can be used to group the load programs together when displaying.</p> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/go-app-counter:latest \\\n   --programs kprobe:kprobe_counter tracepoint:tracepoint_kill_recorder tc:stats \\\n              tcx:tcx_stats uprobe:uprobe_counter xdp:xdp_stats  --application go-app\n</code></pre>"},{"location":"getting-started/cli-guide/#loading-fentryfexit-programs","title":"Loading fentry/fexit Programs","text":"<p>Below is an example loading an fentry program (fexit is similar). The fentry and fexit commands require the attach point at load time, which is the name of the function the eBPF will be attached too. The function name is included in the <code>--programs</code> parameter and uses the format: <code>&lt;TYPE&gt;:&lt;FUNC_NAME&gt;:&lt;ATTACH_FUNC&gt;</code> The fentry and fexit programs still require a <code>bpfman attach</code> command to be called before they will actually be triggered.</p> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/fentry:latest \\\n     --programs fentry:test_fentry:do_unlinkat\n\nsudo bpfman load image --image-url quay.io/bpfman-bytecode/fentry:latest \\\n     --programs fexit:test_fexit:do_unlinkat\n</code></pre>"},{"location":"getting-started/cli-guide/#loading-probe-versus-retprobe-programs","title":"Loading probe Versus retprobe Programs","text":"<p><code>kprobe</code> and <code>kretprobe</code> (as well as <code>uprobe</code> and <code>uretprobe</code>) are loaded and attached with the same set of attributes. From the kernel's perspective, probes and retprobes are both probes. What distinguishes a probe from a retprobe is the <code>SEC(..)</code> header in the code. For example, <code>kprobe</code> will look something like:</p> <pre><code>SEC(\"kprobe/my_kprobe\")\nint my_kprobe(struct pt_regs *ctx) {\n  bpf_printk(\" KP: GLOBAL_u8: 0x%02X, GLOBAL_u32: 0x%08X\", GLOBAL_u8,\n             GLOBAL_u32);\n  return 0;\n}\n</code></pre> <p>Whereas <code>kretprobe</code> may look something like:</p> <pre><code>SEC(\"kretprobe/my_kretprobe\")\nint my_kretprobe(struct pt_regs *ctx) {\n  bpf_printk(\"KRP: GLOBAL_u8: 0x%02X, GLOBAL_u32: 0x%08X\", GLOBAL_u8,\n             GLOBAL_u32);\n  return 0;\n}\n</code></pre> <p>But loading each type of program is similar:</p> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/kprobe:latest \\\n   --programs kprobe:my_kprobe\n</code></pre> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/kretprobe:latest \\\n   --programs kprobe:my_kretprobe\n</code></pre>"},{"location":"getting-started/cli-guide/#setting-global-variables-in-ebpf-programs","title":"Setting Global Variables in eBPF Programs","text":"<p>Global variables can be set for any eBPF program type when loading as follows:</p> <pre><code>cd bpfman/\nsudo bpfman load file -p tests/integration-test/bpf/.output/tc_pass.bpf/bpf_x86_bpfel.o \\\n     --programs tc:pass -g GLOBAL_u8=01 GLOBAL_u32=0A0B0C0D --application TcGlobal\n</code></pre> <p>Note that when setting global variables, the eBPF program being loaded must have global variables named with the strings given, and the size of the value provided must match the size of the given variable.  For example, the above command can be used to update the following global variables in an eBPF program.</p> <pre><code>volatile const __u32 GLOBAL_u8 = 0;\nvolatile const __u32 GLOBAL_u32 = 0;\n</code></pre>"},{"location":"getting-started/cli-guide/#bpfman-attach","title":"bpfman attach","text":"<p>The <code>bpfman attach</code> command is used to attach an eBPF program to a hook point. Each program type (i.e. <code>&lt;COMMAND&gt;</code>) has it's own set of attributes specific to the program type, and those program specific attributes MUST come after the <code>Program ID</code> (from the load command) and the program type are entered.</p> <pre><code>sudo bpfman attach --help\nAttach an eBPF program to a hook point using the Program Id\n\nUsage: bpfman attach &lt;PROGRAM_ID&gt; &lt;COMMAND&gt;\n\nCommands:\n  xdp         Install an eBPF program on the XDP hook point for a given interface\n  tc          Install an eBPF program on the TC hook point for a given interface\n  tcx         Install an eBPF program on the TCX hook point for a given interface and direction\n  tracepoint  Install an eBPF program on a Tracepoint\n  kprobe      Install a kprobe or kretprobe eBPF probe\n  uprobe      Install a uprobe or uretprobe eBPF probe\n  fentry      Install a fentry eBPF probe\n  fexit       Install a fexit eBPF probe\n  help        Print this message or the help of the given subcommand(s)\n\nArguments:\n  &lt;PROGRAM_ID&gt;  Required: Program Id to be attached\n\nOptions:\n  -h, --help  Print help\n</code></pre> <p>Each <code>&lt;COMMAND&gt;</code> has its own custom parameters:</p> <pre><code>sudo bpfman attach xdp --help\nInstall an eBPF program on the XDP hook point for a given interface\n\nUsage: bpfman attach &lt;PROGRAM_ID&gt; xdp [OPTIONS] --iface &lt;IFACE&gt; --priority &lt;PRIORITY&gt;\n\nOptions:\n  -i, --iface &lt;IFACE&gt;\n          Required: Interface to load program on\n\n  -p, --priority &lt;PRIORITY&gt;\n          Required: Priority to run program in chain. Lower value runs first.\n          [possible values: 1-1000]\n\n      --proceed-on &lt;PROCEED_ON&gt;...\n          Optional: Proceed to call other programs in chain on this exit code.\n          Multiple values supported by repeating the parameter.\n          Example: --proceed-on pass --proceed-on drop\n\n          [possible values: aborted, drop, pass, tx, redirect, dispatcher_return]\n\n          [default: pass, dispatcher_return]\n\n  -n, --netns &lt;NETNS&gt;\n          Optional: The file path of the target network namespace.\n          Example: -n /var/run/netns/bpfman-test\n\n  -m, --metadata &lt;METADATA&gt;\n          Optional: Specify Key/Value metadata to be attached to a link when it\n          is loaded by bpfman.\n          Format: &lt;KEY&gt;=&lt;VALUE&gt;\n\n          This can later be used to list a certain subset of links which contain\n          the specified metadata.\n          Example: --metadata owner=acme\n\n  -h, --help\n          Print help (see a summary with '-h')```\n\nExample attaching an XDP Program:\n\n```console\nsudo bpfman attach 63674 xdp --iface eno3 --priority 100\n</code></pre> <p>The <code>tc</code> command is similar to <code>xdp</code>, but it also requires the <code>direction</code> option and the <code>proceed-on</code> values are different.</p> <pre><code>sudo bpfman attach tc --help\nInstall an eBPF program on the TC hook point for a given interface\n\nUsage: bpfman attach &lt;PROGRAM_ID&gt; tc [OPTIONS] --direction &lt;DIRECTION&gt; --iface &lt;IFACE&gt; --priority &lt;PRIORITY&gt;\n\nOptions:\n  -d, --direction &lt;DIRECTION&gt;\n          Required: Direction to apply program.\n\n          [possible values: ingress, egress]\n\n  -i, --iface &lt;IFACE&gt;\n          Required: Interface to load program on\n\n  -p, --priority &lt;PRIORITY&gt;\n          Required: Priority to run program in chain. Lower value runs first.\n          [possible values: 1-1000]\n\n      --proceed-on &lt;PROCEED_ON&gt;...\n          Optional: Proceed to call other programs in chain on this exit code.\n          Multiple values supported by repeating the parameter.\n          Example: --proceed-on ok --proceed-on pipe\n\n          [possible values: unspec, ok, reclassify, shot, pipe, stolen, queued,\n                            repeat, redirect, trap, dispatcher_return]\n\n          [default: ok, pipe, dispatcher_return]\n\n  -n, --netns &lt;NETNS&gt;\n          Optional: The file path of the target network namespace.\n          Example: -n /var/run/netns/bpfman-test\n\n  -m, --metadata &lt;METADATA&gt;\n          Optional: Specify Key/Value metadata to be attached to a link when it\n          is loaded by bpfman.\n          Format: &lt;KEY&gt;=&lt;VALUE&gt;\n\n          This can later be used to list a certain subset of links which contain\n          the specified metadata.\n          Example: --metadata owner=acme\n\n  -h, --help\n          Print help (see a summary with '-h')\n</code></pre> <p>The following is an example of attaching the <code>tc</code> command using short option names:</p> <pre><code>sudo bpfman attach 63671 tc -d ingress -i eno3 -p 40\n</code></pre>"},{"location":"getting-started/cli-guide/#additional-attach-examples","title":"Additional Attach Examples","text":"<p>Below are some additional examples of <code>bpfman attach</code> commands:</p>"},{"location":"getting-started/cli-guide/#fentry","title":"Fentry","text":"<pre><code>sudo bpfman attach 63682 fentry\n</code></pre>"},{"location":"getting-started/cli-guide/#fexit","title":"Fexit","text":"<pre><code>sudo bpfman attach 63744 fexit\n</code></pre>"},{"location":"getting-started/cli-guide/#kprobe","title":"Kprobe","text":"<pre><code>sudo bpfman attach 63690 kprobe -f try_to_wake_up\n</code></pre>"},{"location":"getting-started/cli-guide/#kretprobe","title":"Kretprobe","text":"<pre><code>sudo bpfman attach 63698 kprobe -f try_to_wake_up\n</code></pre>"},{"location":"getting-started/cli-guide/#tc","title":"TC","text":"<pre><code>sudo bpfman attach 63706 tc --direction ingress --iface eno3 --priority 110\n</code></pre>"},{"location":"getting-started/cli-guide/#tcx","title":"TCX","text":"<pre><code>sudo bpfman attach 63672 tcx --direction ingress --iface eno3 --priority 22\n</code></pre>"},{"location":"getting-started/cli-guide/#tracepoint","title":"Tracepoint","text":"<pre><code>sudo bpfman attach 63670 tracepoint --tracepoint syscalls/sys_enter_openat\n</code></pre>"},{"location":"getting-started/cli-guide/#uprobe","title":"Uprobe","text":"<pre><code>sudo bpfman attach 63673 uprobe -t \"libc\" -f \"malloc\"\n</code></pre>"},{"location":"getting-started/cli-guide/#uretprobe","title":"Uretprobe","text":"<pre><code>sudo bpfman attach 63809 uprobe -t \"libc\" -f \"malloc\"\n</code></pre>"},{"location":"getting-started/cli-guide/#xdp","title":"XDP","text":"<pre><code>sudo bpfman attach 63674 xdp --iface eno3 --priority 35\n</code></pre>"},{"location":"getting-started/cli-guide/#attach-to-multiple-hook-points","title":"Attach to Multiple Hook Points","text":"<p>Most programs can attach to multiple hook points. To attach a program to multiple hook points, simply call <code>bpfman attach</code> multiple times with the same <code>Program ID</code>:</p> <pre><code>sudo bpfman attach 63661 xdp --iface eno3 --priority 35\nsudo bpfman attach 63661 xdp --iface eno4 --priority 35\n\nsudo bpfman list programs --application XdpPassProgram\n Program ID  Application     Type  Function Name  Links\n 63661       XdpPassProgram  xdp   pass           (2) 1301256968, 18827142\n</code></pre>"},{"location":"getting-started/cli-guide/#modifying-the-proceed-on-behavior","title":"Modifying the Proceed-On Behavior","text":"<p>The <code>proceed-on</code> setting applies to <code>xdp</code> and <code>tc</code> programs. For both of these program types, an ordered list of eBPF programs is maintained per attach point. The <code>proceed-on</code> setting determines whether processing will \"proceed\" to the next eBPF program in the list, or terminate processing and return, based on the program's return value. For example, the default <code>proceed-on</code> configuration for an <code>xdp</code> program can be modified as follows:</p> <pre><code>sudo bpfman attach 63661 xdp -i eno3 -p 30 --proceed-on drop pass dispatcher_return\n</code></pre>"},{"location":"getting-started/cli-guide/#bpfman-detach","title":"bpfman detach","text":"<p>The <code>bpfman detach</code> command is used to detach an eBPF program from a hook point. When detached, the eBPF program is still loaded in kernel memory, but it is not attached to the hook point, so the eBPF program will not be triggered. The <code>bpfman detach</code> takes the <code>Link ID</code>, which can be obtained from the <code>bpfman list programs|links</code> or <code>bpfman get program|link</code> commands.</p> <pre><code>sudo bpfman detach --help\nDetach an eBPF program from a hook point using the Link Id\n\nUsage: bpfman detach &lt;LINK_ID&gt;\n\nArguments:\n  &lt;LINK_ID&gt;  Required: Link Id to be detached\n\nOptions:\n  -h, --help  Print help\n</code></pre> <p>For example:</p> <pre><code>sudo bpfman list programs\n Program ID  Application     Type        Function Name    Links\n 63652       TcPassProgram   tc          pass\n 63661       XdpPassProgram  xdp         pass             (3) 1301256968, 18827142, 3974774760\n 63669       go-app          kprobe      kprobe_counter\n 63670       go-app          tracepoint  tracepoint_kill  (1) 1462192047\n 63671       go-app          tc          stats            (1) 3041462868\n 63672       go-app          tcx         tcx_stats        (1) 3926782293\n 63673       go-app          uprobe      uprobe_counter\n 63674       go-app          xdp         xdp_stats        (2) 241636937, 4229414503\n 63682                       fentry      test_fentry      (1) 294437142\n 63690                       kprobe      my_kprobe        (1) 2131925936\n 63698                       kprobe      my_kretprobe     (1) 1834679786\n 63706       TcGlobal        tc          pass             (1) 2333059649\n 63744                       fexit       test_fexit       (1) 2055942218\n 63809                       uprobe      uretprobe_count  (1) 800266964\n</code></pre> <pre><code>sudo bpfman detach 3974774760\n</code></pre>"},{"location":"getting-started/cli-guide/#bpfman-list","title":"bpfman list","text":"<p>The <code>bpfman list programs</code> command lists all the bpfman loaded eBPF programs and the <code>bpfman list links</code> command lists all the bpfman attached eBPF programs.</p>"},{"location":"getting-started/cli-guide/#bpfman-list-programs","title":"bpfman list programs","text":"<p>Use the <code>bpfman list programs</code> command lists all the bpfman loaded eBPF programs. From the output of the command, if there is a value for the <code>Links</code> parameter, then the program has been loaded and attached. If no value exists, the program has only been loaded (or not managed by bpfman).</p> <pre><code>sudo bpfman list programs\n Program ID  Application     Type        Function Name    Links\n 63652       TcPassProgram   tc          pass\n 63661       XdpPassProgram  xdp         pass             (2) 1301256968, 18827142\n 63669       go-app          kprobe      kprobe_counter\n 63670       go-app          tracepoint  tracepoint_kill  (1) 1462192047\n 63671       go-app          tc          stats            (1) 3041462868\n 63672       go-app          tcx         tcx_stats        (1) 3926782293\n 63673       go-app          uprobe      uprobe_counter\n 63674       go-app          xdp         xdp_stats        (2) 241636937, 4229414503\n 63682                       fentry      test_fentry      (1) 294437142\n 63690                       kprobe      my_kprobe        (1) 2131925936\n 63698                       kprobe      my_kretprobe     (1) 1834679786\n 63706       TcGlobal        tc          pass             (1) 2333059649\n 63744                       fexit       test_fexit       (1) 2055942218\n 63809                       uprobe      uretprobe_count  (1) 800266964\n</code></pre> <p>If the <code>--application</code> parameter was used during the <code>bpfman load</code> command, that can be used to filter the programs displayed in the command.</p> <pre><code>sudo bpfman list programs --application go-app\n Program ID  Application  Type        Function Name    Links\n 63669       go-app       kprobe      kprobe_counter\n 63670       go-app       tracepoint  tracepoint_kill  (1) 1462192047\n 63671       go-app       tc          stats            (1) 3041462868\n 63672       go-app       tcx         tcx_stats        (1) 3926782293\n 63673       go-app       uprobe      uprobe_counter\n 63674       go-app       xdp         xdp_stats        (2) 241636937, 422941450\n ```\n\nTo see all eBPF programs loaded on the system, not just bpfman loaded programs,\ninclude the `--all` option.\n\n```console\nsudo bpfman list programs --all\n :\n 63638                       cgroup_device  sd_devices\n 63639                       cgroup_skb     sd_fw_egress\n 63640                       cgroup_skb     sd_fw_ingress\n 63641                       cgroup_device  sd_devices\n 63642                       cgroup_skb     sd_fw_egress\n 63643                       cgroup_skb     sd_fw_ingress\n 63651                       tc             tc_dispatcher\n 63652       TcPassProgram   tc             pass\n 63660                       xdp            xdp_dispatcher\n 63661       XdpPassProgram  xdp            pass             (2) 1301256968, 18827142\n 63669       go-app          kprobe         kprobe_counter\n 63670       go-app          tracepoint     tracepoint_kill  (1) 1462192047\n 63671       go-app          tc             stats            (1) 3041462868\n 63672       go-app          tcx            tcx_stats        (1) 3926782293\n 63673       go-app          uprobe         uprobe_counter\n 63674       go-app          xdp            xdp_stats        (2) 241636937, 4229414503\n 63682                       fentry         test_fentry      (1) 294437142\n 63690                       kprobe         my_kprobe        (1) 2131925936\n 63698                       kprobe         my_kretprobe     (1) 1834679786\n 63706       TcGlobal        tc             pass             (1) 2333059649\n 63744                       fexit          test_fexit       (1) 2055942218\n 63787                       tc             tc_dispatcher\n 63809                       uprobe         uretprobe_count  (1) 800266964\n 63847                       xdp            xdp_dispatcher\n 63884                       xdp            xdp_dispatcher\n ```\n\nTo filter on a given program type, include the `--program-type` parameter:\n\n```console\nsudo bpfman list programs --all --program-type tc\n Program ID  Application    Type  Function Name  Links\n 63651                      tc    tc_dispatcher\n 63652       TcPassProgram  tc    pass\n 63671       go-app         tc    stats          (1) 3041462868\n 63672       go-app         tcx   tcx_stats      (1) 3926782293\n 63706       TcGlobal       tc    pass           (1) 2333059649\n 63787                      tc    tc_dispatcher\n</code></pre> <p>Note: The list filters by the Kernel Program Type.</p> <ul> <li>probe: <code>kprobe</code>, <code>kretprobe</code>, <code>uprobe</code> and <code>uretprobe</code> all map to the <code>probe</code> Kernel Program Type.</li> <li>tracing: <code>fentry</code> and <code>fexit</code> both map to the <code>tracing</code> Kernel Program Type.</li> <li>tc: <code>tc</code> and <code>tcx</code> both map to the <code>tc</code> Kernel Program Type.</li> </ul>"},{"location":"getting-started/cli-guide/#bpfman-list-links","title":"bpfman list links","text":"<p>Use the <code>bpfman list links</code> command lists all the bpfman attached eBPF programs.</p> <pre><code>sudo bpfman list links\n Program ID  Link ID     Application     Type        Function Name    Attachment\n 63661       1301256968  XdpPassProgram  xdp         pass             eno4 pos-0\n 63661       18827142    XdpPassProgram  xdp         pass             eno3 pos-0\n 63670       1462192047  go-app          tracepoint  tracepoint_kill  syscalls/sys_enter_openat\n 63671       3041462868  go-app          tc          stats            eno3 ingress pos-0\n 63672       3926782293  go-app          tcx         tcx_stats        eno3 ingress pos-0\n 63674       241636937   go-app          xdp         xdp_stats        eno3 pos-2\n 63674       4229414503  go-app          xdp         xdp_stats        eno3 pos-1\n 63682       294437142                   fentry      test_fentry      do_unlinkat\n 63690       2131925936                  kprobe      my_kprobe        try_to_wake_up\n 63698       1834679786                  kprobe      my_kretprobe     try_to_wake_up\n 63706       2333059649  TcGlobal        tc          pass             eno3 ingress pos-1\n 63744       2055942218                  fexit       test_fexit       do_unlinkat\n 63809       800266964                   uprobe      uretprobe_count  libc malloc\n</code></pre> <p>If the <code>--application</code> parameter was used during the <code>bpfman load</code> command, that can be used to filter the programs displayed in the command.</p> <pre><code>sudo bpfman list links --application go-app\n Program ID  Link ID     Application  Type        Function Name    Attachment\n 63670       1462192047  go-app       tracepoint  tracepoint_kill  syscalls/sys_enter_openat\n 63671       3041462868  go-app       tc          stats            eno3 ingress pos-0\n 63672       3926782293  go-app       tcx         tcx_stats        eno3 ingress pos-0\n 63674       241636937   go-app       xdp         xdp_stats        eno3 pos-2\n 63674       4229414503  go-app       xdp         xdp_stats        eno3 pos-1\n ```\n\nTo filter on a given program type, include the `--program-type` parameter:\n\n```console\nsudo bpfman list links -p tc\n Program ID  Link ID     Application  Type  Function Name  Attachment\n 63671       3041462868  go-app       tc    stats          eno3 ingress pos-0\n 63672       3926782293  go-app       tcx   tcx_stats      eno3 ingress pos-0\n 63706       2333059649  TcGlobal     tc    pass           eno3 ingress pos-1\n</code></pre> <p>Note: The list filters by the Kernel Program Type.</p> <ul> <li>probe: <code>kprobe</code>, <code>kretprobe</code>, <code>uprobe</code> and <code>uretprobe</code> all map to the <code>probe</code> Kernel Program Type.</li> <li>tracing: <code>fentry</code> and <code>fexit</code> both map to the <code>tracing</code> Kernel Program Type.</li> <li>tc: <code>tc</code> and <code>tcx</code> both map to the <code>tc</code> Kernel Program Type.</li> </ul>"},{"location":"getting-started/cli-guide/#bpfman-get","title":"bpfman get","text":"<p>To retrieve detailed information for a loaded eBPF program, use the <code>bpfman get program &lt;PROGRAM_ID&gt;</code> command. To retrieve detailed information for an attached eBPF program, use the <code>bpfman get link &lt;LINK_ID&gt;</code> command.</p>"},{"location":"getting-started/cli-guide/#bpfman-get-program","title":"bpfman get program","text":"<p>To retrieve detailed information for a loaded eBPF program, use the <code>bpfman get program &lt;PROGRAM_ID&gt;</code> command. If the eBPF program was loaded via bpfman, then there will be a <code>Bpfman State</code> section with bpfman related attributes and a <code>Kernel State</code> section with kernel information. If the eBPF program was loaded outside of bpfman, then the <code>Bpfman State</code> section will be empty and <code>Kernel State</code> section will be populated.</p> <p>bpfman managed eBPF Program:</p> <pre><code>sudo bpfman get program 63661\n Bpfman State\n---------------\n BPF Function:  pass\n Program Type:  xdp\n Image URL:     quay.io/bpfman-bytecode/xdp_pass:latest\n Pull Policy:   IfNotPresent\n Global:        None\n Metadata:      bpfman_application=XdpPassProgram\n Map Pin Path:  /run/bpfman/fs/maps/63661\n Map Owner ID:  None\n Maps Used By:  63661\n Links:         1301256968 (eno4 pos-0)\n                18827142 (eno3 pos-0)\n Kernel State\n----------------------------------\n Program ID:                       63661\n BPF Function:                     pass\n Kernel Type:                      xdp\n Loaded At:                        2025-04-01T10:26:22-0400\n Tag:                              4b9d1b2c140e87ce\n GPL Compatible:                   true\n Map IDs:                          [21083]\n BTF ID:                           31353\n Size Translated (bytes):          96\n JITted:                           true\n Size JITted:                      75\n Kernel Allocated Memory (bytes):  4096\n Verified Instruction Count:       9\n</code></pre> <p>Non-bpfman managed eBPF Program:</p> <pre><code>sudo bpfman get program 63643\n Kernel State\n----------------------------------\n Program ID:                       63643\n BPF Function:                     sd_fw_ingress\n Kernel Type:                      cgroup_skb\n Loaded At:                        2025-04-01T10:25:02-0400\n Tag:                              6deef7357e7b4530\n GPL Compatible:                   true\n Map IDs:                          []\n BTF ID:                           0\n Size Translated (bytes):          64\n JITted:                           true\n Size JITted:                      63\n Kernel Allocated Memory (bytes):  4096\n Verified Instruction Count:       8\n</code></pre>"},{"location":"getting-started/cli-guide/#bpfman-get-link","title":"bpfman get link","text":"<p>To retrieve detailed information for an attached eBPF program, use the <code>bpfman get link &lt;LINK_ID&gt;</code> command. Only bpfman loaded and attached eBPF programs contain link data.</p> <pre><code>sudo bpfman get link 18827142\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63661\n Link ID:            18827142\n Interface:          eno3\n Priority:           35\n Position:           0\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre>"},{"location":"getting-started/cli-guide/#bpfman-unload","title":"bpfman unload","text":"<p>The <code>bpfman unload</code> command takes the <code>Program ID</code> from the load or list command as a parameter, and unloads the requested eBPF program. The eBPF programs do not need to be detached before unloading.</p> <pre><code>sudo bpfman unload 63661\n</code></pre> <pre><code>sudo bpfman list programs\n Program ID  Application    Type        Function Name    Links\n 63652       TcPassProgram  tc          pass\n 63669       go-app         kprobe      kprobe_counter\n 63670       go-app         tracepoint  tracepoint_kill  (1) 1462192047\n 63671       go-app         tc          stats            (1) 3041462868\n 63672       go-app         tcx         tcx_stats        (1) 3926782293\n 63673       go-app         uprobe      uprobe_counter\n 63674       go-app         xdp         xdp_stats        (2) 241636937, 4229414503\n 63682                      fentry      test_fentry      (1) 294437142\n 63690                      kprobe      my_kprobe        (1) 2131925936\n 63698                      kprobe      my_kretprobe     (1) 1834679786\n 63706       TcGlobal       tc          pass             (1) 2333059649\n 63744                      fexit       test_fexit       (1) 2055942218\n 63809                      uprobe      uretprobe_count  (1) 800266964\n</code></pre>"},{"location":"getting-started/cli-guide/#bpfman-image","title":"bpfman image","text":"<p>The <code>bpfman image</code> commands contain a set of container image related commands.</p>"},{"location":"getting-started/cli-guide/#bpfman-image-pull","title":"bpfman image pull","text":"<p>The <code>bpfman image pull</code> command pulls a given bytecode image for future use by a load command.</p> <pre><code>sudo bpfman image pull --help\nPull an eBPF bytecode image from a remote registry\n\nUsage: bpfman image pull [OPTIONS] --image-url &lt;IMAGE_URL&gt;\n\nOptions:\n  -i, --image-url &lt;IMAGE_URL&gt;\n          Required: Container Image URL.\n          Example: --image-url quay.io/bpfman-bytecode/xdp_pass:latest\n\n  -r, --registry-auth &lt;REGISTRY_AUTH&gt;\n          Optional: Registry auth for authenticating with the specified image registry.\n          This should be base64 encoded from the '&lt;username&gt;:&lt;password&gt;' string just like\n          it's stored in the docker/podman host config.\n          Example: --registry_auth \"YnjrcKw63PhDcQodiU9hYxQ2\"\n\n  -p, --pull-policy &lt;PULL_POLICY&gt;\n          Optional: Pull policy for remote images.\n\n          [possible values: Always, IfNotPresent, Never]\n\n          [default: IfNotPresent]\n\n  -h, --help\n          Print help (see a summary with '-h')\n</code></pre> <p>Example usage:</p> <pre><code>sudo bpfman image pull --image-url quay.io/bpfman-bytecode/xdp_pass:latest\nSuccessfully downloaded bytecode\n</code></pre> <p>Then when loaded, the local image will be used:</p> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/xdp_pass:latest \\\n     --programs xdp:pass\n Bpfman State\n ---------------\n BPF Function:  pass\n Program Type:  xdp\n Image URL:     quay.io/bpfman-bytecode/xdp_pass:latest\n Pull Policy:   IfNotPresent\n Global:        None\n Metadata:      None\n Map Pin Path:  /run/bpfman/fs/maps/64047\n Map Owner ID:  None\n Maps Used By:  64047\n Links:         None\n\n Kernel State\n ----------------------------------\n Program ID:                       64047\n BPF Function:                     pass\n Kernel Type:                      xdp\n Loaded At:                        2025-04-01T12:32:51-0400\n Tag:                              4b9d1b2c140e87ce\n GPL Compatible:                   true\n Map IDs:                          [21259]\n BTF ID:                           31787\n Size Translated (bytes):          96\n JITted:                           true\n Size JITted:                      75\n Kernel Allocated Memory (bytes):  4096\n Verified Instruction Count:       9\n</code></pre>"},{"location":"getting-started/cli-guide/#bpfman-image-build","title":"bpfman image build","text":"<p>The <code>bpfman image build</code> command is a utility command that builds and pushes an eBPF program in a OCI container image leveraging either <code>docker</code> or <code>podman</code>. The eBPF program bytecode must already be generated. This command calls <code>docker</code> or <code>podman</code> with the proper parameters for building multi-architecture based images with the proper labels for a OCI container image.</p> <p>Since this command is leveraging <code>docker</code> and <code>podman</code>, a container file (<code>--container-file</code> or <code>-f</code>) is required, along with an image tag (<code>--tag</code> of <code>-t</code>). In addition, the bytecode to package must be included. The bytecode can take several forms, but at least one must be provided:</p> <ul> <li><code>--bytecode</code> or <code>-b</code>: Use this option for a single bytecode object file built for the host architecture.   The value of this parameter is a single bytecode object file.</li> <li><code>--cilium-ebpf-project</code> or <code>-c</code>: Use this option for a cilium/ebpf based project.   The value of this parameter is a directory that contains multiple object files for different architectures,   where the object files follow the Cilium naming convention with the architecture in the name (i.e. bpf_x86_bpfel.o,   bpf_arm64_bpfel.o, bpf_powerpc_bpfel.o, bpf_s390_bpfeb.o).</li> <li><code>--bc-386-el</code> .. <code>--bc-s390x-eb</code>: Use this option to add one or more architecture specific bytecode files.</li> </ul> <pre><code>bpfman image build --help\nBuild an eBPF bytecode image from local bytecode objects and push to a registry.\n\nTo use, the --container-file and --tag must be included, as well as a pointer to\nat least one bytecode file that can be passed in several ways. Use either:\n\n* --bytecode: for a single bytecode built for the host architecture.\n\n* --cilium-ebpf-project: for a cilium/ebpf project directory which contains\n  multiple object files for different architectures.\n\n* --bc-386-el .. --bc-s390x-eb: to add one or more architecture specific bytecode files.\n\nExamples:\n   bpfman image build -f Containerfile.bytecode -t quay.io/&lt;USER&gt;/go-xdp-counter:test \\\n     -b ./examples/go-xdp-counter/bpf_x86_bpfel.o\n\nUsage: bpfman image build [OPTIONS] --tag &lt;TAG&gt; --container-file &lt;CONTAINER_FILE&gt; &lt;--bytecode &lt;BYTECODE&gt;|--cilium-ebpf-project &lt;CILIUM_EBPF_PROJECT&gt;|--bc-386-el &lt;BC_386_EL&gt;|--bc-amd64-el &lt;BC_AMD64_EL&gt;|--bc-arm-el &lt;BC_ARM_EL&gt;|--bc-arm64-el &lt;BC_ARM64_EL&gt;|--bc-loong64-el &lt;BC_LOONG64_EL&gt;|--bc-mips-eb &lt;BC_MIPS_EB&gt;|--bc-mipsle-el &lt;BC_MIPSLE_EL&gt;|--bc-mips64-eb &lt;BC_MIPS64_EB&gt;|--bc-mips64le-el &lt;BC_MIPS64LE_EL&gt;|--bc-ppc64-eb &lt;BC_PPC64_EB&gt;|--bc-ppc64le-el &lt;BC_PPC64LE_EL&gt;|--bc-riscv64-el &lt;BC_RISCV64_EL&gt;|--bc-s390x-eb &lt;BC_S390X_EB&gt;&gt;\n\nOptions:\n  -t, --tag &lt;TAG&gt;\n          Required: Name and optionally a tag in the name:tag format.\n          Example: --tag quay.io/bpfman-bytecode/xdp_pass:latest\n\n  -f, --container-file &lt;CONTAINER_FILE&gt;\n          Required: Dockerfile to use for building the image.\n          Example: --container_file Containerfile.bytecode\n\n  -r, --runtime &lt;RUNTIME&gt;\n          Optional: Container runtime to use, works with docker or podman, defaults to docker\n          Example: --runtime podman\n\n  -b, --bytecode &lt;BYTECODE&gt;\n          Optional: bytecode file to use for building the image assuming host architecture.\n          Example: -b ./examples/go-xdp-counter/bpf_x86_bpfel.o\n\n  -c, --cilium-ebpf-project &lt;CILIUM_EBPF_PROJECT&gt;\n          Optional: If specified pull multi-arch bytecode files from a cilium/ebpf formatted project\n          where the bytecode files all contain a standard bpf_&lt;GOARCH&gt;_&lt;(el/eb)&gt;.o tag.\n          Example: --cilium-ebpf-project ./examples/go-xdp-counter\n\n      --bc-386-el &lt;BC_386_EL&gt;\n          Optional: bytecode file to use for building the image assuming amd64 architecture.\n          Example: --bc-386-el ./examples/go-xdp-counter/bpf_386_bpfel.o\n\n      --bc-amd64-el &lt;BC_AMD64_EL&gt;\n          Optional: bytecode file to use for building the image assuming amd64 architecture.\n          Example: --bc-amd64-el ./examples/go-xdp-counter/bpf_x86_bpfel.o\n\n      --bc-arm-el &lt;BC_ARM_EL&gt;\n          Optional: bytecode file to use for building the image assuming arm architecture.\n          Example: --bc-arm-el ./examples/go-xdp-counter/bpf_arm_bpfel.o\n\n      --bc-arm64-el &lt;BC_ARM64_EL&gt;\n          Optional: bytecode file to use for building the image assuming arm64 architecture.\n          Example: --bc-arm64-el ./examples/go-xdp-counter/bpf_arm64_bpfel.o\n\n      --bc-loong64-el &lt;BC_LOONG64_EL&gt;\n          Optional: bytecode file to use for building the image assuming loong64 architecture.\n          Example: --bc-loong64-el ./examples/go-xdp-counter/bpf_loong64_bpfel.o\n\n      --bc-mips-eb &lt;BC_MIPS_EB&gt;\n          Optional: bytecode file to use for building the image assuming mips architecture.\n          Example: --bc-mips-eb ./examples/go-xdp-counter/bpf_mips_bpfeb.o\n\n      --bc-mipsle-el &lt;BC_MIPSLE_EL&gt;\n          Optional: bytecode file to use for building the image assuming mipsle architecture.\n          Example: --bc-mipsle-el ./examples/go-xdp-counter/bpf_mipsle_bpfel.o\n\n      --bc-mips64-eb &lt;BC_MIPS64_EB&gt;\n          Optional: bytecode file to use for building the image assuming mips64 architecture.\n          Example: --bc-mips64-eb ./examples/go-xdp-counter/bpf_mips64_bpfeb.o\n\n      --bc-mips64le-el &lt;BC_MIPS64LE_EL&gt;\n          Optional: bytecode file to use for building the image assuming mips64le architecture.\n          Example: --bc-mips64le-el ./examples/go-xdp-counter/bpf_mips64le_bpfel.o\n\n      --bc-ppc64-eb &lt;BC_PPC64_EB&gt;\n          Optional: bytecode file to use for building the image assuming ppc64 architecture.\n          Example: --bc-ppc64-eb ./examples/go-xdp-counter/bpf_ppc64_bpfeb.o\n\n      --bc-ppc64le-el &lt;BC_PPC64LE_EL&gt;\n          Optional: bytecode file to use for building the image assuming ppc64le architecture.\n          Example: --bc-ppc64le-el ./examples/go-xdp-counter/bpf_ppc64le_bpfel.o\n\n      --bc-riscv64-el &lt;BC_RISCV64_EL&gt;\n          Optional: bytecode file to use for building the image assuming riscv64 architecture.\n          Example: --bc-riscv64-el ./examples/go-xdp-counter/bpf_riscv64_bpfel.o\n\n      --bc-s390x-eb &lt;BC_S390X_EB&gt;\n          Optional: bytecode file to use for building the image assuming s390x architecture.\n          Example: --bc-s390x-eb ./examples/go-xdp-counter/bpf_s390x_bpfeb.o\n\n  -h, --help\n          Print help (see a summary with '-h')\n</code></pre> <p>Below are some different examples of building images. Note that <code>sudo</code> is not required. This command also pushed the image to a registry, so user must already be logged into the registry.</p> <p>Example of single bytecode image:</p> <pre><code>bpfman image build -f Containerfile.bytecode -t quay.io/$QUAY_USER/go-xdp-counter:test -b ./examples/go-xdp-counter/bpf_x86_bpfel.o\n</code></pre> <p>Example of directory with Cilium generated bytecode objects:</p> <pre><code>bpfman image build -f Containerfile.bytecode.multi.arch -t quay.io/$QUAY_USER/go-xdp-counter:test -c ./examples/go-xdp-counter/\n</code></pre> <p>Note</p> <p>To build images for multiple architectures on a local system, docker (or podman) may need additional configuration settings to allow for caching of non-native images. See https://docs.docker.com/build/building/multi-platform/ for more details.</p>"},{"location":"getting-started/cli-guide/#bpfman-image-generate-build-args","title":"bpfman image generate-build-args","text":"<p>The <code>bpfman image generate-build-args</code> command is a utility command that generates the labels used to package eBPF program bytecode in a OCI container image. It is recommended to use the <code>bpfman image build</code> command to package the eBPF program in a OCI container image, but an alternative is to generate the labels then build the container image with <code>docker</code> or <code>podman</code>.</p> <p>The eBPF program bytecode must already be generated. The bytecode can take several forms, but at least one must be provided:</p> <ul> <li><code>--bytecode</code> or <code>-b</code>: Use this option for a single bytecode object file built for the host architecture.   The value of this parameter is a single bytecode object file.</li> <li><code>--cilium-ebpf-project</code> or <code>-c</code>: Use this option for a cilium/ebpf based project.   The value of this parameter is a directory that contains multiple object files for different architectures,   where the object files follow the Cilium naming convention with the architecture in the name (i.e. bpf_x86_bpfel.o,   bpf_arm64_bpfel.o, bpf_powerpc_bpfel.o, bpf_s390_bpfeb.o).</li> <li><code>--bc-386-el</code> .. <code>--bc-s390x-eb</code>: Use this option to add one or more architecture specific bytecode files.</li> </ul> <pre><code>bpfman image generate-build-args --help\nGenerate the OCI image labels for a given bytecode file.\n\nTo use, the --container-file and --tag must be included, as well as a pointer to\nat least one bytecode file that can be passed in several ways. Use either:\n\n* --bytecode: for a single bytecode built for the host architecture.\n\n* --cilium-ebpf-project: for a cilium/ebpf project directory which contains\n  multiple object files for different architectures.\n\n* --bc-386-el .. --bc-s390x-eb: to add one or more architecture specific bytecode files.\n\nExamples:\n  bpfman image generate-build-args --bc-amd64-el ./examples/go-xdp-counter/bpf_x86_bpfel.o\n\nUsage: bpfman image generate-build-args &lt;--bytecode &lt;BYTECODE&gt;|--cilium-ebpf-project &lt;CILIUM_EBPF_PROJECT&gt;|--bc-386-el &lt;BC_386_EL&gt;|--bc-amd64-el &lt;BC_AMD64_EL&gt;|--bc-arm-el &lt;BC_ARM_EL&gt;|--bc-arm64-el &lt;BC_ARM64_EL&gt;|--bc-loong64-el &lt;BC_LOONG64_EL&gt;|--bc-mips-eb &lt;BC_MIPS_EB&gt;|--bc-mipsle-el &lt;BC_MIPSLE_EL&gt;|--bc-mips64-eb &lt;BC_MIPS64_EB&gt;|--bc-mips64le-el &lt;BC_MIPS64LE_EL&gt;|--bc-ppc64-eb &lt;BC_PPC64_EB&gt;|--bc-ppc64le-el &lt;BC_PPC64LE_EL&gt;|--bc-riscv64-el &lt;BC_RISCV64_EL&gt;|--bc-s390x-eb &lt;BC_S390X_EB&gt;&gt;\n\nOptions:\n  -b, --bytecode &lt;BYTECODE&gt;\n          Optional: bytecode file to use for building the image assuming host architecture.\n          Example: -b ./examples/go-xdp-counter/bpf_x86_bpfel.o\n\n  -c, --cilium-ebpf-project &lt;CILIUM_EBPF_PROJECT&gt;\n          Optional: If specified pull multi-arch bytecode files from a cilium/ebpf formatted project\n          where the bytecode files all contain a standard bpf_&lt;GOARCH&gt;_&lt;(el/eb)&gt;.o tag.\n          Example: --cilium-ebpf-project ./examples/go-xdp-counter\n\n      --bc-386-el &lt;BC_386_EL&gt;\n          Optional: bytecode file to use for building the image assuming amd64 architecture.\n          Example: --bc-386-el ./examples/go-xdp-counter/bpf_386_bpfel.o\n\n      --bc-amd64-el &lt;BC_AMD64_EL&gt;\n          Optional: bytecode file to use for building the image assuming amd64 architecture.\n          Example: --bc-amd64-el ./examples/go-xdp-counter/bpf_x86_bpfel.o\n\n      --bc-arm-el &lt;BC_ARM_EL&gt;\n          Optional: bytecode file to use for building the image assuming arm architecture.\n          Example: --bc-arm-el ./examples/go-xdp-counter/bpf_arm_bpfel.o\n\n      --bc-arm64-el &lt;BC_ARM64_EL&gt;\n          Optional: bytecode file to use for building the image assuming arm64 architecture.\n          Example: --bc-arm64-el ./examples/go-xdp-counter/bpf_arm64_bpfel.o\n\n      --bc-loong64-el &lt;BC_LOONG64_EL&gt;\n          Optional: bytecode file to use for building the image assuming loong64 architecture.\n          Example: --bc-loong64-el ./examples/go-xdp-counter/bpf_loong64_bpfel.o\n\n      --bc-mips-eb &lt;BC_MIPS_EB&gt;\n          Optional: bytecode file to use for building the image assuming mips architecture.\n          Example: --bc-mips-eb ./examples/go-xdp-counter/bpf_mips_bpfeb.o\n\n      --bc-mipsle-el &lt;BC_MIPSLE_EL&gt;\n          Optional: bytecode file to use for building the image assuming mipsle architecture.\n          Example: --bc-mipsle-el ./examples/go-xdp-counter/bpf_mipsle_bpfel.o\n\n      --bc-mips64-eb &lt;BC_MIPS64_EB&gt;\n          Optional: bytecode file to use for building the image assuming mips64 architecture.\n          Example: --bc-mips64-eb ./examples/go-xdp-counter/bpf_mips64_bpfeb.o\n\n      --bc-mips64le-el &lt;BC_MIPS64LE_EL&gt;\n          Optional: bytecode file to use for building the image assuming mips64le architecture.\n          Example: --bc-mips64le-el ./examples/go-xdp-counter/bpf_mips64le_bpfel.o\n\n      --bc-ppc64-eb &lt;BC_PPC64_EB&gt;\n          Optional: bytecode file to use for building the image assuming ppc64 architecture.\n          Example: --bc-ppc64-eb ./examples/go-xdp-counter/bpf_ppc64_bpfeb.o\n\n      --bc-ppc64le-el &lt;BC_PPC64LE_EL&gt;\n          Optional: bytecode file to use for building the image assuming ppc64le architecture.\n          Example: --bc-ppc64le-el ./examples/go-xdp-counter/bpf_ppc64le_bpfel.o\n\n      --bc-riscv64-el &lt;BC_RISCV64_EL&gt;\n          Optional: bytecode file to use for building the image assuming riscv64 architecture.\n          Example: --bc-riscv64-el ./examples/go-xdp-counter/bpf_riscv64_bpfel.o\n\n      --bc-s390x-eb &lt;BC_S390X_EB&gt;\n          Optional: bytecode file to use for building the image assuming s390x architecture.\n          Example: --bc-s390x-eb ./examples/go-xdp-counter/bpf_s390x_bpfeb.o\n\n  -h, --help\n          Print help (see a summary with '-h')\n</code></pre> <p>Below are some different examples of generating build arguments. Note that <code>sudo</code> is not required.</p> <p>Example of single bytecode image:</p> <pre><code>$ bpfman image generate-build-args -b ./examples/go-xdp-counter/bpf_x86_bpfel.o\nBYTECODE_FILE=./examples/go-xdp-counter/bpf_x86_bpfel.o\nPROGRAMS={\"xdp_stats\":\"xdp\"}\nMAPS={\"xdp_stats_map\":\"per_cpu_array\"}\n</code></pre> <p>Example of directory with Cilium generated bytecode objects:</p> <pre><code>$ bpfman image generate-build-args -c ./examples/go-xdp-counter/\nBC_AMD64_EL=./examples/go-xdp-counter/bpf_x86_bpfel.o\nBC_ARM_EL=./examples/go-xdp-counter/bpf_arm64_bpfel.o\nBC_PPC64LE_EL=./examples/go-xdp-counter/bpf_powerpc_bpfel.o\nBC_S390X_EB=./examples/go-xdp-counter/bpf_s390_bpfeb.o\nPROGRAMS={\"xdp_stats\":\"xdp\"}\nMAPS={\"xdp_stats_map\":\"per_cpu_array\"}\n</code></pre> <p>Once the labels are generated, the eBPF program can be packaged in a OCI container image using <code>docker</code> or <code>podman</code> by passing the generated labels as <code>build-arg</code> parameters:</p> <pre><code>docker build \\\n  --build-arg BYTECODE_FILE=./examples/go-xdp-counter/bpf_x86_bpfel.o \\\n  --build-arg PROGRAMS={\"xdp_stats\":\"xdp\"} \\\n  --build-arg MAPS={\"xdp_stats_map\":\"per_cpu_array\"} \\\n  -f Containerfile.bytecode . -t quay.io/$USER/go-xdp-counter-bytecode:test\n</code></pre>"},{"location":"getting-started/example-bpf-k8s/","title":"Deploying Example eBPF Programs On Kubernetes","text":"<p>This section will describe launching eBPF enabled applications on a Kubernetes cluster. The approach is slightly different when running on a Kubernetes cluster.</p> <p>This section assumes there is already a Kubernetes cluster running and <code>bpfman</code> is running in the cluster. See Deploying the bpfman-operator for details on deploying bpfman on a Kubernetes cluster, but the quickest solution is to run a Kubernetes KIND Cluster:</p> <pre><code>cd bpfman-operator/\nmake run-on-kind\n</code></pre>"},{"location":"getting-started/example-bpf-k8s/#loading-ebpf-programs-on-kubernetes","title":"Loading eBPF Programs On Kubernetes","text":"<p>Instead of using the userspace program or CLI to load the eBPF bytecode as done in previous sections, the bytecode will be loaded by creating a Kubernetes CRD object. There is a CRD object for each eBPF program type bpfman supports.</p> <ul> <li>FentryProgram CRD: Fentry Sample yaml</li> <li>FexitProgram CRD: Fexit Sample yaml</li> <li>KprobeProgram CRD: Kprobe Examples yaml</li> <li>TcProgram CRD: TcProgram Examples yaml</li> <li>TcxProgram CRD: TcxProgram Examples yaml</li> <li>TracepointProgram CRD: Tracepoint Examples yaml</li> <li>UprobeProgram CRD: Uprobe Examples yaml</li> <li>XdpProgram CRD: XdpProgram Examples yaml</li> </ul> <p>Sample bytecode yaml with XdpProgram CRD: <pre><code>cat examples/config/base/go-xdp-counter/bytecode.yaml\napiVersion: bpfman.io/v1alpha1\nkind: XdpProgram\nmetadata:\n  labels:\n    app.kubernetes.io/name: xdpprogram\n  name: go-xdp-counter-example\nspec:\n  name: xdp_stats\n  # Select all nodes\n  nodeselector: {}\n  interfaceselector:\n    primarynodeinterface: true\n  priority: 55\n  bytecode:\n    image:\n      url: quay.io/bpfman-bytecode/go-xdp-counter:latest\n</code></pre></p> <p>Note that all the sample yaml files are configured with the bytecode running on all nodes (<code>nodeselector: {}</code>). This can be configured to run on specific nodes, but the DaemonSet yaml for the userspace program, which is described below, should have an equivalent change.</p> <p>Assume the following command is run:</p> <pre><code>kubectl apply -f examples/config/base/go-xdp-counter/bytecode.yaml\n  xdpprogram.bpfman.io/go-xdp-counter-example created\n</code></pre> <p>The diagram below shows <code>go-xdp-counter</code> example, but the other examples operate in a similar fashion.</p> <p></p> <p>Following the diagram for XDP example (Blue numbers):</p> <ol> <li>The user creates a <code>XdpProgram</code> object with the parameters associated with the eBPF bytecode, like interface, priority and BFP bytecode image. The name of the <code>XdpProgram</code> object in this example is <code>go-xdp-counter-example</code>. The <code>XdpProgram</code> is applied using <code>kubectl</code>, but in a more practical deployment, the <code>XdpProgram</code> would be applied by the application or a controller.</li> <li><code>bpfman-agent</code>, running on each node, is watching for all changes to <code>XdpProgram</code> objects. When it sees a <code>XdpProgram</code> object created or modified, it makes sure a <code>BpfProgram</code> object for that node exists. The name of the <code>BpfProgram</code> object is the <code>XdpProgram</code> object name with the node name and interface or attach point appended. On a KIND Cluster, it would be similar to <code>go-xdp-counter-example-bpfman-deployment-control-plane-eth0</code>.</li> <li><code>bpfman-agent</code> then determines if it should be running on the given node, loads or unloads as needed by making gRPC calls the <code>bpfman-rpc</code>, which calls into the <code>bpfman</code> Library. <code>bpfman</code> behaves the same as described in the running locally example.</li> <li><code>bpfman-agent</code> finally updates the status of the <code>BpfProgram</code> object.</li> <li><code>bpfman-operator</code> watches all <code>BpfProgram</code> objects, and updates the status of the <code>XdpProgram</code> object indicating if the eBPF program has been applied to all the desired nodes or not.</li> </ol> <p>To retrieve information on the <code>XdpProgram</code> objects:</p> <pre><code>kubectl get xdpprograms\nNAME                     BPFFUNCTIONNAME   NODESELECTOR   STATUS\ngo-xdp-counter-example   xdp_stats         {}             ReconcileSuccess\n\n\nkubectl get xdpprograms go-xdp-counter-example -o yaml\napiVersion: bpfman.io/v1alpha1\nkind: XdpProgram\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"bpfman.io/v1alpha1\",\"kind\":\"XdpProgram\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/name\":\"xdpprogram\"},\"name\":\"go-xdp-counter-example\"},\"spec\":{\"bpffunctionname\":\"xdp_stats\",\"bytecode\":{\"image\":{\"url\":\"quay.io/bpfman-bytecode/go-xdp-counter:latest\"}},\"interfaceselector\":{\"primarynodeinterface\":true},\"nodeselector\":{},\"priority\":55}}\n  creationTimestamp: \"2023-11-06T21:05:15Z\"\n  finalizers:\n  - bpfman.io.operator/finalizer\n  generation: 2\n  labels:\n    app.kubernetes.io/name: xdpprogram\n  name: go-xdp-counter-example\n  resourceVersion: \"3103\"\n  uid: edd45e2e-a40b-4668-ac76-c1f1eb63a23b\nspec:\n  bpffunctionname: xdp_stats\n  bytecode:\n    image:\n      imagepullpolicy: IfNotPresent\n      url: quay.io/bpfman-bytecode/go-xdp-counter:latest\n  interfaceselector:\n    primarynodeinterface: true\n  mapownerselector: {}\n  nodeselector: {}\n  priority: 55\n  proceedon:\n  - pass\n  - dispatcher_return\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-06T21:05:21Z\"\n    message: bpfProgramReconciliation Succeeded on all nodes\n    reason: ReconcileSuccess\n    status: \"True\"\n    type: ReconcileSuccess\n</code></pre> <p>To retrieve information on the <code>BpfProgram</code> objects:</p> <pre><code>kubectl get bpfprograms\nNAME                                                          TYPE      STATUS         AGE\n:\ngo-xdp-counter-example-bpfman-deployment-control-plane-eth0   xdp       bpfmanLoaded   11m\n\n\nkubectl get bpfprograms go-xdp-counter-example-bpfman-deployment-control-plane-eth0 -o yaml\napiVersion: bpfman.io/v1alpha1\nkind: BpfProgram\nmetadata:\n  annotations:\n    bpfman.io.xdpprogramcontroller/interface: eth0\n    bpfman.io/ProgramId: \"4801\"\n  creationTimestamp: \"2023-11-06T21:05:15Z\"\n  finalizers:\n  - bpfman.io.xdpprogramcontroller/finalizer\n  generation: 1\n  labels:\n    bpfman.io/ownedByProgram: go-xdp-counter-example\n    kubernetes.io/hostname: bpfman-deployment-control-plane\n  name: go-xdp-counter-example-bpfman-deployment-control-plane-eth0\n  ownerReferences:\n  - apiVersion: bpfman.io/v1alpha1\n    blockOwnerDeletion: true\n    controller: true\n    kind: XdpProgram\n    name: go-xdp-counter-example\n    uid: edd45e2e-a40b-4668-ac76-c1f1eb63a23b\n  resourceVersion: \"3102\"\n  uid: f7ffd156-168b-4dc8-be38-18c42626a631\nspec:\n  type: xdp\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-06T21:05:21Z\"\n    message: Successfully loaded bpfProgram\n    reason: bpfmanLoaded\n    status: \"True\"\n    type: Loaded\n</code></pre>"},{"location":"getting-started/example-bpf-k8s/#deploying-an-ebpf-enabled-application-on-kubernetes","title":"Deploying an eBPF enabled application On Kubernetes","text":"<p>Here, a userspace container is deployed to consume the map data generated by the eBPF counter program. bpfman provides a Container Storage Interface (CSI) driver for exposing eBPF maps into a userspace container. To avoid having to mount a host directory that contains the map pinned file into the container and forcing the container to have permissions to access that host directory, the CSI driver mounts the map at a specified location in the container. All the examples use CSI, here is go-xdp-counter/deployment.yaml for reference:</p> <pre><code>cd bpfman/examples/\ncat config/base/go-xdp-counter/deployment.yaml\n:\n---\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: go-xdp-counter-ds\n  namespace: go-xdp-counter\n  labels:\n    k8s-app: go-xdp-counter\nspec:\n  :\n  template:\n    :\n    spec:\n       :\n      containers:\n      - name: go-xdp-counter\n        :\n        volumeMounts:\n        - name: go-xdp-counter-maps                        &lt;==== 2) VolumeMount in container\n          mountPath: /run/xdp/maps                         &lt;==== 2a) Mount path in the container\n          readOnly: true\n      volumes:\n      - name: go-xdp-counter-maps                          &lt;==== 1) Volume describing the map\n        csi:\n          driver: csi.bpfman.io                             &lt;==== 1a) bpfman CSI Driver\n          volumeAttributes:\n            csi.bpfman.io/program: go-xdp-counter-example   &lt;==== 1b) eBPF Program owning the map\n            csi.bpfman.io/maps: xdp_stats_map               &lt;==== 1c) Map to be exposed to the container\n</code></pre>"},{"location":"getting-started/example-bpf-k8s/#loading-a-userspace-container-image","title":"Loading A Userspace Container Image","text":"<p>The userspace programs have been pre-built and can be found here:</p> <ul> <li>quay.io/bpfman-userspace/go-kprobe-counter:latest</li> <li>quay.io/bpfman-userspace/go-tc-counter:latest</li> <li>quay.io/bpfman-userspace/go-tracepoint-counter:latest</li> <li>quay.io/bpfman-userspace/go-uprobe-counter:latest</li> <li>quay.io/bpfman-userspace/go-xdp-counter:latest</li> </ul> <p>The example yaml files below are loading from these image.</p> <ul> <li>go-kprobe-counter/deployment.yaml</li> <li>go-tc-counter/deployment.yaml</li> <li>go-tracepoint-counter/deployment.yaml</li> <li>go-uprobe-counter/deployment.yaml</li> <li>go-xdp-counter/deployment.yaml</li> </ul> <p>The userspace program in a Kubernetes Deployment doesn't interacts directly with <code>bpfman</code> like it did in the local host deployment. Instead, the userspace program running on each node, if needed, reads the <code>BpfProgram</code> object from the KubeApiServer to gather additional information about the loaded eBPF program. To interact with the KubeApiServer, RBAC must be setup properly to access the <code>BpfProgram</code> object. The <code>bpfman-operator</code> defined the yaml for several ClusterRoles that can be used to access the different <code>bpfman</code> related CRD objects with different access rights. The example userspace containers will use the <code>bpfprogram-viewer-role</code>, which allows Read-Only access to the <code>BpfProgram</code> object. This ClusterRole is created automatically by the <code>bpfman-operator</code>.</p> <p>The remaining objects (NameSpace, ServiceAccount, ClusterRoleBinding and examples DaemonSet) can be created for each program type as follows:</p> <pre><code>cd bpfman/\nkubectl create -f examples/config/base/go-xdp-counter/deployment.yaml\n</code></pre> <p>This creates the <code>go-xdp-counter</code> userspace pod, but the other examples operate in a similar fashion.</p> <p></p> <p>Following the diagram for the XDP example (Green numbers):</p> <ol> <li>The userspace program queries the KubeApiServer for a specific <code>BpfProgram</code> object.</li> <li>The userspace program verifies the <code>BpfProgram</code> has been loaded and uses the map to periodically read the counter values.</li> </ol> <p>To see if the userspace programs are working, view the logs:</p> <pre><code>kubectl get pods -A\nNAMESPACE               NAME                              READY   STATUS    RESTARTS   AGE\nbpfman                  bpfman-daemon-jsgdh               3/3     Running   0          11m\nbpfman                  bpfman-operator-6c5c8887f7-qk28x  2/2     Running   0          12m\ngo-xdp-counter          go-xdp-counter-ds-2hs6g           1/1     Running   0          6m12s\n:\n\nkubectl logs -n go-xdp-counter go-xdp-counter-ds-2hs6g\n2023/11/06 20:27:16 2429 packets received\n2023/11/06 20:27:16 1328474 bytes received\n\n2023/11/06 20:27:19 2429 packets received\n2023/11/06 20:27:19 1328474 bytes received\n\n2023/11/06 20:27:22 2430 packets received\n2023/11/06 20:27:22 1328552 bytes received\n:\n</code></pre> <p>To cleanup:</p> <pre><code>kubectl delete -f examples/config/base/go-xdp-counter/deployment.yaml\nkubectl delete -f examples/config/base/go-xdp-counter/bytecode.yaml\n</code></pre>"},{"location":"getting-started/example-bpf-k8s/#automated-deployment","title":"Automated Deployment","text":"<p>The steps above are automated in the <code>Makefile</code> in the examples directory. Run <code>make deploy</code> to load each of the example bytecode and userspace yaml files, then <code>make undeploy</code> to unload them.</p> <pre><code>cd bpfman/examples/\nmake deploy\n  for target in deploy-tc deploy-tracepoint deploy-xdp deploy-xdp-ms deploy-kprobe deploy-target deploy-uprobe ; do \\\n      make $target  || true; \\\n  done\n  make[1]: Entering directory '/home/&lt;$USER&gt;/go/src/github.com/bpfman/bpfman/examples'\n  sed 's@URL_BC@quay.io/bpfman-bytecode/go-tc-counter:latest@' config/default/go-tc-counter/patch.yaml.env &gt; config/default/go-tc-counter/patch.yaml\n  cd config/default/go-tc-counter &amp;&amp; /home/&lt;$USER&gt;/go/src/github.com/bpfman/bpfman/examples/bin/kustomize edit set image quay.io/bpfman-userspace/go-tc-counter=quay.io/bpfman-userspace/go-tc-counter:latest\n  namespace/go-tc-counter created\n  serviceaccount/bpfman-app-go-tc-counter created\n  daemonset.apps/go-tc-counter-ds created\n  tcprogram.bpfman.io/go-tc-counter-example created\n  :\n  sed 's@URL_BC@quay.io/bpfman-bytecode/go-uprobe-counter:latest@' config/default/go-uprobe-counter/patch.yaml.env &gt; config/default/go-uprobe-counter/patch.yaml\n  cd config/default/go-uprobe-counter &amp;&amp; /home/&lt;$USER&gt;/go/src/github.com/bpfman/bpfman/examples/bin/kustomize edit set image quay.io/bpfman-userspace/go-uprobe-counter=quay.io/bpfman-userspace/go-uprobe-counter:latest\n  namespace/go-uprobe-counter created\n  serviceaccount/bpfman-app-go-uprobe-counter created\n  daemonset.apps/go-uprobe-counter-ds created\n  uprobeprogram.bpfman.io/go-uprobe-counter-example created\n  make[1]: Leaving directory '/home/&lt;$USER&gt;/go/src/github.com/bpfman/bpfman/examples'\n\n# Test Away ...\n\nkubectl get pods -A\nNAMESPACE               NAME                                                      READY   STATUS    RESTARTS   AGE\nbpfman                  bpfman-daemon-md2c5                                       3/3     Running   0          2d17h\nbpfman                  bpfman-operator-7f67bc7c57-95zf7                          2/2     Running   0          2d17h\ngo-kprobe-counter       go-kprobe-counter-ds-8dkls                                1/1     Running   0          2m14s\ngo-target               go-target-ds-nbdf5                                        1/1     Running   0          2m14s\ngo-tc-counter           go-tc-counter-ds-7mtcw                                    1/1     Running   0          2m19s\ngo-tracepoint-counter   go-tracepoint-counter-ds-bcbs7                            1/1     Running   0          2m18s\ngo-uprobe-counter       go-uprobe-counter-ds-j26hc                                1/1     Running   0          2m13s\ngo-xdp-counter          go-xdp-counter-ds-nls6s                                   1/1     Running   0          2m17s\n\nkubectl get bpfprograms\nNAME                                                                                                TYPE         STATUS         AGE\ngo-kprobe-counter-example-bpfman-deployment-control-plane-try-to-wake-up                            kprobe       bpfmanLoaded   2m41s\ngo-tc-counter-example-bpfman-deployment-control-plane-eth0                                          tc           bpfmanLoaded   2m46s\ngo-tracepoint-counter-example-bpfman-deployment-control-plane-syscalls-sys-enter-kill               tracepoint   bpfmanLoaded   2m35s\ngo-uprobe-counter-example-bpfman-deployment-control-plane--go-target-go-target-ds-nbdf5-go-target   uprobe       bpfmanLoaded   2m29s\ngo-xdp-counter-example-bpfman-deployment-control-plane-eth0                                         xdp          bpfmanLoaded   2m24s\ngo-xdp-counter-sharing-map-example-bpfman-deployment-control-plane-eth0                             xdp          bpfmanLoaded   2m21s\n\nmake undeploy\n  for target in undeploy-tc undeploy-tracepoint undeploy-xdp undeploy-xdp-ms undeploy-kprobe undeploy-uprobe undeploy-target ; do \\\n      make $target  || true; \\\n  done\n  make[1]: Entering directory '/home/&lt;$USER&gt;/go/src/github.com/bpfman/bpfman/examples'\n  sed 's@URL_BC@quay.io/bpfman-bytecode/go-tc-counter:latest@' config/default/go-tc-counter/patch.yaml.env &gt; config/default/go-tc-counter/patch.yaml\n  cd config/default/go-tc-counter &amp;&amp; /home/&lt;$USER&gt;/go/src/github.com/bpfman/bpfman/examples/bin/kustomize edit set image quay.io/bpfman-userspace/go-tc-counter=quay.io/bpfman-userspace/go-tc-counter:latest\n  namespace \"go-tc-counter\" deleted\n  serviceaccount \"bpfman-app-go-tc-counter\" deleted\n  daemonset.apps \"go-tc-counter-ds\" deleted\n  tcprogram.bpfman.io \"go-tc-counter-example\" deleted\n  :\n  kubectl delete -f config/base/go-target/deployment.yaml\n  namespace \"go-target\" deleted\n  serviceaccount \"bpfman-app-go-target\" deleted\n  daemonset.apps \"go-target-ds\" deleted\n  make[1]: Leaving directory '/home/&lt;$USER&gt;/go/src/github.com/bpfman/bpfman/examples'\n</code></pre> <p>Individual examples can be loaded and unloaded as well, for example <code>make deploy-xdp</code> and <code>make undeploy-xdp</code>. To see the full set of available commands, run <code>make help</code>:</p> <pre><code>make help\n\nUsage:\n  make &lt;target&gt;\n  make deploy TAG=v0.2.0\n  make deploy-xdp IMAGE_XDP_US=quay.io/user1/go-xdp-counter-userspace:test\n\nGeneral\n  help             Display this help.\n\nLocal Dependencies\n  kustomize        Download kustomize locally if necessary.\n\nDevelopment\n  fmt              Run go fmt against code.\n  verify           Verify all the autogenerated code\n\nBuild\n  build            Build all the userspace example code.\n  generate         Run `go generate` to build the bytecode for each of the examples.\n  build-us-images  Build all example userspace images\n  build-bc-images  Build bytecode example userspace images\n  push-us-images   Push all example userspace images\n  push-bc-images   Push all example bytecode images\n  load-us-images-kind  Build and load all example userspace images into kind\n\nDeployment Variables (not commands)\n  TAG              Used to set all images to a fixed tag. Example: make deploy TAG=v0.2.0\n  IMAGE_TC_BC      TC Bytecode image. Example: make deploy-tc IMAGE_TC_BC=quay.io/user1/go-tc-counter-bytecode:test\n  IMAGE_TC_US      TC Userspace image. Example: make deploy-tc IMAGE_TC_US=quay.io/user1/go-tc-counter-userspace:test\n  IMAGE_TP_BC      Tracepoint Bytecode image. Example: make deploy-tracepoint IMAGE_TP_BC=quay.io/user1/go-tracepoint-counter-bytecode:test\n  IMAGE_TP_US      Tracepoint Userspace image. Example: make deploy-tracepoint IMAGE_TP_US=quay.io/user1/go-tracepoint-counter-userspace:test\n  IMAGE_XDP_BC     XDP Bytecode image. Example: make deploy-xdp IMAGE_XDP_BC=quay.io/user1/go-xdp-counter-bytecode:test\n  IMAGE_XDP_US     XDP Userspace image. Example: make deploy-xdp IMAGE_XDP_US=quay.io/user1/go-xdp-counter-userspace:test\n  IMAGE_KP_BC      Kprobe Bytecode image. Example: make deploy-kprobe IMAGE_KP_BC=quay.io/user1/go-kprobe-counter-bytecode:test\n  IMAGE_KP_US      Kprobe Userspace image. Example: make deploy-kprobe IMAGE_KP_US=quay.io/user1/go-kprobe-counter-userspace:test\n  IMAGE_UP_BC      Uprobe Bytecode image. Example: make deploy-uprobe IMAGE_UP_BC=quay.io/user1/go-uprobe-counter-bytecode:test\n  IMAGE_UP_US      Uprobe Userspace image. Example: make deploy-uprobe IMAGE_UP_US=quay.io/user1/go-uprobe-counter-userspace:test\n  IMAGE_GT_US      Uprobe Userspace target. Example: make deploy-target IMAGE_GT_US=quay.io/user1/go-target-userspace:test\n  KIND_CLUSTER_NAME  Name of the deployed cluster to load example images to, defaults to `bpfman-deployment`\n  ignore-not-found  For any undeploy command, set to true to ignore resource not found errors during deletion. Example: make undeploy ignore-not-found=true\n\nDeployment\n  deploy-tc        Deploy go-tc-counter to the cluster specified in ~/.kube/config.\n  undeploy-tc      Undeploy go-tc-counter from the cluster specified in ~/.kube/config.\n  deploy-tracepoint  Deploy go-tracepoint-counter to the cluster specified in ~/.kube/config.\n  undeploy-tracepoint  Undeploy go-tracepoint-counter from the cluster specified in ~/.kube/config.\n  deploy-xdp       Deploy go-xdp-counter to the cluster specified in ~/.kube/config.\n  undeploy-xdp     Undeploy go-xdp-counter from the cluster specified in ~/.kube/config.\n  deploy-xdp-ms    Deploy go-xdp-counter-sharing-map (shares map with go-xdp-counter) to the cluster specified in ~/.kube/config.\n  undeploy-xdp-ms  Undeploy go-xdp-counter-sharing-map from the cluster specified in ~/.kube/config.\n  deploy-kprobe    Deploy go-kprobe-counter to the cluster specified in ~/.kube/config.\n  undeploy-kprobe  Undeploy go-kprobe-counter from the cluster specified in ~/.kube/config.\n  deploy-uprobe    Deploy go-uprobe-counter to the cluster specified in ~/.kube/config.\n  undeploy-uprobe  Undeploy go-uprobe-counter from the cluster specified in ~/.kube/config.\n  deploy-target    Deploy go-target to the cluster specified in ~/.kube/config.\n  undeploy-target  Undeploy go-target from the cluster specified in ~/.kube/config.\n  deploy           Deploy all examples to the cluster specified in ~/.kube/config.\n  undeploy         Undeploy all examples to the cluster specified in ~/.kube/config.\n</code></pre>"},{"location":"getting-started/example-bpf-k8s/#building-a-userspace-container-image","title":"Building A Userspace Container Image","text":"<p>To build the userspace examples in a container instead of using the pre-built ones, from the bpfman examples code source directory, run the following build command:</p> <pre><code>cd bpfman/examples\nmake \\\n  IMAGE_KP_US=quay.io/$USER/go-kprobe-counter:latest \\\n  IMAGE_TC_US=quay.io/$USER/go-tc-counter:latest \\\n  IMAGE_TP_US=quay.io/$USER/go-tracepoint-counter:latest \\\n  IMAGE_UP_US=quay.io/$USER/go-uprobe-counter:latest \\\n  IMAGE_XDP_US=quay.io/$USER/go-xdp-counter:latest \\\n  build-us-images\n</code></pre> <p>Then EITHER push images to a remote repository:</p> <pre><code>docker login quay.io\ncd bpfman/examples\nmake \\\n  IMAGE_KP_US=quay.io/$USER/go-kprobe-counter:latest \\\n  IMAGE_TC_US=quay.io/$USER/go-tc-counter:latest \\\n  IMAGE_TP_US=quay.io/$USER/go-tracepoint-counter:latest \\\n  IMAGE_UP_US=quay.io/$USER/go-uprobe-counter:latest \\\n  IMAGE_XDP_US=quay.io/$USER/go-xdp-counter:latest \\\n  push-us-images\n</code></pre> <p>OR load the images directly to a specified kind cluster:</p> <pre><code>cd bpfman/examples\nmake \\\n  IMAGE_KP_US=quay.io/$USER/go-kprobe-counter:latest \\\n  IMAGE_TC_US=quay.io/$USER/go-tc-counter:latest \\\n  IMAGE_TP_US=quay.io/$USER/go-tracepoint-counter:latest \\\n  IMAGE_UP_US=quay.io/$USER/go-uprobe-counter:latest \\\n  IMAGE_XDP_US=quay.io/$USER/go-xdp-counter:latest \\\n  KIND_CLUSTER_NAME=bpfman-deployment \\\n  load-us-images-kind\n</code></pre> <p>Lastly, update the yaml to use the private images or override the yaml files using the Makefile:</p> <pre><code>cd bpfman/examples/\n\nmake deploy-kprobe IMAGE_XDP_US=quay.io/$USER/go-kprobe-counter:latest\nmake undeploy-kprobe\n\nmake deploy-tc IMAGE_TC_US=quay.io/$USER/go-tc-counter:latest\nmake undeploy-tc\n\nmake deploy-tracepoint IMAGE_TP_US=quay.io/$USER/go-tracepoint-counter:latest\nmake undeploy-tracepoint\n\nmake deploy-uprobe IMAGE_XDP_US=quay.io/$USER/go-uprobe-counter:latest\nmake undeploy-uprobe\n\nmake deploy-xdp IMAGE_XDP_US=quay.io/$USER/go-xdp-counter:latest\nmake undeploy-xdp\n</code></pre>"},{"location":"getting-started/example-bpf-local/","title":"Deploying Example eBPF Programs On Local Host","text":"<p>This section describes running bpfman and the example eBPF programs on a local host.</p>"},{"location":"getting-started/example-bpf-local/#example-overview","title":"Example Overview","text":"<p>Assume the following command is run:</p> <pre><code>cd bpfman/examples/go-xdp-counter/\ngo run -exec sudo . -iface eno3\n</code></pre> <p>The diagram below shows <code>go-xdp-counter</code> example, but the other examples operate in a similar fashion.</p> <p></p> <p>Following the diagram (Purple numbers):</p> <ol> <li>When <code>go-xdp-counter</code> userspace is started, it will send a gRPC request over unix    socket to <code>bpfman-rpc</code> requesting <code>bpfman</code> to load and attach the <code>go-xdp-counter</code> eBPF bytecode    located on disk at <code>bpfman/examples/go-xdp-counter/bpf_x86_bpfel.o</code> at a priority of 50 and on    interface <code>eno3</code>.    These values are configurable as we will see later, but for now we will use the defaults    (except interface, which is required to be entered).</li> <li><code>bpfman</code> will load it's <code>dispatcher</code> eBPF program, which links to the <code>go-xdp-counter</code> eBPF program    and return a kernel Program ID referencing the running program.</li> <li><code>bpfman list programs</code> can be used to show that the eBPF program was loaded.</li> <li>Once the <code>go-xdp-counter</code> eBPF bytecode is loaded and attached, the eBPF program will write packet counts    and byte counts to a shared map.</li> <li><code>go-xdp-counter</code> userspace program periodically reads counters from the shared map and logs    the value.</li> </ol> <p>Below are the steps to run the example program described above and then some additional examples that use the <code>bpfman</code> CLI to load and unload other eBPF programs. See Launching bpfman for more detailed instructions on building and loading bpfman. This tutorial assumes bpfman has been built, <code>bpfman-rpc</code> is running, and the <code>bpfman</code> CLI is in $PATH.</p>"},{"location":"getting-started/example-bpf-local/#running-example-programs","title":"Running Example Programs","text":"<p>Example eBPF Programs describes how the example programs work, how to build them, and how to run the different examples. Build the <code>go-xdp-counter</code> program before continuing.</p> <p>To run the <code>go-xdp-counter</code> program, determine the host interface to attach the eBPF program to and then start the go program. In this example, <code>eno3</code> will be used, as shown in the diagram at the top of the page. The output should show the count and total bytes of packets as they pass through the interface as shown below:</p> <pre><code>cd bpfman/examples/go-xdp-counter/\n\ngo run -exec sudo . --iface eno3\n2023/07/17 17:43:58 Using Input: Interface=eno3 Priority=50 Source=/home/$USER/src/bpfman/examples/go-xdp-counter/bpf_x86_bpfel.o\n2023/07/17 17:43:58 Program registered with id 6211\n2023/07/17 17:44:01 4 packets received\n2023/07/17 17:44:01 580 bytes received\n\n2023/07/17 17:44:04 4 packets received\n2023/07/17 17:44:04 580 bytes received\n\n2023/07/17 17:44:07 8 packets received\n2023/07/17 17:44:07 1160 bytes received\n\n:\n</code></pre> <p>In another terminal, use the CLI to show the <code>go-xdp-counter</code> eBPF bytecode was loaded.</p> <pre><code>sudo bpfman list programs\n Program ID  Application    Type        Function Name    Links\n 64063                      xdp         xdp_stats        (1) 930390918\n</code></pre> <p>Finally, press <code>&lt;CTRL&gt;+c</code> when finished with <code>go-xdp-counter</code>.</p> <pre><code>:\n\n2023/07/17 17:44:34 28 packets received\n2023/07/17 17:44:34 4060 bytes received\n\n^C2023/07/17 17:44:35 Exiting...\n2023/07/17 17:44:35 Unloading Program: 6211\n</code></pre>"},{"location":"getting-started/example-bpf-local/#using-cli-to-manage-ebpf-programs","title":"Using CLI to Manage eBPF Programs","text":"<p>bpfman provides a CLI to interact with the <code>bpfman</code> Library. Find a deeper dive into CLI syntax in CLI Guide. We will load  and attach the simple <code>xdp-pass</code> program, which allows all traffic to pass through the attached interface, <code>eno3</code> in this example. The source code, xdp_pass.bpf.c, is located in the integration-test directory and there is also a prebuilt image: quay.io/bpfman-bytecode/xdp_pass:latest.</p> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/xdp_pass:latest \\\n     --programs xdp:pass --application XdpPassProgram\n Bpfman State\n---------------\n BPF Function:  pass\n Program Type:  xdp\n Image URL:     quay.io/bpfman-bytecode/xdp_pass:latest\n Pull Policy:   IfNotPresent\n Global:        None\n Metadata:      bpfman_application=XdpPassProgram\n Map Pin Path:  /run/bpfman/fs/maps/63556\n Map Owner ID:  None\n Maps Used By:  63556\n Links:         None\n\n Kernel State\n----------------------------------\n Program ID:                       63556\n BPF Function:                     pass\n Kernel Type:                      xdp\n Loaded At:                        2025-04-01T10:19:01-0400\n Tag:                              4b9d1b2c140e87ce\n GPL Compatible:                   true\n Map IDs:                          [21073]\n BTF ID:                           31333\n Size Translated (bytes):          96\n JITted:                           true\n Size JITted:                      75\n Kernel Allocated Memory (bytes):  4096\n Verified Instruction Count:       9\n</code></pre> <p><code>bpfman load image</code> returns the same data as the <code>bpfman get program</code> command. From the output, the Program Id of <code>63661</code> can be found in the <code>Kernel State</code> section. The Program Id can be used to perform a <code>bpfman get program</code> to retrieve all relevant program data and a <code>bpfman unload</code> when the program needs to be unloaded.</p> <pre><code>sudo bpfman list programs --application XdpPassProgram\n Program ID  Application     Type  Function Name  Links\n 63661       XdpPassProgram  xdp   pass\n</code></pre> <p>We can recheck the details about the loaded program with the <code>bpfman get program</code> command:</p> <pre><code>sudo bpfman get 63661\n Bpfman State\n---------------\n BPF Function:  pass\n Program Type:  xdp\n Image URL:     quay.io/bpfman-bytecode/xdp_pass:latest\n Pull Policy:   IfNotPresent\n Global:        None\n Metadata:      bpfman_application=XdpPassProgram\n Map Pin Path:  /run/bpfman/fs/maps/63556\n Map Owner ID:  None\n Maps Used By:  63556\n Links:         None\n\n Kernel State\n----------------------------------\n Program ID:                       63556\n BPF Function:                     pass\n Kernel Type:                      xdp\n Loaded At:                        2025-04-01T10:19:01-0400\n Tag:                              4b9d1b2c140e87ce\n GPL Compatible:                   true\n Map IDs:                          [21073]\n BTF ID:                           31333\n Size Translated (bytes):          96\n JITted:                           true\n Size JITted:                      75\n Kernel Allocated Memory (bytes):  4096\n Verified Instruction Count:       9\n</code></pre> <p>At this point, the program is loaded in kernel memory, but has not been attached to any hook points. So the eBPF program will not be triggered. To attach the eBPF program to a hook point, use the <code>bpfman attach</code> command.</p> <pre><code>sudo bpfman attach 63661 xdp --iface eno3 --priority 35\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63661\n Link ID:            1301256968\n Interface:          eno4\n Priority:           35\n Position:           0\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <p><code>bpfman attach</code> returns the same data as the <code>bpfman get link</code> command. From the output, the Link Id of <code>1301256968</code> can be found in the <code>Bpfman State</code> section. The Link Id can be used to perform a <code>bpfman get link</code> to retrieve all relevant link data.</p> <pre><code>sudo bpfman list programs --application XdpPassProgram\n Program ID  Application     Type  Function Name  Links\n 63661       XdpPassProgram  xdp   pass           (1) 1301256968\n</code></pre> <p>We can recheck the details about the attached program with the <code>bpfman get link</code> command:</p> <pre><code>sudo bpfman get link 63661 1301256968\n Bpfman State\n---------------\n BPF Function:       pass\n Program Type:       xdp\n Program ID:         63661\n Link ID:            1301256968\n Interface:          eno4\n Priority:           35\n Position:           0\n Proceed On:         pass, dispatcher_return\n Network Namespace:  None\n Metadata:           bpfman_application=XdpPassProgram\n</code></pre> <p>Then unload the program:</p> <pre><code>sudo bpfman unload 63661\n</code></pre>"},{"location":"getting-started/example-bpf/","title":"Example eBPF Programs","text":"<p>Example applications that use the <code>bpfman-go</code> bindings can be found in the bpfman/examples/ directory. Current examples include:</p> <ul> <li>bpfman/examples/go-app-counter/</li> <li>bpfman/examples/go-kprobe-counter/</li> <li>bpfman/examples/go-target/</li> <li>bpfman/examples/go-tc-counter/</li> <li>bpfman/examples/go-tcx-counter/</li> <li>bpfman/examples/go-tracepoint-counter/</li> <li>bpfman/examples/go-uprobe-counter/</li> <li>bpfman/examples/go-uretprobe-counter/</li> <li>bpfman/examples/go-xdp-counter/</li> </ul>"},{"location":"getting-started/example-bpf/#example-code-breakdown","title":"Example Code Breakdown","text":"<p>These examples and the associated documentation are intended to provide the basics on how to deploy and manage an eBPF program using bpfman. Each of the examples contains an eBPF Program(s) written in C (app_counter.c, kprobe_counter.c, tc_counter.c, tcx_counter.c, tracepoint_counter.c, uprobe_counter.c, uretprobe_counter.c, and xdp_counter.c) that is compiled into eBPF bytecode for each supported architecture (bpf_arm64_bpfel.o, bpf_powerpc_bpfel.o, bpf_s390_bpfeb.o and bpf_x86_bpfel.o). Each time the eBPF program is called, it increments the packet and byte counts in a map that is accessible by the userspace portion.</p> <p>Each of the examples also have a userspace portion written in GO. The userspace code is leveraging the cilium/ebpf library to manage the maps shared with the eBPF program. The example eBPF programs are very similar in functionality, and only vary where in the Linux networking stack they are inserted. The userspace program then polls the eBPF map every 3 seconds and logs the current counts.</p> <p>The examples were written to either run locally on a host or run in a container in a Kubernetes deployment. The userspace code flow is slightly different depending on the deployment, so input parameters dictate the deployment method.</p>"},{"location":"getting-started/example-bpf/#examples-in-local-deployment","title":"Examples in Local Deployment","text":"<p>When run locally, the userspace program makes gRPC calls to <code>bpfman-rpc</code> requesting <code>bpfman</code> to load the eBPF program at the requested hook point (TC hook point, Tracepoint, XDP hook point, etc). Data sent in the RPC request is either defaulted or passed in via input parameters. To make the examples as simple as possible to run, all input data is defaulted (except the interface TC and XDP programs need to attach to) but can be overwritten if desired. All example programs have the following common parameters (kprobe does not have any command specific parameters):</p> <pre><code>cd bpfman/examples/go-kprobe-counter/\n\n./go-kprobe-counter --help\nUsage of ./go-kprobe-counter:\n  -crd\n      Flag to indicate all attributes should be pulled from the BpfProgram CRD.\n      Used in Kubernetes deployments and is mutually exclusive with all other\n      parameters.\n  -file string\n      File path of bytecode source. \"file\" and \"image\"/\"id\" are mutually exclusive.\n      Example: -file /home/$USER/src/bpfman/examples/go-kprobe-counter/bpf_x86_bpfel.o\n  -id uint\n      Optional Program ID of bytecode that has already been loaded. \"id\" and\n      \"file\"/\"image\" are mutually exclusive.\n      Example: -id 28341\n  -image string\n      Image repository URL of bytecode source. \"image\" and \"file\"/\"id\" are\n      mutually exclusive.\n      Example: -image quay.io/bpfman-bytecode/go-kprobe-counter:latest\n  -map_owner_id int\n      Program Id of loaded eBPF program this eBPF program will share a map with.\n      Example: -map_owner_id 9785\n</code></pre> <p>The location of the eBPF bytecode can be provided four different ways:</p> <ul> <li>Defaulted: If nothing is passed in, the code scans the local directory for   a <code>bpf_x86_bpfel.o</code> file. If found, that is used. If not, it errors out.</li> <li>file: Fully qualified path of the bytecode object file.</li> <li>image: Image repository URL of bytecode source.</li> <li>id: Kernel program Id of a bytecode that has already been loaded. This   program could have been loaded using <code>bpftool</code>, or <code>bpfman</code>. </li> </ul> <p>If two userspace programs need to share the same map, map_owner_id is the Program ID of the first loaded program that has the map the second program wants to share.</p> <p>The examples require <code>sudo</code> to run because they require access the Unix socket <code>bpfman-rpc</code> is listening on. Deploying Example eBPF Programs On Local Host steps through launching <code>bpfman</code> locally and running some of the examples. </p>"},{"location":"getting-started/example-bpf/#examples-in-kubernetes-deployment","title":"Examples in Kubernetes Deployment","text":"<p>When run in a Kubernetes deployment, all the input data is passed to Kubernetes through yaml files. To indicate to the userspace code that it is in a Kubernetes deployment and not to try to load the eBPF bytecode, the example is launched in the container with the crd flag. Example: <code>./go-kprobe-counter -crd</code></p> <p>For these examples, the bytecode is loaded via one yaml file which creates a *Program CRD Object (KprobeProgram, TcProgram, TracepointProgram, etc.) and the userspace pod is loaded via another yaml file. In a more realistic deployment, the userspace pod may have the logic to send the *Program CRD Object create request to the KubeAPI Server, but the two yaml files are load manually for simplicity in the example code. The examples directory contain yaml files to load each example, leveraging Kustomize to modify the yaml to load the latest images from Quay.io, to load custom images or released based images. It is recommended to use the commands built into the Makefile, which run kustomize, to apply and remove the yaml files to a Kubernetes cluster. Use <code>make help</code> to see all the make options. For example:</p> <pre><code>cd bpfman/examples/\n\n# Deploy then undeploy all the examples\nmake deploy\nmake undeploy\n\nOR\n\n# Deploy then undeploy just the TC example\nmake deploy-tc\nmake undeploy-tc\n</code></pre> <p>Deploying Example eBPF Programs On Kubernetes steps through deploying bpfman to multiple nodes in a Kubernetes cluster and loading the examples.</p>"},{"location":"getting-started/example-bpf/#building-example-code","title":"Building Example Code","text":"<p>All the examples can be built locally as well as packaged in a container for Kubernetes deployment.</p>"},{"location":"getting-started/example-bpf/#building-locally","title":"Building Locally","text":"<p>To build directly on a system, make sure all the prerequisites are met, then build.</p>"},{"location":"getting-started/example-bpf/#prerequisites","title":"Prerequisites","text":"<p>This assumes bpfman is already installed and running on the system. If not, see Setup and Building bpfman.</p> <ol> <li>All requirements defined by the <code>cilium/ebpf</code> package</li> <li> <p>libbpf development package to get the required eBPF c headers</p> <p>Fedora: <code>sudo dnf install libbpf-devel</code></p> <p>Ubuntu: <code>sudo apt-get install libbpf-dev</code></p> </li> </ol>"},{"location":"getting-started/example-bpf/#build","title":"Build","text":"<p>To build all the C based eBPF counter bytecode, run:</p> <pre><code>cd bpfman/examples/\nmake generate\n</code></pre> <p>To build all the Userspace GO Client examples, run:</p> <pre><code>cd bpfman/examples/\nmake build\n</code></pre> <p>To build only a single example:</p> <pre><code>cd bpfman/examples/go-tracepoint-counter/\ngo generate\ngo build\n</code></pre> <p>Other program types are the same.</p>"},{"location":"getting-started/example-bpf/#building-ebpf-bytecode-container-image","title":"Building eBPF Bytecode Container Image","text":"<p>eBPF Bytecode Image Specifications provides detailed instructions on building and shipping bytecode in a container image. Pre-built eBPF container images for the examples can be loaded from:</p> <ul> <li><code>quay.io/bpfman-bytecode/go-app-counter:latest</code></li> <li><code>quay.io/bpfman-bytecode/go-kprobe-counter:latest</code></li> <li><code>quay.io/bpfman-bytecode/go-tc-counter:latest</code></li> <li><code>quay.io/bpfman-bytecode/go-tcx-counter:latest</code></li> <li><code>quay.io/bpfman-bytecode/go-tracepoint-counter:latest</code></li> <li><code>quay.io/bpfman-bytecode/go-uprobe-counter:latest</code></li> <li><code>quay.io/bpfman-bytecode/go-uretprobe-counter:latest</code></li> <li><code>quay.io/bpfman-bytecode/go-xdp-counter:latest</code></li> </ul> <p>To build the example eBPF bytecode container images, first generate the bytecode (the <code>generate</code> commands require the Prerequisites described above in the Building Locally section).</p> <p>To generate the bytecode for all the examples:</p> <pre><code>cd bpfman/examples/\nmake generate\n</code></pre> <p>OR to generate the bytecode for a single example (XDP in this case):</p> <pre><code>cd bpfman/examples/go-xdp-counter/\ngo generate\n</code></pre> <p>The preferred method for building the container image is to use the <code>bpfman image build</code> command. See bpfman image build in the CLI Guide for more details.</p> <pre><code>cd bpfman/examples/go-xdp-counter/\nbpfman image build -f ../../Containerfile.bytecode -t quay.io/$QUAY_USER/go-xdp-counter-bytecode:test -b bpf_x86_bpfel.o\n</code></pre> <p>The examples Makefile has commands to build all the example images if needed. See Locally Build Example Container Images for more details.</p> <p><code>bpfman</code> currently does not provide a method for pre-loading bytecode images (see issue #603), so push the bytecode image to an image repository.</p> <p>For example:</p> <pre><code>docker login quay.io\ndocker push quay.io/$QUAY_USER/go-xdp-counter-bytecode:test\n</code></pre>"},{"location":"getting-started/example-bpf/#running-examples","title":"Running Examples","text":"<p>Below are some examples of how to run the bpfman examples on a host where bpfman is already installed.</p> <pre><code>cd bpfman/examples/go-xdp-counter/\nsudo ./go-xdp-counter -iface &lt;INTERNET INTERFACE NAME&gt;\n</code></pre> <p>or (NOTE: TC programs also require a direction, ingress or egress)</p> <pre><code>cd bpfman/examples/go-tc-counter/\nsudo ./go-tc-counter -direction ingress -iface &lt;INTERNET INTERFACE NAME&gt;\n</code></pre> <p>or</p> <pre><code>cd bpfman/examples/go-tracepoint-counter/\nsudo ./go-tracepoint-counter\n</code></pre> <p>bpfman can load eBPF bytecode from a container image built following the spec described in eBPF Bytecode Image Specifications.</p> <p>To use the container image, pass the URL to the userspace program:</p> <pre><code>sudo ./go-xdp-counter -iface eno3 -image quay.io/bpfman-bytecode/go-xdp-counter:latest\n2022/12/02 16:28:32 Using Input: Interface=eno3 Priority=50 Source=quay.io/bpfman-bytecode/go-xdp-counter:latest\n2022/12/02 16:28:34 Program registered with id 6223\n2022/12/02 16:28:37 4 packets received\n2022/12/02 16:28:37 580 bytes received\n\n2022/12/02 16:28:40 4 packets received\n2022/12/02 16:28:40 580 bytes received\n\n^C2022/12/02 16:28:42 Exiting...\n2022/12/02 16:28:42 Unloading Program: 6223\n</code></pre> <p>Or to run with the privately built bytecode container image:</p> <pre><code>sudo ./go-xdp-counter -iface eno3 -image quay.io/$QUAY_USER/go-xdp-counter-bytecode:test\n2022/12/02 16:38:44 Using Input: Interface=eno3 Priority=50 Source=quay.io/$QUAY_USER/go-xdp-counter-bytecode:test\n2022/12/02 16:38:45 Program registered with id 6225\n2022/12/02 16:38:48 4 packets received\n2022/12/02 16:38:48 580 bytes received\n\n2022/12/02 16:38:51 4 packets received\n2022/12/02 16:38:51 580 bytes received\n\n^C2022/12/02 16:38:51 Exiting...\n2022/12/02 16:38:51 Unloading Program: 6225\n</code></pre>"},{"location":"getting-started/launching-bpfman/","title":"Launching bpfman","text":"<p>The most basic way to deploy bpfman is to run it directly on a host system. First <code>bpfman</code> needs to be built and then started.</p>"},{"location":"getting-started/launching-bpfman/#build-bpfman","title":"Build bpfman","text":"<p>Perform the following steps to build <code>bpfman</code>. If this is your first time using bpfman, follow the instructions in Setup and Building bpfman to setup the prerequisites for building. To avoid installing the dependencies and having to build bpfman, consider running bpfman from a packaged release (see Run bpfman From Release Image) or installing the bpfman RPM (see Run bpfman From RPM).</p> <pre><code>cd bpfman/\ncargo build\n</code></pre>"},{"location":"getting-started/launching-bpfman/#install-and-start-bpfman","title":"Install and Start bpfman","text":"<p>Run the following command to copy the <code>bpfman</code> CLI and <code>bpfman-rpc</code> binaries to <code>/usr/sbin/</code> and copy <code>bpfman.socket</code> and <code>bpfman.service</code> files to <code>/usr/lib/systemd/system/</code>. This option will also enable and start the systemd services:</p> <pre><code>cd bpfman/\nsudo ./scripts/setup.sh install\n</code></pre> <p><code>bpfman</code> CLI is now in $PATH and can be used to load, attach, view and unload eBPF programs.</p> <pre><code>sudo bpfman load image --image-url quay.io/bpfman-bytecode/xdp_pass:latest \\\n     --programs xdp:pass --application XdpPassProgram\n</code></pre> <pre><code>sudo bpfman attach 63661 xdp --iface eno3 --priority 35\n</code></pre> <pre><code>sudo bpfman list programs --application XdpPassProgram\n Program ID  Application     Type  Function Name  Links\n 63661       XdpPassProgram  xdp   pass           (1) 1301256968\n</code></pre> <pre><code>sudo bpfman unload 63661\n</code></pre> <p><code>bpfman</code> CLI is a Rust program that calls the <code>bpfman</code> library directly. To view logs while running <code>bpfman</code> CLI commands, prepend <code>RUST_LOG=info</code> to each command (see Logging for more details):</p> <pre><code>sudo RUST_LOG=info bpfman list programs\n[INFO  bpfman::utils] Has CAP_BPF: true\n[INFO  bpfman::utils] Has CAP_SYS_ADMIN: true\n Program ID  Application     Type        Function Name    Links\n</code></pre> <p>The examples (see Deploying Example eBPF Programs On Local Host) are Go based programs, so they are building and sending RPC messages to the rust based binary <code>bpfman-rpc</code>, which in turn calls the <code>bpfman</code> library.</p> <pre><code>cd bpfman/examples/go-xdp-counter/\ngo run -exec sudo . -iface eno3\n</code></pre> <p>To view bpfman logs for RPC based applications, including all the provided examples, use <code>journalctl</code>:</p> <pre><code>sudo journalctl -f -u bpfman.service -u bpfman.socket\n:\n  &lt;RUN \"go run -exec sudo . -iface eno3\"&gt;\nAug 26 18:03:54 server-calvin bpfman-rpc[2401725]: Using a Unix socket from systemd\nAug 26 18:03:54 server-calvin bpfman-rpc[2401725]: Using inactivity timer of 15 seconds\nAug 26 18:03:54 server-calvin bpfman-rpc[2401725]: Listening on /run/bpfman-sock/bpfman.sock\nAug 26 18:03:54 server-calvin bpfman-rpc[2401725]: Has CAP_BPF: true\nAug 26 18:03:54 server-calvin bpfman-rpc[2401725]: Has CAP_SYS_ADMIN: true\nAug 26 18:03:54 server-calvin bpfman-rpc[2401725]: Starting Cosign Verifier, downloading data from Sigstore TUF repository\nAug 26 18:03:55 server-calvin bpfman-rpc[2401725]: Loading program bytecode from file: /home/$USER/src/bpfman/bpfman/examples/go-xdp-counter/bpf_x86_bpfel.o\nAug 26 18:03:57 server-calvin bpfman-rpc[2401725]: The bytecode image: quay.io/bpfman/xdp-dispatcher:latest is signed\nAug 26 18:03:57 server-calvin bpfman-rpc[2401725]: Added xdp program with name: xdp_stats and id: 53919\nAug 26 18:04:09 server-calvin bpfman-rpc[2401725]: Shutdown Unix Handler /run/bpfman-sock/bpfman.sock```\n</code></pre>"},{"location":"getting-started/launching-bpfman/#additional-notes","title":"Additional Notes","text":"<p>To update the configuration settings associated with running <code>bpfman</code> as a service, edit the service configuration files:</p> <pre><code>sudo vi /usr/lib/systemd/system/bpfman.socket\nsudo vi /usr/lib/systemd/system/bpfman.service\nsudo systemctl daemon-reload\n</code></pre> <p>If <code>bpfman</code> CLI or <code>bpfman-rpc</code> is rebuilt, the following command can be run to install the update binaries without tearing down <code>bpfman</code>. The services are automatically restarted.</p> <pre><code>sudo ./scripts/setup.sh reinstall\n</code></pre> <p>To unwind all the changes, stop <code>bpfman</code> and remove all related files from the system, run the following script:</p> <pre><code>sudo ./scripts/setup.sh uninstall\n</code></pre>"},{"location":"getting-started/launching-bpfman/#preferred-method-to-start-bpfman","title":"Preferred Method to Start bpfman","text":"<p>In order to call into the <code>bpfman</code> Library, the calling process must be privileged. In order to load and unload eBPF, the kernel requires a set of powerful capabilities. Long lived privileged processes are more vulnerable to attack than short lived processes. When <code>bpfman-rpc</code> is run as a systemd service, it is leveraging socket activation. This means that it loads a <code>bpfman.socket</code> and <code>bpfman.service</code> file. The socket service is the long lived process, which doesn't have any special permissions. The service that runs <code>bpfman-rpc</code> is only started when there is a request on the socket, and then <code>bpfman-rpc</code> stops itself after an inactivity timeout.</p> <p>Note</p> <p>For security reasons, it is recommended to run <code>bpfman-rpc</code> as a systemd service when running on a local host. For local development, some may find it useful to run <code>bpfman-rpc</code> as a long lived process.</p> <p>When run as a systemd service, the set of linux capabilities are limited to only the required set. If permission errors are encountered, see Linux Capabilities for help debugging.</p>"},{"location":"getting-started/operator-quick-start/","title":"Deploying the bpfman-operator","text":"<p>The <code>bpfman-operator</code> repository exists in order to deploy and manage bpfman within a Kubernetes cluster. This operator was built utilizing some great tooling provided by the operator-sdk library. A great first step in understanding some of the functionality can be to just run <code>make help</code>.</p>"},{"location":"getting-started/operator-quick-start/#deploy-bpfman-operation","title":"Deploy bpfman Operation","text":"<p>The <code>bpfman-operator</code> is running as a Deployment with a ReplicaSet of one. It runs on the control plane and is composed of the containers <code>bpfman-operator</code> and <code>kube-rbac-proxy</code>. The operator is responsible for launching the bpfman Daemonset, which runs on every node. The bpfman Daemonset is composed of the containers <code>bpfman</code>, <code>bpfman-agent</code>, and <code>node-driver-registrar</code>.</p> <p>Described below are two ways to deploy bpfman in a Kubernetes cluster:</p> <ul> <li>Deploy Locally via KIND: Easiest way to deploy bpfman in a Kubernetes cluster   and great for testing.</li> <li>Deploy To Openshift Cluster: Special steps are needed to deploy on an   Openshift cluster because SELinux is enable.</li> </ul>"},{"location":"getting-started/operator-quick-start/#deploy-locally-via-kind","title":"Deploy Locally via KIND","text":"<p>After reviewing the possible make targets it's quick and easy to get bpfman deployed locally on your system via a KIND cluster with:</p> <pre><code>cd bpfman-operator\nmake run-on-kind\n</code></pre> <p>Note</p> <p>By default, bpfman-operator deploys bpfman with CSI enabled. CSI requires Kubernetes v1.26 due to a PR (kubernetes/kubernetes#112597) that addresses a gRPC Protocol Error that was seen in the CSI client code and it doesn't appear to have been backported. It is recommended to install kind v0.20.0 or later.</p>"},{"location":"getting-started/operator-quick-start/#deploy-to-openshift-cluster","title":"Deploy To Openshift Cluster","text":"<p>The recommended way of deploying bpfman to an OpenShift cluster is via the OpenShift Console and using Operator Hub. This is described in OperatorHub via OpenShift Console. For other options, see Deploy To Existing Cluster.</p>"},{"location":"getting-started/operator-quick-start/#api-types-overview","title":"API Types Overview","text":"<p>Refer to  api-spec.md for a more detailed description of all the bpfman Kubernetes API types.</p>"},{"location":"getting-started/operator-quick-start/#cluster-scoped-versus-namespaced-scoped-crds","title":"Cluster Scoped Versus Namespaced Scoped CRDs","text":"<p>For security reasons, cluster admins may want to limit certain applications to only loading eBPF programs within a given namespace. To provide these tighter controls on eBPF program loading, some of the bpfman Custom Resource Definitions (CRDs) are Namespace scoped. Not all eBPF programs make sense to be namespaced scoped. The namespaced scoped CRDs use the \"&lt;ProgramType&gt;NsProgram\" identifier and cluster scoped CRDs to use \"&lt;ProgramType&gt;Program\" identifier.</p>"},{"location":"getting-started/operator-quick-start/#multiple-program-crds","title":"Multiple Program CRDs","text":"<p>The multiple <code>*Program</code> CRDs are the bpfman Kubernetes API objects most relevant to users and can be used to understand clusterwide state for an eBPF program. It's designed to express how, and where eBPF programs are to be deployed within a Kubernetes cluster. Currently bpfman supports:</p> <ul> <li><code>fentryProgram</code></li> <li><code>fexitProgram</code></li> <li><code>kprobeProgram</code></li> <li><code>tcProgram</code> and <code>tcNsProgram</code></li> <li><code>tcxProgram</code> and <code>tcxNsProgram</code></li> <li><code>tracepointProgram</code></li> <li><code>uprobeProgram</code> and <code>uprobeNsProgam</code></li> <li><code>xdpProgram</code> and <code>xdpNsProgram</code></li> </ul> <p>There is also the <code>bpfApplication</code> and <code>bpfNsApplication</code> CRDs, which are designed for managing eBPF programs at an application level within a Kubernetes cluster. These CRD allows Kubernetes users to define which eBPF programs are essential for an application's operations and specify how these programs should be deployed across the cluster. With cluster scoped variant (<code>bpfApplication</code>), any variation of the cluster scoped eBPF programs can be loaded. With namespace scoped variant (<code>bpfNsApplication</code>), any variation of the namespace scoped eBPF programs can be loaded.</p>"},{"location":"getting-started/operator-quick-start/#bpfprogram-and-bpfnsprogram-crd","title":"BpfProgram and BpfNsProgram CRD","text":"<p>The <code>BpfProgram</code> and  <code>BpfNsProgram</code> CRDs are used internally by the bpfman-deployment to keep track of per node bpfman state such as map pin points, and to report node specific errors back to the user. Kubernetes users/controllers are only allowed to view these objects, NOT create or edit them.</p> <p>Applications wishing to use bpfman to deploy/manage their eBPF programs in Kubernetes will make use of this object to find references to the bpfMap pin points (<code>spec.maps</code>) in order to configure their eBPF programs.</p>"},{"location":"getting-started/operator-quick-start/#deploy-an-ebpf-program-to-the-cluster","title":"Deploy an eBPF Program to the cluster","text":"<p>There are sample yamls for each of the support program type in the bpfman-operator/config/samples directory.</p>"},{"location":"getting-started/operator-quick-start/#deploy-cluster-scoped-sample","title":"Deploy Cluster Scoped Sample","text":"<p>Any of the cluster scoped samples can be applied as is. To test the deployment simply deploy one of the sample <code>xdpPrograms</code>:</p> <pre><code>cd bpfman-operator/\nkubectl apply -f config/samples/bpfman.io_v1alpha1_xdp_pass_xdpprogram.yaml\n</code></pre> <p>If loading of the XDP Program to the selected nodes was successful it will be reported back to the user via the <code>xdpProgram</code>'s status field:</p> <pre><code>$ kubectl get xdpprogram xdp-pass-all-nodes -o yaml\napiVersion: bpfman.io/v1alpha1\nkind: XdpProgram\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"bpfman.io/v1alpha1\",\"kind\":\"XdpProgram\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/name\":\"xdpprogram\"},\"name\":\"xdp-pass-all-nodes\"},\"spec\":{\"bpffunctionname\":\"pass\",\"bytecode\":{\"image\":{\"url\":\"quay.io/bpfman-bytecode/xdp_pass:latest\"}},\"globaldata\":{\"GLOBAL_u32\":[13,12,11,10],\"GLOBAL_u8\":[1]},\"interfaceselector\":{\"primarynodeinterface\":true},\"nodeselector\":{},\"priority\":0}}\n  creationTimestamp: \"2023-11-07T19:16:39Z\"\n  finalizers:\n  - bpfman.io.operator/finalizer\n  generation: 2\n  labels:\n    app.kubernetes.io/name: xdpprogram\n  name: xdp-pass-all-nodes\n  resourceVersion: \"157187\"\n  uid: 21c71a61-4e73-44eb-9b49-07af2866d25b\nspec:\n  bpffunctionname: pass\n  bytecode:\n    image:\n      imagepullpolicy: IfNotPresent\n      url: quay.io/bpfman-bytecode/xdp_pass:latest\n  globaldata:\n    GLOBAL_u8: AQ==\n    GLOBAL_u32: DQwLCg==\n  interfaceselector:\n    primarynodeinterface: true\n  mapownerselector: {}\n  nodeselector: {}\n  priority: 0\n  proceedon:\n  - pass\n  - dispatcher_return\nstatus:\n  conditions:\n  - lastTransitionTime: \"2023-11-07T19:16:42Z\"\n    message: bpfProgramReconciliation Succeeded on all nodes\n    reason: ReconcileSuccess\n    status: \"True\"\n    type: ReconcileSuccess\n</code></pre> <p>To see information in listing form simply run:</p> <pre><code>$ kubectl get xdpprogram -o wide\nNAME                 BPFFUNCTIONNAME   NODESELECTOR   PRIORITY   INTERFACESELECTOR               PROCEEDON\nxdp-pass-all-nodes   pass              {}             0          {\"primarynodeinterface\":true}   [\"pass\",\"dispatcher_return\"]\n</code></pre> <p>To view each attachment point on each node, use the <code>bpfProgram</code> object:</p> <pre><code>$ kubectl get bpfprograms\nNAME                          TYPE   STATUS         AGE\nxdp-pass-all-nodes-f3def00d   xdp    bpfmanLoaded   56s\n\n\n$ kubectl get bpfprograms xdp-pass-all-nodes-f3def00d -o yaml\napiVersion: bpfman.io/v1alpha1\nkind: BpfProgram\nmetadata:\n  annotations:\n    bpfman.io.xdpprogramcontroller/interface: eth0\n    bpfman.io/ProgramId: \"26577\"\n    bpfman.io/bpfProgramAttachPoint: eth0\n  creationTimestamp: \"2024-12-18T22:26:55Z\"\n  finalizers:\n  - bpfman.io.xdpprogramcontroller/finalizer\n  generation: 1\n  labels:\n    bpfman.io/appProgramId: \"\"\n    bpfman.io/ownedByProgram: xdp-pass-all-nodes\n    kubernetes.io/hostname: bpfman-deployment-control-plane\n  name: xdp-pass-all-nodes-f3def00d\n  ownerReferences:\n  - apiVersion: bpfman.io/v1alpha1\n    blockOwnerDeletion: true\n    controller: true\n    kind: XdpProgram\n    name: xdp-pass-all-nodes\n    uid: 7685a5b6-a626-4483-8c20-06b29643a2a8\n  resourceVersion: \"8430\"\n  uid: 83c5a80d-2dca-46ce-806b-6fdf7bde901f\nspec:\n  type: xdp\nstatus:\n  conditions:\n  - lastTransitionTime: \"2024-12-18T22:27:11Z\"\n    message: Successfully loaded bpfProgram\n    reason: bpfmanLoaded\n    status: \"True\"\n    type: Loaded\n</code></pre>"},{"location":"getting-started/operator-quick-start/#deploy-namespace-scoped-sample","title":"Deploy Namespace Scoped Sample","text":"<p>The namespace scoped samples need a namespace and pods to attach to. A yaml has been created that will create a <code>Namespace</code> called \"acme\" (see bpfman-operator/hack/namespace_scoped.yaml). The reason for namespace scoped CRDs is to limit an application or user to a namespace. To this end, this yaml also creates a limited <code>ServiceAccount</code>, <code>Role</code>, <code>RoleBinding</code> and <code>Secret</code>.</p> <pre><code>cd bpfman-operator\nkubectl apply -f hack/namespace_scoped.yaml \n  namespace/acme created\n  serviceaccount/test-account created\n  role.rbac.authorization.k8s.io/test-account created\n  rolebinding.rbac.authorization.k8s.io/test-account created\n  secret/test-account-token created\n</code></pre> <p>To create a <code>kubeconfig</code> file that limits access to the created namespace, use the script  bpfman-operator/hack/namespace_scoped.sh. The script needs to know the name of the <code>Cluster</code>, <code>Namespace</code>, <code>Service Account</code> and <code>Secret</code>. The script defaults these fields to what is currently in  bpfman-operator/hack/namespace_scoped.yaml. However, if a file is passed to the script, it will look for the <code>Secret</code> object and attempt to extract the values.  This can be used if the names are changed or a different yaml file is used. The output of the script is the contents of a <code>kubeconfig</code>. This can be printed to the console or redirected to a file.</p> <pre><code>./hack/namespace_scoped.sh hack/namespace_scoped.yaml &gt; /tmp/kubeconfig \n</code></pre> <p>To use the <code>kubeconfig</code> file, select the session to limit access in and run:</p> <pre><code>export KUBECONFIG=/tmp/kubeconfig\n</code></pre> <p>From within this limited access session, a sample <code>nginx</code> deployment can be created in the same namespace using bpfman-operator/hack/namespace_scoped.yaml.</p> <pre><code>kubectl apply -f hack/nginx-deployment.yaml\n  deployment.apps/nginx-deployment created\n</code></pre> <p>Finally, load any of the namespaced samples from bpfman-operator/config/samples. They are of the format: <code>bpfman.io_v1alpha1_*nsprogram.yaml</code></p> <pre><code>kubectl apply -f config/samples/bpfman.io_v1alpha1_tc_pass_tcnsprogram.yaml \n  tcnsprogram.bpfman.io/tc-containers created\n</code></pre> <p>The status for each namespaced program is reported via the *NsProgram status field and further information can be seen in the resulting BpfNsProgram CRDs. As an example, the following commands display the information of the TC program loaded in the acme namespace with the command above.</p> <pre><code>$ kubectl get tcnsprograms\nNAME            BPFFUNCTIONNAME   NODESELECTOR   STATUS\ntc-containers   pass              {}             ReconcileSuccess\n\n\n$ kubectl get tcnsprograms tc-containers -o yaml\napiVersion: bpfman.io/v1alpha1\nkind: TcNsProgram\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"bpfman.io/v1alpha1\",\"kind\":\"TcNsProgram\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/name\":\"tcnsprogram\"},\"name\":\"tc-containers\",\"namespace\":\"acme\"},\"spec\":{\"bpffunctionname\":\"pass\",\"bytecode\":{\"image\":{\"url\":\"quay.io/bpfman-bytecode/tc_pass:latest\"}},\"containers\":{\"containernames\":[\"nginx\"],\"pods\":{\"matchLabels\":{\"app\":\"nginx\"}}},\"direction\":\"ingress\",\"globaldata\":{\"GLOBAL_u32\":[13,12,11,10],\"GLOBAL_u8\":[1]},\"interfaceselector\":{\"interfaces\":[\"eth0\"]},\"nodeselector\":{},\"priority\":0}}\n  creationTimestamp: \"2024-12-18T22:22:52Z\"\n  finalizers:\n  - bpfman.io.operator/finalizer\n  generation: 2\n  labels:\n    app.kubernetes.io/name: tcnsprogram\n  name: tc-containers\n  namespace: acme\n  resourceVersion: \"7993\"\n  uid: 49291f28-49dc-4486-9119-af7c31569de3\nspec:\n  bpffunctionname: pass\n  bytecode:\n    image:\n      imagepullpolicy: IfNotPresent\n      url: quay.io/bpfman-bytecode/tc_pass:latest\n  containers:\n    containernames:\n    - nginx\n    pods:\n      matchLabels:\n        app: nginx\n  direction: ingress\n  globaldata:\n    GLOBAL_u8: AQ==\n    GLOBAL_u32: DQwLCg==\n  interfaceselector:\n    interfaces:\n    - eth0\n  mapownerselector: {}\n  nodeselector: {}\n  priority: 0\n  proceedon:\n  - pipe\n  - dispatcher_return\nstatus:\n  conditions:\n  - lastTransitionTime: \"2024-12-18T22:23:11Z\"\n    message: bpfProgramReconciliation Succeeded on all nodes\n    reason: ReconcileSuccess\n    status: \"True\"\n    type: ReconcileSuccess\n</code></pre> <p>To view each attachment point on each node, use the <code>bpfNsProgram</code> object:</p> <pre><code>$ kubectl get bpfnsprograms\nNAME                     TYPE   STATUS         AGE\ntc-containers-6494dbed   tc     bpfmanLoaded   12m\ntc-containers-7dcde5ab   tc     bpfmanLoaded   12m\n\n\n$ kubectl get bpfnsprograms tc-containers-6494dbed -o yaml\napiVersion: bpfman.io/v1alpha1\nkind: BpfNsProgram\nmetadata:\n  annotations:\n    bpfman.io.tcnsprogramcontroller/containerpid: \"3256\"\n    bpfman.io.tcnsprogramcontroller/interface: eth0\n    bpfman.io/ProgramId: \"26575\"\n    bpfman.io/bpfProgramAttachPoint: eth0-ingress-nginx-deployment-57d84f57dc-lgc6f-nginx\n  creationTimestamp: \"2024-12-18T22:23:08Z\"\n  finalizers:\n  - bpfman.io.tcnsprogramcontroller/finalizer\n  generation: 1\n  labels:\n    bpfman.io/appProgramId: \"\"\n    bpfman.io/ownedByProgram: tc-containers\n    kubernetes.io/hostname: bpfman-deployment-control-plane\n  name: tc-containers-6494dbed\n  namespace: acme\n  ownerReferences:\n  - apiVersion: bpfman.io/v1alpha1\n    blockOwnerDeletion: true\n    controller: true\n    kind: TcNsProgram\n    name: tc-containers\n    uid: 49291f28-49dc-4486-9119-af7c31569de3\n  resourceVersion: \"7992\"\n  uid: c913eea4-71e0-4d5d-b664-078abac36c40\nspec:\n  type: tc\nstatus:\n  conditions:\n  - lastTransitionTime: \"2024-12-18T22:23:11Z\"\n    message: Successfully loaded bpfProgram\n    reason: bpfmanLoaded\n    status: \"True\"\n    type: Loaded\n</code></pre>"},{"location":"getting-started/overview/","title":"bpfman Overview","text":"<p>Core bpfman is a library written in Rust and published as a Crate via crates.io. The <code>bpfman</code> library leverages the <code>aya</code> library to manage eBPF programs. Applications written in Rust can import the <code>bpfman</code> library and call the bpfman APIs directly. An example of a Rust based application leveraging the <code>bpfman</code> library is the <code>bpfman</code> CLI, which is a Rust based binary used to provision bpfman from a Linux command prompt (see CLI Guide).</p> <p>For applications written in other languages, bpfman provides <code>bpfman-rpc</code>, a Rust based bpfman RPC server binary. Non-Rust applications can send a RPC message to the server, which translate the RPC request into a bpfman library call.</p> <p></p>"},{"location":"getting-started/overview/#local-host-deployment","title":"Local Host Deployment","text":"<p>When deploying <code>bpfman</code> on a local server, the <code>bpfman-rpc</code> binary runs as a systemd service that uses socket activation to start <code>bpfman-rpc</code> only when there is a RPC message to process. More details are provided in Deploying Example eBPF Programs On Local Host.</p>"},{"location":"getting-started/overview/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>When deploying <code>bpfman</code> in a Kubernetes deployment, <code>bpfman-agent</code>, <code>bpfman-rpc</code>, and the <code>bpfman</code> library are packaged in a container. When the container starts, <code>bpfman-rpc</code> is started as a long running process. <code>bpfman-agent</code> listens to the KubeAPI Server and send RPC requests to <code>bpfman-rpc</code>, which in turn calls the <code>bpfman</code> library to manage eBPF programs on a given node.</p> <p></p> <p>More details provided in Deploying Example eBPF Programs On Kubernetes.</p>"},{"location":"getting-started/running-release/","title":"Run bpfman From Release Image","text":"<p>This section describes how to deploy <code>bpfman</code> from a given release. See Releases for the set of bpfman releases.</p> <p>Note</p> <p>Instructions for interacting with bpfman change from release to release, so reference release specific documentation. For example:</p> <p>https://bpfman.io/v0.5.6/getting-started/running-release/</p> <p>Jump to the Setup and Building bpfman section for help building from the latest code or building from a release branch.</p> <p>Start bpfman-rpc contains more details on the different modes to run <code>bpfman</code> in on the host. Use Run using an rpm for deploying a released version of <code>bpfman</code> from an rpm as a systemd service and then use Deploying Example eBPF Programs On Local Host for further information on how to test and interact with <code>bpfman</code>.</p> <p>Deploying the bpfman-operator contains more details on deploying <code>bpfman</code> in a Kubernetes deployment and Deploying Example eBPF Programs On Kubernetes contains more details on interacting with <code>bpfman</code> running in a Kubernetes deployment. Use Deploying Release Version of the bpfman-operator below for deploying released version of <code>bpfman</code> in Kubernetes and then use the links above for further information on how to test and interact with <code>bpfman</code>.</p>"},{"location":"getting-started/running-release/#run-as-a-long-lived-process","title":"Run as a Long Lived Process","text":"<pre><code>export BPFMAN_REL=0.5.6\nmkdir -p $SRC_DIR/bpfman-${BPFMAN_REL}/; cd $SRC_DIR/bpfman-${BPFMAN_REL}/\nwget https://github.com/bpfman/bpfman/releases/download/v${BPFMAN_REL}/bpfman-linux-x86_64.tar.gz\ntar -xzvf bpfman-linux-x86_64.tar.gz; rm bpfman-linux-x86_64.tar.gz\n\n$ tree\n.\n\u251c\u2500\u2500 bpf-log-exporter\n\u251c\u2500\u2500 bpfman\n\u251c\u2500\u2500 bpfman-ns\n\u251c\u2500\u2500 bpfman-rpc\n\u2514\u2500\u2500 bpf-metrics-exporter\n</code></pre> <p>To deploy <code>bpfman-rpc</code>:</p> <pre><code>sudo RUST_LOG=info ./bpfman-rpc --timeout=0\n[INFO  bpfman::utils] Has CAP_BPF: true\n[INFO  bpfman::utils] Has CAP_SYS_ADMIN: true\n[INFO  bpfman_rpc::serve] Using no inactivity timer\n[INFO  bpfman_rpc::serve] Using default Unix socket\n[INFO  bpfman_rpc::serve] Listening on /run/bpfman-sock/bpfman.sock\n:\n</code></pre> <p>To use the CLI:</p> <pre><code>sudo ./bpfman list programs\n Program ID  Application    Type        Function Name    Links\n</code></pre> <p>Continue in Deploying Example eBPF Programs On Local Host if desired.</p>"},{"location":"getting-started/running-release/#deploying-release-version-of-the-bpfman-operator","title":"Deploying Release Version of the bpfman-operator","text":"<p>The quickest solution for running <code>bpfman</code> in a Kubernetes deployment is to run a Kubernetes KIND Cluster:</p> <pre><code>kind create cluster --name=test-bpfman\n</code></pre> <p>Next, deploy the bpfman CRDs:</p> <pre><code>export BPFMAN_REL=0.5.6\nkubectl apply -f  https://github.com/bpfman/bpfman-operator/releases/download/v${BPFMAN_REL}/bpfman-crds-install.yaml\n</code></pre> <p>Next, deploy the <code>bpfman-operator</code>, which will also deploy the <code>bpfman-daemon</code>, which contains <code>bpfman-rpc</code>, <code>bpfman</code> Library and <code>bpfman-agent</code>:</p> <pre><code>kubectl apply -f https://github.com/bpfman/bpfman-operator/releases/download/v${BPFMAN_REL}/bpfman-operator-install-v${BPFMAN_REL}.yaml\n</code></pre> <p>Finally, deploy an example eBPF program.</p> <pre><code>kubectl apply -f https://github.com/bpfman/bpfman/releases/download/v${BPFMAN_REL}/go-xdp-counter-install-v${BPFMAN_REL}.yaml\n</code></pre> <p>There are other example programs in the Releases page.</p> <p>Continue in Deploying the bpfman-operator or Deploying Example eBPF Programs On Kubernetes if desired. Keep in mind that prior to v0.4.0, <code>bpfman</code> was released as <code>bpfd</code>. So follow the release specific documentation.</p> <p>Use the following command to teardown the cluster:</p> <pre><code>kind delete cluster -n test-bpfman\n</code></pre>"},{"location":"getting-started/running-rpm/","title":"Run bpfman From RPM","text":"<p>This section describes how to deploy <code>bpfman</code> from an RPM. RPMs are generated each time a Pull Request is merged in github for Fedora 38, 39 and Rawhide (see Install Prebuilt RPM below). RPMs can also be built locally from a Fedora server (see Build RPM Locally below).</p>"},{"location":"getting-started/running-rpm/#install-prebuilt-rpm","title":"Install Prebuilt RPM","text":"<p>This section describes how to install an RPM built automatically by the Packit Service. The Packit Service builds RPMs for each Pull Request merged.</p>"},{"location":"getting-started/running-rpm/#packit-service-prerequisites","title":"Packit Service Prerequisites","text":"<p>To install an RPM generated by the Packit Service, the following packages need to be installed:</p> <p><code>dnf</code> based OS:</p> <pre><code>sudo dnf install -y dnf-plugins-core\n</code></pre> <p>To install officially released versions:</p> <pre><code>sudo dnf copr enable @ebpf-sig/bpfman\n</code></pre> <p>To install nightly builds:</p> <pre><code>sudo dnf copr enable @ebpf-sig/bpfman-next\n</code></pre> <p>Note</p> <p>If both the <code>bpfman</code> and <code>bpfman-next</code> copr repos are enabled, <code>dnf</code> will automatically pull from <code>bpfman-next</code>. Either repo can be disabled. For example, to disable <code>bpfman-next</code> run:</p> <pre><code>sudo dnf copr disable @ebpf-sig/bpfman-next\n</code></pre>"},{"location":"getting-started/running-rpm/#install-rpm-from-packit-service","title":"Install RPM From Packit Service","text":"<p>To load a RPM from a specific commit (@ebpf-sig/bpfman-next needs to be enabled instead of @ebpf-sig/bpfman), find the commit from bpfman commits, and click on the green check showing a given Pull Request was verified. At the bottom of the list of checks are the RPM builds, click on the <code>details</code>, and follow the Packit Dashboard link to the <code>Copr Build Results</code>. Then install the given RPM:</p> <pre><code>sudo dnf install -y bpfman-0.4.0~dev-1.20240117143006587102.main.191.gda44a71.fc38.x86_64\n</code></pre> <p><code>bpfman</code> is now installed but not running. To start <code>bpfman</code>:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable bpfman.socket\nsudo systemctl start bpfman.socket\n</code></pre> <p>Verify <code>bpfman</code> is installed and running:</p> <pre><code>$ sudo systemctl status bpfman.socket\n\u25cf bpfman.socket - bpfman API Socket\n     Loaded: loaded (/usr/lib/systemd/system/bpfman.socket; enabled; preset: disabled)\n     Active: active (listening) since Thu 2024-01-18 21:19:29 EST; 5s ago\n   Triggers: \u25cf bpfman.service\n     Listen: /run/bpfman-sock/bpfman.sock (Stream)\n     CGroup: /system.slice/bpfman.socket\n:\n\n$ sudo systemctl status bpfman.service\n\u25cb bpfman.service - Run bpfman as a service\n     Loaded: loaded (/usr/lib/systemd/system/bpfman.service; static)\n    Drop-In: /usr/lib/systemd/system/service.d\n             \u2514\u250010-timeout-abort.conf\n     Active: inactive (dead)\nTriggeredBy: \u25cf bpfman.socket\n:\n\n$ sudo bpfman list programs\n Program ID  Application    Type        Function Name    Links\n</code></pre>"},{"location":"getting-started/running-rpm/#uninstall-given-rpm","title":"Uninstall Given RPM","text":"<p>To determine the RPM that is currently loaded:</p> <pre><code>$ sudo rpm -qa | grep bpfman\nbpfman-0.4.0~dev-1.20240117143006587102.main.191.gda44a71.fc39.x86_64\n</code></pre> <p>To stop bpfman and uninstall the RPM:</p> <pre><code>sudo systemctl stop bpfman.socket\nsudo systemctl disable bpfman.socket\n\nsudo dnf erase -y bpfman-0.4.0~dev-1.20240117143006587102.main.191.gda44a71.fc39.x86_64\n\nsudo systemctl daemon-reload\n</code></pre>"},{"location":"getting-started/running-rpm/#build-rpm-locally","title":"Build RPM Locally","text":"<p>This section describes how to build and install an RPM locally.</p>"},{"location":"getting-started/running-rpm/#local-build-prerequisites","title":"Local Build Prerequisites","text":"<p>To build locally, the following packages need to be installed:</p> <p><code>dnf</code> based OS:</p> <pre><code>sudo dnf install packit\nsudo dnf install cargo-rpm-macros\n</code></pre> <p>Note</p> <p><code>cargo-rpm-macros</code> needs to be version 25 or higher. It appears this is only available on Fedora 37, 38, 39 and Rawhide at the moment.</p>"},{"location":"getting-started/running-rpm/#build-locally","title":"Build Locally","text":"<p>To build locally, run the following command:</p> <pre><code>packit build locally\n</code></pre> <p>This will generate several RPMs in a <code>x86_64/</code> directory:</p> <pre><code>$ ls x86_64/\nbpfman-0.4.1-1.20240521101705214906.main.19.b47994a3.fc39.x86_64.rpm\nbpfman-debuginfo-0.4.1-1.20240521101705214906.main.19.b47994a3.fc39.x86_64.rpm\nbpfman-debugsource-0.4.1-1.20240521101705214906.main.19.b47994a3.fc39.x86_64.rpm\n</code></pre> <p>If local RPM builds were previously run on the system, the <code>packit build locally</code> command may fail with something similar to:</p> <pre><code>packit build locally\n2024-05-21 10:00:03.904 base_git.py       INFO   Using user-defined script for ActionName.post_upstream_clone: [['bash', '-c', 'if [[ ! -d /var/tmp/cargo-vendor-filterer ]]; then git clone https://github.com/coreos/cargo-vendor-filterer.git /var/tmp/cargo-vendor-filterer; fi &amp;&amp; cd /var/tmp/cargo-vendor-filterer &amp;&amp; cargo build &amp;&amp; cd - &amp;&amp; cp /var/tmp/cargo-vendor-filterer/target/debug/cargo-vendor-filterer . &amp;&amp; ./cargo-vendor-filterer --format tar.gz --prefix vendor bpfman-bpfman-vendor.tar.gz']]\n2024-05-21 10:00:03.956 logging.py        INFO   error: could not find `Cargo.toml` in `/var/tmp/cargo-vendor-filterer` or any parent directory\n2024-05-21 10:00:03.957 commands.py       ERROR  Command 'bash -c if [[ ! -d /var/tmp/cargo-vendor-filterer ]]; then git clone https://github.com/coreos/cargo-vendor-filterer.git /var/tmp/cargo-vendor-filterer; fi &amp;&amp; cd /var/tmp/cargo-vendor-filterer &amp;&amp; cargo build &amp;&amp; cd - &amp;&amp; cp /var/tmp/cargo-vendor-filterer/target/debug/cargo-vendor-filterer . &amp;&amp; ./cargo-vendor-filterer --format tar.gz --prefix vendor bpfman-bpfman-vendor.tar.gz' failed.\n2024-05-21 10:00:03.957 utils.py          ERROR  Command 'bash -c if [[ ! -d /var/tmp/cargo-vendor-filterer ]]; then git clone https://github.com/coreos/cargo-vendor-filterer.git /var/tmp/cargo-vendor-filterer; fi &amp;&amp; cd /var/tmp/cargo-vendor-filterer &amp;&amp; cargo build &amp;&amp; cd - &amp;&amp; cp /var/tmp/cargo-vendor-filterer/target/debug/cargo-vendor-filterer . &amp;&amp; ./cargo-vendor-filterer --format tar.gz --prefix vendor bpfman-bpfman-vendor.tar.gz' failed.\n</code></pre> <p>To fix, run:</p> <pre><code>sudo rm -rf /var/tmp/cargo-vendor-filterer/\n</code></pre>"},{"location":"getting-started/running-rpm/#install-local-build","title":"Install Local Build","text":"<p>Install the RPM:</p> <pre><code>sudo rpm -i x86_64/bpfman-0.4.1-1.20240521101705214906.main.19.b47994a3.fc39.x86_64.rpm\n</code></pre> <p><code>bpfman</code> is now installed but not running. To start <code>bpfman</code>:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl enable bpfman.socket\nsudo systemctl start bpfman.socket\n</code></pre> <p>Verify <code>bpfman</code> is installed and running:</p> <pre><code>$ sudo systemctl status bpfman.socket\n\u25cf bpfman.socket - bpfman API Socket\n     Loaded: loaded (/usr/lib/systemd/system/bpfman.socket; enabled; preset: disabled)\n     Active: active (listening) since Thu 2024-01-18 21:19:29 EST; 5s ago\n   Triggers: \u25cf bpfman.service\n     Listen: /run/bpfman-sock/bpfman.sock (Stream)\n     CGroup: /system.slice/bpfman.socket\n:\n\n$ sudo systemctl status bpfman.service\n\u25cb bpfman.service - Run bpfman as a service\n     Loaded: loaded (/usr/lib/systemd/system/bpfman.service; static)\n    Drop-In: /usr/lib/systemd/system/service.d\n             \u2514\u250010-timeout-abort.conf\n     Active: inactive (dead)\nTriggeredBy: \u25cf bpfman.socket\n:\n\n$ sudo bpfman list programs\n Program ID  Application    Type        Function Name    Links\n</code></pre>"},{"location":"getting-started/running-rpm/#uninstall-local-build","title":"Uninstall Local Build","text":"<p>To determine the RPM that is currently loaded:</p> <pre><code>$ sudo rpm -qa | grep bpfman\nbpfman-0.4.1-1.20240521101705214906.main.19.b47994a3.fc39.x86_64\n</code></pre> <p>To stop bpfman and uninstall the RPM:</p> <pre><code>sudo systemctl stop bpfman.socket\nsudo systemctl disable bpfman.socket\n\nsudo rpm -e bpfman-0.4.1-1.20240521101705214906.main.19.b47994a3.fc39.x86_64\n\nsudo systemctl daemon-reload\n</code></pre>"},{"location":"getting-started/troubleshooting/","title":"Troubleshooting","text":"<p>This section provides a list of common issues and solutions when working with <code>bpfman</code>.</p>"},{"location":"getting-started/troubleshooting/#xdp","title":"XDP","text":""},{"location":"getting-started/troubleshooting/#xdp-program-fails-to-load","title":"XDP Program Fails to Load","text":"<p>When attempting to load an XDP program and the program fails to load:</p> <pre><code>$ sudo bpfman attach 37568 xdp --iface veth92cd99b --priority 100\nError: status: Aborted, message: \"An error occurred. dispatcher attach failed on interface veth92cd99b: `bpf_link_create` failed\", details: [], metadata: MetadataMap { headers: {\"content-type\": \"application/grpc\", \"date\": \"Tue, 28 Nov 2023 13:37:02 GMT\", \"content-length\": \"0\"} }\n</code></pre> <p>The log may look something like this:</p> <pre><code>Nov 28 08:36:58 ebpf03 bpfman[2081732]: The bytecode image: quay.io/bpfman-bytecode/xdp_pass:latest is signed\nNov 28 08:36:59 ebpf03 bpfman[2081732]: Loading program bytecode from container image: quay.io/bpfman-bytecode/xdp_pass:latest\nNov 28 08:37:01 ebpf03 bpfman[2081732]: The bytecode image: quay.io/bpfman/xdp-dispatcher:v2 is signed\nNov 28 08:37:02 ebpf03 bpfman[2081732]: BPFMAN load error: Error(\n                                            \"dispatcher attach failed on interface veth92cd99b: `bpf_link_create` failed\",\n                                        )\n</code></pre> <p>The issue may be the there is already an external XDP program loaded on the given interface. bpfman allows multiple XDP programs on an interface by loading a <code>dispatcher</code> program which is the XDP program and additional programs are loaded as extensions to the <code>dispatcher</code>. Use <code>bpftool</code> to determine if any programs are already loaded on an interface:</p> <pre><code>$ sudo bpftool net list dev veth92cd99b\nxdp:\nveth92cd99b(32) generic id 8733\n\ntc:\nveth92cd99b(32) clsact/ingress tc_dispatcher id 8922\n\nflow_dissector:\n</code></pre>"},{"location":"governance/CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"governance/CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"governance/CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall   community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of   any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address,   without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"governance/CODE_OF_CONDUCT/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"governance/CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"governance/CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement directly. Maintainers are identified in the MAINTAINERS.md file and their contact information is on their GitHub profile page. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"governance/CODE_OF_CONDUCT/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"governance/CODE_OF_CONDUCT/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"governance/CODE_OF_CONDUCT/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"governance/CODE_OF_CONDUCT/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"governance/CODE_OF_CONDUCT/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"governance/CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p> <p>Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder.</p> <p>For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations.</p>"},{"location":"governance/CONTRIBUTING/","title":"Contributing Guide","text":"<ul> <li>Contributing Guide</li> <li>Ways to Contribute<ul> <li>Come to Meetings</li> </ul> </li> <li>Find an Issue</li> <li>Ask for Help</li> <li>Pull Request Lifecycle</li> <li>Development Environment Setup</li> <li>Signoff Your Commits<ul> <li>DCO</li> </ul> </li> <li>Logical Grouping of Commits</li> <li>Commit message guidelines</li> <li>Test Policy<ul> <li>Unit Tests</li> <li>Integration Tests</li> <li>End-to-End Tests</li> <li>Test Coverage</li> <li>Running Tests Locally</li> </ul> </li> <li>Pull Request Checklist<ul> <li>bpfman Pinned Rust Toolchain</li> <li>bpfman Checklist</li> <li>bpfman-operator Checklist</li> </ul> </li> </ul> <p>Welcome! We are glad that you want to contribute to our project! \ud83d\udc96</p> <p>As you get started, you are in the best position to give us feedback on areas of our project that we need help with including:</p> <ul> <li>Problems found during setting up a new developer environment</li> <li>Gaps in our Quickstart Guide or documentation</li> <li>Bugs in our automation scripts</li> </ul> <p>If anything doesn't make sense, or doesn't work when you run it, please open a bug report and let us know!</p>"},{"location":"governance/CONTRIBUTING/#ways-to-contribute","title":"Ways to Contribute","text":"<p>We welcome many different types of contributions including:</p> <ul> <li>New features</li> <li>Builds, CI/CD</li> <li>Bug fixes</li> <li>Documentation</li> <li>Issue Triage</li> <li>Answering questions on Slack/Mailing List</li> <li>Web design</li> <li>Communications / Social Media / Blog Posts</li> <li>Release management</li> </ul> <p>Not everything happens through a GitHub pull request. Please come to our meetings or contact us and let's discuss how we can work together.</p>"},{"location":"governance/CONTRIBUTING/#come-to-meetings","title":"Come to Meetings","text":"<p>Absolutely everyone is welcome to come to any of our meetings. You never need an invite to join us. In fact, we want you to join us, even if you don\u2019t have anything you feel like you want to contribute. Just being there is enough!</p> <p>You can find out more about our meetings here. You don\u2019t have to turn on your video. The first time you come, introducing yourself is more than enough. Over time, we hope that you feel comfortable voicing your opinions, giving feedback on others\u2019 ideas, and even sharing your own ideas, and experiences.</p>"},{"location":"governance/CONTRIBUTING/#find-an-issue","title":"Find an Issue","text":"<p>We have good first issues for new contributors and help wanted issues suitable for any contributor. good first issue has extra information to help you make your first contribution. help wanted are issues suitable for someone who isn't a core maintainer and is good to move onto after your first pull request.</p> <p>Sometimes there won\u2019t be any issues with these labels. That\u2019s ok! There is likely still something for you to work on. If you want to contribute but you don\u2019t know where to start or can't find a suitable issue, you can reach out to us on Slack and we will be happy to help.</p> <p>Once you see an issue that you'd like to work on, please post a comment saying that you want to work on it. Something like \"I want to work on this\" is fine.</p>"},{"location":"governance/CONTRIBUTING/#ask-for-help","title":"Ask for Help","text":"<p>The best way to reach us with a question when contributing is to ask on:</p> <ul> <li>The original github issue</li> <li>Our Slack channel</li> </ul>"},{"location":"governance/CONTRIBUTING/#pull-request-lifecycle","title":"Pull Request Lifecycle","text":"<p>Pull requests are managed by Mergify.</p> <p>Our process is currently as follows:</p> <ol> <li>When you open a PR a maintainer will automatically be assigned for review</li> <li>Make sure that your PR is passing CI - if you need help with failing checks please feel free to ask!</li> <li>Once it is passing all CI checks, a maintainer will review your PR and you may be asked to make changes.</li> <li>When you have received at least one approval from a maintainer, your PR will be merged automatically.</li> </ol> <p>In some cases, other changes may conflict with your PR. If this happens, you will get notified by a comment in the issue that your PR requires a rebase, and the <code>needs-rebase</code> label will be applied. Once a rebase has been performed, this label will be automatically removed.</p>"},{"location":"governance/CONTRIBUTING/#development-environment-setup","title":"Development Environment Setup","text":"<p>See Setup and Building bpfman</p>"},{"location":"governance/CONTRIBUTING/#signoff-your-commits","title":"Signoff Your Commits","text":""},{"location":"governance/CONTRIBUTING/#dco","title":"DCO","text":"<p>Licensing is important to open source projects. It provides some assurances that the software will continue to be available based under the terms that the author(s) desired. We require that contributors sign off on commits submitted to our project's repositories. The Developer Certificate of Origin (DCO) is a way to certify that you wrote and have the right to contribute the code you are submitting to the project.</p> <p>You sign-off by adding the following to your commit messages. Your sign-off must match the git user and email associated with the commit.</p> <pre><code>This is my commit message\n\nSigned-off-by: Your Name &lt;your.name@example.com&gt;\n</code></pre> <p>Git has a <code>-s</code> command line option to do this automatically:</p> <pre><code>git commit -s -m 'This is my commit message'\n</code></pre> <p>If you forgot to do this and have not yet pushed your changes to the remote repository, you can amend your commit with the sign-off by running</p> <pre><code>git commit --amend -s\n</code></pre>"},{"location":"governance/CONTRIBUTING/#logical-grouping-of-commits","title":"Logical Grouping of Commits","text":"<p>It is a recommended best practice to keep your changes as logically grouped as possible within individual commits. If while you're developing you prefer doing a number of commits that are \"checkpoints\" and don't represent a single logical change, please squash those together before asking for a review. When addressing review comments, please perform an interactive rebase and edit commits directly rather than adding new commits with messages like \"Fix review comments\".</p>"},{"location":"governance/CONTRIBUTING/#commit-message-guidelines","title":"Commit message guidelines","text":"<p>A good commit message should describe what changed and why.</p> <ol> <li> <p>The first line should:</p> </li> <li> <p>contain a short description of the change (preferably 50 characters or less,     and no more than 72 characters)</p> </li> <li>be entirely in lowercase with the exception of proper nouns, acronyms, and     the words that refer to code, like function/variable names</li> <li>be prefixed with the name of the sub crate being changed</li> </ol> <p>Examples:</p> <ul> <li>bpfman: validate program section names</li> <li> <p>bpf: add dispatcher program test slot</p> </li> <li> <p>Keep the second line blank.</p> </li> <li>Wrap all other lines at 72 columns (except for long URLs).</li> <li>If your patch fixes an open issue, you can add a reference to it at the end    of the log. Use the <code>Fixes: #</code> prefix and the issue number. For other    references use <code>Refs: #</code>. <code>Refs</code> may include multiple issues, separated by a    comma.</li> </ul> <p>Examples:</p> <ul> <li><code>Fixes: #1337</code></li> <li><code>Refs: #1234</code></li> </ul> <p>Sample complete commit message:</p> <pre><code>subcrate: explain the commit in one line\n\nBody of commit message is a few lines of text, explaining things\nin more detail, possibly giving some background about the issue\nbeing fixed, etc.\n\nThe body of the commit message can be several paragraphs, and\nplease do proper word-wrap and keep columns shorter than about\n72 characters or so. That way, `git log` will show things\nnicely even when it is indented.\n\nFixes: #1337\nRefs: #453, #154\n</code></pre>"},{"location":"governance/CONTRIBUTING/#test-policy","title":"Test Policy","text":"<p>Testing is a critical part of the development process. All contributions must include tests to verify the functionality of the code. This ensures that the code works as expected and helps prevent future regressions.</p>"},{"location":"governance/CONTRIBUTING/#unit-tests","title":"Unit Tests","text":"<p>Unit tests should cover individual components or functions. They should be fast and isolated from external dependencies.</p>"},{"location":"governance/CONTRIBUTING/#integration-tests","title":"Integration Tests","text":"<p>Integration tests should verify that different components work together as expected. These tests may involve external dependencies and should be run in an environment that closely resembles production.</p>"},{"location":"governance/CONTRIBUTING/#end-to-end-tests","title":"End-to-End Tests","text":"<p>End-to-end tests should simulate real-world scenarios to ensure the entire system works as expected. These tests are typically slower and more complex than unit or integration tests.</p>"},{"location":"governance/CONTRIBUTING/#test-coverage","title":"Test Coverage","text":"<p>We aim for high test coverage across the codebase. While 100% coverage is not always feasible, contributors should strive to cover as much of their code as possible.</p>"},{"location":"governance/CONTRIBUTING/#running-tests-locally","title":"Running Tests Locally","text":"<p>Before submitting a pull request, contributors should run all tests locally to ensure they pass. This includes unit, integration, and end-to-end tests.</p>"},{"location":"governance/CONTRIBUTING/#pull-request-checklist","title":"Pull Request Checklist","text":"<p>When you submit your pull request, or you push new commits to it, our automated systems will run some checks on your new code. We require that your pull request passes these checks, but we also have more criteria than just that before we can accept and merge it. We recommend that you check the following things locally before you submit your code.</p>"},{"location":"governance/CONTRIBUTING/#bpfman-pinned-rust-toolchain","title":"bpfman Pinned Rust Toolchain","text":"<p>bpfman is coded in Rust and uses the latest <code>nightly</code> Rust toolchain for some of the tools. There are periods where the Rust toolchain may be pinned to a fixed version due to tool issues. Examine bpfman/.github/workflows/build.yml and find <code>NIGHTLY_VERSION</code> to determine if the nightly toolchain is currently pinned.</p> <ul> <li>Example of using latest toolchain: <code>NIGHTLY_VERSION: nightly</code></li> <li>Example of using pinned toolchain: <code>NIGHTLY_VERSION: nightly-2024-09-24</code></li> </ul> <p>If the toolchain is pinned, use the following to install a pinned toolchain then show all the installed toolchains:</p> <pre><code>rustup toolchain install nightly-2024-09-24\n\nrustup show -v\n</code></pre> <p>Then replace <code>+nightly</code> in the commands below with the pinned toolchain <code>+nightly-2024-09-24</code>.</p>"},{"location":"governance/CONTRIBUTING/#bpfman-checklist","title":"bpfman Checklist","text":"<p>Before submitting a pull request to the bpfman repository, verify the following:</p> <ul> <li> <p>Verify that Rust code has been formatted and that all clippy lints have been fixed:</p> <pre><code>cd bpfman/\ncargo +nightly clippy --all -- --deny warnings\n</code></pre> </li> <li> <p>Verify that the code has been formatted and linted:</p> <pre><code>cargo +nightly fmt --all -- --check\n</code></pre> </li> <li> <p>Verify that Yaml files have been formatted (see   Install Yaml Formatter)</p> <pre><code>prettier -l \"*.yaml\"\n</code></pre> </li> <li> <p>Verify that Bash scripts have been linted using <code>shellcheck</code></p> <pre><code>cargo xtask lint\n</code></pre> </li> <li> <p>Verify that unit tests are passing locally (see   Unit Testing):</p> <pre><code>cargo xtask unit-test\n</code></pre> </li> <li> <p>Verify that integration tests are passing locally (see   Basic Integration Tests):</p> <pre><code>cargo xtask integration-test\n</code></pre> </li> </ul>"},{"location":"governance/CONTRIBUTING/#bpfman-operator-checklist","title":"bpfman-operator Checklist","text":"<ul> <li> <p>If developing the bpfman-operator, verify that bpfman-operator unit and integration tests   are passing locally:</p> <p>See Kubernetes Operator Tests.</p> </li> </ul>"},{"location":"governance/GOVERNANCE/","title":"bpfman Project Governance","text":"<p>The bpfman project is dedicated to creating an easy way to run eBPF programs on a single host and in clusters. This governance explains how the project is run.</p> <ul> <li>Values</li> <li>Maintainers</li> <li>Becoming a Maintainer</li> <li>Meetings</li> <li>Code of Conduct Enforcement</li> <li>Security Response Team</li> <li>Voting</li> <li>Modifications</li> </ul>"},{"location":"governance/GOVERNANCE/#values","title":"Values","text":"<p>The bpfman project and its leadership embrace the following values:</p> <ul> <li> <p>Openness: Communication and decision-making happens in the open and is discoverable for future   reference. As much as possible, all discussions and work take place in public   forums and open repositories.</p> </li> <li> <p>Fairness: All stakeholders have the opportunity to provide feedback and submit   contributions, which will be considered on their merits.</p> </li> <li> <p>Community over Product or Company: Sustaining and growing our community takes   priority over shipping code or sponsors' organizational goals.  Each   contributor participates in the project as an individual.</p> </li> <li> <p>Inclusivity: We innovate through different perspectives and skill sets, which   can only be accomplished in a welcoming and respectful environment.</p> </li> <li> <p>Participation: Responsibilities within the project are earned through   participation, and there is a clear path up the contributor ladder into leadership   positions.</p> </li> </ul>"},{"location":"governance/GOVERNANCE/#maintainers","title":"Maintainers","text":"<p>bpfman Maintainers have write access to the project GitHub repository. They can merge their patches or patches from others. The list of current maintainers can be found at MAINTAINERS.md.  Maintainers collectively manage the project's resources and contributors.</p> <p>This privilege is granted with some expectation of responsibility: maintainers are people who care about the bpfman project and want to help it grow and improve. A maintainer is not just someone who can make changes, but someone who has demonstrated their ability to collaborate with the team, get the most knowledgeable people to review code and docs, contribute high-quality code, and follow through to fix issues (in code or tests).</p> <p>A maintainer is a contributor to the project's success and a citizen helping the project succeed.</p> <p>The collective team of all Maintainers is known as the Maintainer Council, which is the governing body for the project.</p>"},{"location":"governance/GOVERNANCE/#becoming-a-maintainer","title":"Becoming a Maintainer","text":"<p>To become a Maintainer you need to demonstrate the following:</p> <ul> <li>commitment to the project:</li> <li>participate in discussions, contributions, code and documentation reviews, for 6 months or more,</li> <li>perform reviews for 10 non-trivial pull requests,</li> <li>contribute 10 non-trivial pull requests and have them merged,</li> <li>ability to write quality code and/or documentation,</li> <li>ability to collaborate with the team,</li> <li>understanding of how the team works (policies, processes for testing and code review, etc),</li> <li>understanding of the project's code base and coding and documentation style.</li> </ul> <p>A new Maintainer must be proposed by an existing maintainer by opening a Pull Request on GitHub to update the MAINTAINERS.md file. A simple majority vote of existing Maintainers approves the application. Maintainer nominations will be evaluated without prejudice to employers or demographics.</p> <p>Maintainers who are selected will be granted the necessary GitHub rights.</p>"},{"location":"governance/GOVERNANCE/#removing-a-maintainer","title":"Removing a Maintainer","text":"<p>Maintainers may resign at any time if they feel that they will not be able to continue fulfilling their project duties.</p> <p>Maintainers may also be removed after being inactive, failing to fulfill their Maintainer responsibilities, violating the Code of Conduct, or for other reasons. Inactivity is defined as a period of very low or no activity in the project for a year or more, with no definite schedule to return to full Maintainer activity.</p> <p>A Maintainer may be removed at any time by a 2/3 vote of the remaining maintainers.</p> <p>Depending on the reason for removal, a Maintainer may be converted to Emeritus status. Emeritus Maintainers will still be consulted on some project matters and can be rapidly returned to Maintainer status if their availability changes.</p>"},{"location":"governance/GOVERNANCE/#meetings","title":"Meetings","text":"<p>Time zones permitting, Maintainers are expected to participate in the public developer meeting, detailed in the meetings document.</p> <p>Maintainers will also have closed meetings to discuss security reports or Code of Conduct violations. Such meetings should be scheduled by any Maintainer on receipt of a security issue or CoC report. All current Maintainers must be invited to such closed meetings, except for any Maintainer who is accused of a CoC violation.</p>"},{"location":"governance/GOVERNANCE/#code-of-conduct","title":"Code of Conduct","text":"<p>Code of Conduct violations by community members will be discussed and resolved on the private maintainer Slack channel.</p>"},{"location":"governance/GOVERNANCE/#security-response-team","title":"Security Response Team","text":"<p>The Maintainers will appoint a Security Response Team to handle security reports. This committee may simply consist of the Maintainer Council themselves.  If this responsibility is delegated, the Maintainers will appoint a team of at least two contributors to handle it.  The Maintainers will review who is assigned to this at least once a year.</p> <p>The Security Response Team is responsible for handling all reports of security holes and breaches according to the security policy.</p>"},{"location":"governance/GOVERNANCE/#voting","title":"Voting","text":"<p>While most business in bpfman is conducted by \"lazy consensus\", periodically the Maintainers may need to vote on specific actions or changes. A vote can be taken on the private developer slack channel for security or conduct matters. Votes may also be taken at the developer meeting.  Any Maintainer may demand a vote be taken.</p> <p>Most votes require a simple majority of all Maintainers to succeed, except where otherwise noted.  Two-thirds majority votes mean at least two-thirds of all existing maintainers.</p>"},{"location":"governance/GOVERNANCE/#modifying-this-charter","title":"Modifying this Charter","text":"<p>Changes to this Governance and its supporting documents may be approved by a 2/3 vote of the Maintainers.</p>"},{"location":"governance/MAINTAINERS/","title":"Maintainers","text":"<p>See CONTRIBUTING.md for general contribution guidelines. See GOVERNANCE.md for governance guidelines and maintainer responsibilities. See CODEOWNERS for a detailed list of owners for the various source directories.</p> Name Employer Dave Tucker Red Hat Andrew McDermott Red Hat Andre Fredette Red Hat Billy McFall Red Hat"},{"location":"governance/MAINTAINERS/#emeritus-maintainers","title":"Emeritus Maintainers","text":"Name Employer Andrew Stoycos Red Hat"},{"location":"governance/MEETINGS/","title":"bpfman Community Meetings","text":""},{"location":"governance/MEETINGS/#meeting-time","title":"Meeting time","text":"<p>We meet every Thursday at 10:00 AM Eastern Time. The meetings last up to 1 hour.</p> <p>Project calendar</p>"},{"location":"governance/MEETINGS/#meeting-location","title":"Meeting location","text":"<p>Platform: CNCF Zoom</p> <p>Meeting ID: 95637056950</p> <p>Meeting Passcode: 333928</p> <p>Video call link</p> <p>Or dial:</p> <p>\ud83c\uddfa\ud83c\uddf8  +1 253 215 8782 or 877 369 0926 (Toll Free)</p> <p>\ud83c\udde8\ud83c\udde6  +1 647 374 4685 or 855 703 8985 (Toll Free)</p> <p>More phone numbers: https://zoom.us/u/alwnPIaVT</p>"},{"location":"governance/MEETINGS/#meeting-agenda-and-minutes","title":"Meeting agenda and minutes","text":"<p>Meeting agenda</p>"},{"location":"governance/REVIEWING/","title":"Reviewing Guide","text":"<p>This document covers who may review pull requests for this project, and guides how to perform code reviews that meet our community standards and code of conduct. All reviewers must read this document and agree to follow the project review guidelines. Reviewers who do not follow these guidelines may have their privileges revoked.</p>"},{"location":"governance/REVIEWING/#the-reviewer-role","title":"The Reviewer Role","text":"<p>Only maintainers are REQUIRED to review pull requests. Other contributors may opt to review pull requests, but any LGTM from a non-maintainer won't count towards the required number of Approved Reviews in the Mergify policy.</p>"},{"location":"governance/REVIEWING/#values","title":"Values","text":"<p>All reviewers must abide by the Code of Conduct and are also protected by it. A reviewer should not tolerate poor behavior and is encouraged to report any behavior that violates the Code of Conduct. All of our values listed above are distilled from our Code of Conduct.</p> <p>Below are concrete examples of how it applies to code review specifically:</p>"},{"location":"governance/REVIEWING/#inclusion","title":"Inclusion","text":"<p>Be welcoming and inclusive. You should proactively ensure that the author is successful. While any particular pull request may not ultimately be merged, overall we want people to have a great experience and be willing to contribute again. Answer the questions they didn't know to ask or offer concrete help when they appear stuck.</p>"},{"location":"governance/REVIEWING/#sustainability","title":"Sustainability","text":"<p>Avoid burnout by enforcing healthy boundaries. Here are some examples of how a reviewer is encouraged to act to take care of themselves:</p> <ul> <li>Authors should meet baseline expectations when submitting a pull request, such as writing tests.</li> <li>If your availability changes, you can step down from a pull request and have someone else assigned.</li> <li>If interactions with an author are not following the code of conduct, close the PR and raise it with your Code of Conduct committee or point of contact. It's not your job to coax people into behaving.</li> </ul>"},{"location":"governance/REVIEWING/#trust","title":"Trust","text":"<p>Be trustworthy. During a review, your actions both build and help maintain the trust that the community has placed in this project. Below are examples of ways that we build trust:</p> <ul> <li>Transparency - If a pull request won't be merged, clearly say why and close it. If a pull request won't be reviewed for a while, let the author know so they can set expectations and understand why it's blocked.</li> <li>Integrity - Put the project's best interests ahead of personal relationships or company affiliations when deciding if a change should be merged.</li> <li>Stability - Only merge when the change won't negatively impact project stability. It can be tempting to merge a pull request that doesn't meet our quality standards, for example when the review has been delayed, or because we are trying to deliver new features quickly, but regressions can significantly hurt trust in our project.</li> </ul>"},{"location":"governance/REVIEWING/#process","title":"Process","text":"<ul> <li>Reviewers are automatically assigned based on the CODEOWNERS file.</li> <li>Reviewers should wait for automated checks to pass before reviewing</li> <li>At least 1 approved review is required from a maintainer before a pull request can be merged</li> <li>All CI checks must pass</li> <li>If a PR is stuck for some reason it is down to the reviewer to determine the best course of action:</li> <li>PRs may be closed if they are no longer relevant</li> <li>A maintainer may choose to carry a PR forward on their own, but they should ALWAYS include the original author's commits</li> <li>A maintainer may choose to open additional PRs to help lay a foundation on which the stuck PR can be unstuck. They may either rebase the stuck PR themselves or leave this to the author</li> <li>Maintainers should not merge their pull requests without a review</li> <li>Maintainers should let the Mergify bot merge PRs and not merge PRs directly</li> <li>In times of need, i.e. to fix pressing security issues, the Maintainers may, at their discretion, merge PRs without review. They should at least add a comment to the PR explaining why they did so.</li> </ul>"},{"location":"governance/REVIEWING/#checklist","title":"Checklist","text":"<p>Below are a set of common questions that apply to all pull requests:</p> <ul> <li>[ ] Is this PR targeting the correct branch?</li> <li>[ ] Does the commit message provide an adequate description of the change?</li> <li>[ ] Does the affected code have corresponding tests?</li> <li>[ ] Are the changes documented, not just with inline documentation, but also with conceptual documentation such as an overview of a new feature, or task-based documentation like a tutorial? Consider if this change should be announced on your project blog.</li> <li>[ ] Does this introduce breaking changes that would require an announcement or bumping of the major version?</li> <li>[ ] Does this PR introduce any new dependencies?</li> </ul>"},{"location":"governance/REVIEWING/#reading-list","title":"Reading List","text":"<p>Reviewers are encouraged to read the following articles for help with common reviewer tasks:</p> <ul> <li>The Art of Closing: How to close an unfinished or rejected pull request</li> <li>Kindness and Code Reviews: Improving the Way We Give Feedback</li> <li>Code Review Guidelines for Humans: Examples of good and back feedback</li> </ul>"},{"location":"governance/SECURITY/","title":"Security Policy","text":""},{"location":"governance/SECURITY/#supported-versions","title":"Supported Versions","text":"<p>No released versions of bpfman and bpfman-agent or bpfman-operator will receive regular security updates until a mainline release has been performed. A reported and fixed vulnerability will be included in the next minor release, which depending on the severity of the vulnerability may be immediate.</p>"},{"location":"governance/SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>To report a vulnerability, please use the Private Vulnerability Reporting Feature on GitHub. We will endevour to respond within 48hrs of reporting. If a vulnerability is reported but considered low priority it may be converted into an issue and handled on the public issue tracker. Should a vulnerability be considered severe we will endeavour to patch it within 48hrs of acceptance, and may ask for you to collaborate with us on a temporary private fork of the repository.</p>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2023/","title":"2023","text":""},{"location":"blog/category/community-meeting/","title":"Community Meeting","text":""},{"location":"blog/category/2024/","title":"2024","text":""}]}